# Comparing `tmp/flexout-0.2.3-py3-none-any.whl.zip` & `tmp/flexout-0.2.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,16 +1,16 @@
-Zip file size: 16152 bytes, number of entries: 14
--rw-rw-rw-  2.0 fat      468 b- defN 23-Feb-24 00:00 flexout/__init__.py
--rw-rw-rw-  2.0 fat      164 b- defN 23-Feb-27 13:58 flexout/_version.py
--rw-rw-rw-  2.0 fat     8302 b- defN 23-Feb-24 05:12 flexout/base.py
--rw-rw-rw-  2.0 fat     6919 b- defN 23-Feb-24 17:44 flexout/csv.py
--rw-rw-rw-  2.0 fat    16465 b- defN 23-Feb-25 13:27 flexout/excel.py
--rw-rw-rw-  2.0 fat     9012 b- defN 23-Feb-27 13:58 flexout/filemgr.py
--rw-rw-rw-  2.0 fat     3886 b- defN 23-Feb-24 00:00 flexout/flexout.py
--rw-rw-rw-  2.0 fat      400 b- defN 23-Feb-24 17:44 flexout/noop.py
--rw-rw-rw-  2.0 fat      703 b- defN 23-Feb-24 00:00 flexout/tabulate.py
--rw-rw-rw-  2.0 fat     1084 b- defN 23-Feb-27 13:58 flexout-0.2.3.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     3218 b- defN 23-Feb-27 13:58 flexout-0.2.3.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Feb-27 13:58 flexout-0.2.3.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Feb-27 13:58 flexout-0.2.3.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     1052 b- defN 23-Feb-27 13:58 flexout-0.2.3.dist-info/RECORD
-14 files, 51773 bytes uncompressed, 14434 bytes compressed:  72.1%
+Zip file size: 15627 bytes, number of entries: 14
+-rw-r--r--  2.0 unx      449 b- defN 23-Jun-10 14:09 flexout/__init__.py
+-rw-r--r--  2.0 unx      160 b- defN 23-Jun-10 14:11 flexout/_version.py
+-rw-r--r--  2.0 unx     8346 b- defN 23-Jun-10 14:09 flexout/base.py
+-rw-r--r--  2.0 unx     6729 b- defN 23-Jun-10 14:09 flexout/csv.py
+-rw-r--r--  2.0 unx    16065 b- defN 23-Jun-10 14:09 flexout/excel.py
+-rw-r--r--  2.0 unx     8720 b- defN 23-Jun-10 14:09 flexout/filemgr.py
+-rw-r--r--  2.0 unx     3775 b- defN 23-Jun-10 14:09 flexout/flexout.py
+-rw-r--r--  2.0 unx      383 b- defN 23-Jun-10 14:09 flexout/noop.py
+-rw-r--r--  2.0 unx      676 b- defN 23-Jun-10 14:09 flexout/tabulate.py
+-rw-r--r--  2.0 unx     1065 b- defN 23-Jun-10 14:11 flexout-0.2.4.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx     1788 b- defN 23-Jun-10 14:11 flexout-0.2.4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-10 14:11 flexout-0.2.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Jun-10 14:11 flexout-0.2.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1052 b- defN 23-Jun-10 14:11 flexout-0.2.4.dist-info/RECORD
+14 files, 49308 bytes uncompressed, 13909 bytes compressed:  71.8%
```

## zipnote {}

```diff
@@ -21,23 +21,23 @@
 
 Filename: flexout/noop.py
 Comment: 
 
 Filename: flexout/tabulate.py
 Comment: 
 
-Filename: flexout-0.2.3.dist-info/LICENSE.txt
+Filename: flexout-0.2.4.dist-info/LICENSE.txt
 Comment: 
 
-Filename: flexout-0.2.3.dist-info/METADATA
+Filename: flexout-0.2.4.dist-info/METADATA
 Comment: 
 
-Filename: flexout-0.2.3.dist-info/WHEEL
+Filename: flexout-0.2.4.dist-info/WHEEL
 Comment: 
 
-Filename: flexout-0.2.3.dist-info/top_level.txt
+Filename: flexout-0.2.4.dist-info/top_level.txt
 Comment: 
 
-Filename: flexout-0.2.3.dist-info/RECORD
+Filename: flexout-0.2.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## flexout/__init__.py

 * *Ordering differences only*

```diff
@@ -1,19 +1,19 @@
-from __future__ import annotations
-import sys
-
-from .flexout import flexout
-
-from . import filemgr
-from .filemgr import configure_smb_credentials
-
-from .base import BaseOut
-from .csv import CsvOut
-from .tabulate import TabulateOut
-from .excel import ExcelOut
-
-try:
-    # Version generated by setuptools_scm during build
-    from ._version import __version__, __version_tuple__
-except ImportError:
-    __version__ = None
-    __version_tuple__ = None
+from __future__ import annotations
+import sys
+
+from .flexout import flexout
+
+from . import filemgr
+from .filemgr import configure_smb_credentials
+
+from .base import BaseOut
+from .csv import CsvOut
+from .tabulate import TabulateOut
+from .excel import ExcelOut
+
+try:
+    # Version generated by setuptools_scm during build
+    from ._version import __version__, __version_tuple__
+except ImportError:
+    __version__ = None
+    __version_tuple__ = None
```

## flexout/_version.py

```diff
@@ -1,4 +1,4 @@
-# file generated by setuptools_scm
-# don't change, don't track in version control
-__version__ = version = '0.2.3'
-__version_tuple__ = version_tuple = (0, 2, 3)
+# file generated by setuptools_scm
+# don't change, don't track in version control
+__version__ = version = '0.2.4'
+__version_tuple__ = version_tuple = (0, 2, 4)
```

## flexout/base.py

```diff
@@ -1,267 +1,276 @@
-from __future__ import annotations
-import logging, sys
-from io import IOBase
-from enum import Enum
-
-from . import filemgr
-
-logger = logging.getLogger(__name__)
-
-_DICT_KEYS_TYPE = type({}.keys())
-
-
-class BaseOut:
-    def __init__(self, target: IOBase|str = None, headers: list[str] = None, append: bool = False, newline: str = None, encoding: str = None, **kwargs):
-        # Management of file and path
-        if isinstance(target, IOBase) or not target:
-            self._file = target
-            self._external_file = True
-            self._path = None
-            self._table_name = None
-            self._name = _get_iobase_name(target)
-        else:
-            self._file = None
-            self._external_file = False
-            self._path, self._table_name = _split_path_target(target)
-            self._name = target
-
-        self._append = append
-        self._newline = newline
-        self._encoding = encoding
-
-        # Management of tabular data
-        self._headers: list[str] = _get_headers_from_arg(headers) if headers else []
-        self._rows: list[list] = []
-        self._wait_for_more_headers: bool = True
-        self._delayed_rows: list[list] = []
-        self._rows_count: int = 0
-        self._missing_in_headers: list[str] = []
-
-
-    # -------------------------------------------------------------------------
-    # Open/close
-    # -------------------------------------------------------------------------
-
-    def __enter__(self):
-        return self
-
-
-    def __exit__(self, exc_type, exc_val, exc_tb):        
-        if exc_type:
-            return # forward exception
-
-        self._flush_delayed()
-        
-        self._before_close()
-
-        if self._file and not self._external_file:
-            self._file.close()
-
-
-    def _open_path(self):
-        if not self._path:
-            raise ValueError(f'cannot open path for {self._name}')
-        return filemgr.open_file(self._path, mode='a' if self._append else 'w', newline=self._newline, encoding=self._encoding, mkdir=True)
-
-
-    def _flush_delayed(self):
-        if self._wait_for_more_headers:
-            self._wait_for_more_headers = False
-            if self._headers:
-                self._output_headers()
-
-        if self._delayed_rows:
-            for drow in self._delayed_rows:
-                self._actual_append(drow)
-            
-            self._delayed_rows = []
-
-
-    def _before_close(self):
-        pass
-
-
-    # -------------------------------------------------------------------------
-    # Main public interface
-    # -------------------------------------------------------------------------
-
-    @property
-    def rows(self):
-        return self._rows
-
-
-    @property
-    def headers(self):
-        return self._headers
-       
-
-    @headers.setter
-    def headers(self, value: list[str]):
-        if self._headers:
-           raise ValueError('cannot add headers anymore')
-
-        self._headers = _get_headers_from_arg(value)
-        self._wait_for_more_headers = False
-        self._output_headers()
-
-
-    def append(self, *args, nowait=False):
-        """
-        Add a tabular row.
-
-        If a single dict is passed as argument, keys of the dict are considered to be table headers :
-        - If output has already started, the row will be written immediatly (an exception will be raised if any key of the dict does not match the headers)
-        - If output has NOT started yet, writing of the row will be delayed (headers will be updated with the keys of the dict), except if option `nowait` is set to True
-        """
-        self._rows_count += 1
-
-        if len(args) == 1 and isinstance(args[0], dict):
-            # Dict row: keys are headers.
-
-            if self._headers is None:
-                self._headers = []
-            
-            missing_in_headers = []
-
-            row = [None] * len(self._headers)            
-            for key, value in args[0].items():
-                try:
-                    index = self._headers.index(key)
-                    row[index] = value
-                except:
-                    if self._wait_for_more_headers:
-                        # add to headers
-                        self._headers.append(key)
-                        row.append(value)
-                    else:
-                        # missing in headers: we only warn for the first occurrence                        
-                        if not key in self._missing_in_headers:
-                            missing_in_headers.append(key)
-                            self._missing_in_headers.append(key)
-
-            if missing_in_headers:
-                logger.warning(f"ignore value for key not found in headers: {', '.join(missing_in_headers)} (first occurence on row {self._rows_count})")
-            
-            if self._wait_for_more_headers and not nowait:
-                self._delayed_rows.append(row)
-            else:
-                self._flush_delayed()
-                self._actual_append(row)
-
-        else:
-            # Row without header information is given: we write the row immediatly
-            if len(args) == 1 and isinstance(args[0], list):
-                row = args[0]
-            else:
-                row = list(args)
-
-            self._flush_delayed()
-            self._actual_append(row)
-
-
-    @property
-    def file(self) -> IOBase:
-        if not self._file:
-            self._file = self._open_path()
-        return self._file
-
-
-    def __str__(self) -> str:
-        return self._name
-
-
-    def print_title(self, title: str = None, out = None, level = None):
-        if out or (hasattr(self, '_file') and self._file in [sys.stdout, sys.stderr]):
-            if not out:
-                out = self._file
-            print('\n##########%s##########\n' % (f' {title[0].upper()+title[1:]} ' if title else ''), file=out)
-        else:
-            logger.log(level if level is not None else logging.INFO, 'export %sto %s' % (f'{title} ' if title else '', self._name))
-
-
-    # -------------------------------------------------------------------------
-    # Private helpers
-    # -------------------------------------------------------------------------
-
-    def _actual_append(self, row: list):
-        row = self._format_row(row)
-        self._on_append(row)
-        self.rows.append(row)
-
-
-    def _output_headers(self):
-        pass # Implemented by subclasses
-
-
-    def _on_append(self, row: list):
-        pass # Implemented by subclasses
-        
-
-    def _format_row(self, row: list):
-        if self._headers:
-            while len(row) < len(self._headers):
-                row.append(None)
-
-        for i, value in enumerate(row):
-            row[i] = self._format_value(value)
-
-        return row
-
-
-    def _format_value(self, value) -> str:
-        if value is None:
-            return None
-        elif isinstance(value, Enum):
-            return value.name
-        elif isinstance(value, list):
-            return '|'.join(str(val) for val in value)
-        else:
-            return value
-
-
-def _split_path_target(target: str) -> tuple[str,str]:
-    """
-    Return (path, table_name).
-    """
-    if not target:
-        return (None, None)
-    
-    pos = target.find('#')
-    if pos > 0:
-        path = target[0:pos]
-        arg = target[pos+1:].replace('-', '_')
-    else:
-        path = target
-        arg = None
-    
-    return (path, arg)
-
-
-def _get_headers_from_arg(arg) -> list[str]:
-    if isinstance(arg, (tuple,_DICT_KEYS_TYPE)):
-        return list(arg)
-    elif isinstance(arg, list):
-        return arg
-    else:
-        raise ValueError(f'invalid type for headers: {arg} ({type(arg).__name__})')
-
-
-def _get_iobase_name(file: str) -> str:
-    if not file:
-        return '<none>'
-    
-    try:
-        name = file.name
-        if not name or not isinstance(name, str):
-            name = None
-    except AttributeError:
-        name = None
-
-    if name:
-        if name.startswith('<') and name.endswith('>'):
-            return name
-        else:
-            return f'<{name}>'
-
-    else:
-        return f"<{type(file).__name__}>"
+from __future__ import annotations
+import logging, sys
+from io import IOBase
+from enum import Enum
+
+from . import filemgr
+
+logger = logging.getLogger(__name__)
+
+_DICT_KEYS_TYPE = type({}.keys())
+
+
+class BaseOut:
+    def __init__(self, target: IOBase|str = None, headers: list[str] = None, append: bool = False, newline: str = None, encoding: str = None, **kwargs):
+        # Management of file and path
+        if isinstance(target, IOBase) or not target:
+            self._file = target
+            self._external_file = True
+            self._path = None
+            self._table_name = None
+            self._name = _get_iobase_name(target)
+        else:
+            self._file = None
+            self._external_file = False
+            self._path, self._table_name = _split_path_target(target)
+            self._name = target
+
+        self._append = append
+        self._newline = newline
+        self._encoding = encoding
+
+        # Management of tabular data
+        self._headers: list[str] = _get_headers_from_arg(headers) if headers else []
+        self._rows: list[list] = []
+        self._wait_for_more_headers: bool = True
+        self._delayed_rows: list[list] = []
+        self._rows_count: int = 0
+        self._missing_in_headers: list[str] = []
+
+
+    # -------------------------------------------------------------------------
+    # Open/close
+    # -------------------------------------------------------------------------
+
+    def __enter__(self):
+        return self
+
+
+    def __exit__(self, exc_type, exc_val, exc_tb):        
+        if exc_type:
+            return # forward exception
+
+        self._flush_delayed()
+        
+        self._before_close()
+
+        if self._file and not self._external_file:
+            self._file.close()
+
+
+    def _open_path(self):
+        if not self._path:
+            raise ValueError(f'cannot open path for {self._name}')
+        return filemgr.open_file(self._path, mode='a' if self._append else 'w', newline=self._newline, encoding=self._encoding, mkdir=True)
+
+
+    def _flush_delayed(self):
+        if self._wait_for_more_headers:
+            self._wait_for_more_headers = False
+            if self._headers:
+                self._output_headers()
+
+        if self._delayed_rows:
+            for drow in self._delayed_rows:
+                self._actual_append(drow)
+            
+            self._delayed_rows = []
+
+
+    def _before_close(self):
+        pass
+
+
+    # -------------------------------------------------------------------------
+    # Main public interface
+    # -------------------------------------------------------------------------
+
+    @property
+    def rows(self):
+        return self._rows
+
+
+    @property
+    def headers(self):
+        return self._headers
+       
+
+    @headers.setter
+    def headers(self, value: list[str]):
+        if self._headers:
+           raise ValueError('cannot add headers anymore')
+
+        self._headers = _get_headers_from_arg(value)
+        self._wait_for_more_headers = False
+        self._output_headers()
+
+
+    def append(self, *args, nowait=False):
+        """
+        Add a tabular row.
+
+        If a single dict is passed as argument, keys of the dict are considered to be table headers :
+        - If output has already started, the row will be written immediatly (an exception will be raised if any key of the dict does not match the headers)
+        - If output has NOT started yet, writing of the row will be delayed (headers will be updated with the keys of the dict), except if option `nowait` is set to True
+        """
+        self._rows_count += 1
+
+        if len(args) == 1 and isinstance(args[0], dict):
+            # Dict row: keys are headers.
+
+            if self._headers is None:
+                self._headers = []
+            
+            missing_in_headers = []
+
+            row = [None] * len(self._headers)            
+            for key, value in args[0].items():
+                try:
+                    index = self._headers.index(key)
+                    row[index] = value
+                except:
+                    if self._wait_for_more_headers:
+                        # add to headers
+                        self._headers.append(key)
+                        row.append(value)
+                    else:
+                        # missing in headers: we only warn for the first occurrence                        
+                        if not key in self._missing_in_headers:
+                            missing_in_headers.append(key)
+                            self._missing_in_headers.append(key)
+
+            if missing_in_headers:
+                logger.warning(f"ignore value for key not found in headers: {', '.join(missing_in_headers)} (first occurence on row {self._rows_count})")
+            
+            if self._wait_for_more_headers and not nowait:
+                self._delayed_rows.append(row)
+            else:
+                self._flush_delayed()
+                self._actual_append(row)
+
+        else:
+            # Row without header information is given: we write the row immediatly
+            if len(args) == 1 and _is_row(args[0]):
+                # The first argument is an iterable that is considered the actual row
+                row = list(args[0])
+            else:
+                row = list(args)
+
+            self._flush_delayed()
+            self._actual_append(row)
+
+
+    @property
+    def file(self) -> IOBase:
+        if not self._file:
+            self._file = self._open_path()
+        return self._file
+
+
+    def __str__(self) -> str:
+        return self._name
+
+
+    def print_title(self, title: str = None, out = None, level = None):
+        if out or (hasattr(self, '_file') and self._file in [sys.stdout, sys.stderr]):
+            if not out:
+                out = self._file
+            print('\n##########%s##########\n' % (f' {title[0].upper()+title[1:]} ' if title else ''), file=out)
+        else:
+            logger.log(level if level is not None else logging.INFO, 'export %sto %s' % (f'{title} ' if title else '', self._name))
+
+
+    # -------------------------------------------------------------------------
+    # Private helpers
+    # -------------------------------------------------------------------------
+
+    def _actual_append(self, row: list):
+        row = self._format_row(row)
+        self._on_append(row)
+        self.rows.append(row)
+
+
+    def _output_headers(self):
+        pass # Implemented by subclasses
+
+
+    def _on_append(self, row: list):
+        pass # Implemented by subclasses
+        
+
+    def _format_row(self, row: list):
+        if self._headers:
+            while len(row) < len(self._headers):
+                row.append(None)
+
+        for i, value in enumerate(row):
+            row[i] = self._format_value(value)
+
+        return row
+
+
+    def _format_value(self, value) -> str:
+        if value is None:
+            return None
+        elif isinstance(value, Enum):
+            return value.name
+        elif isinstance(value, list):
+            return '|'.join(str(val) for val in value)
+        else:
+            return value
+
+
+def _split_path_target(target: str) -> tuple[str,str]:
+    """
+    Return (path, table_name).
+    """
+    if not target:
+        return (None, None)
+    
+    pos = target.find('#')
+    if pos > 0:
+        path = target[0:pos]
+        arg = target[pos+1:].replace('-', '_')
+    else:
+        path = target
+        arg = None
+    
+    return (path, arg)
+
+
+def _get_headers_from_arg(arg) -> list[str]:
+    if isinstance(arg, (tuple,_DICT_KEYS_TYPE)):
+        return list(arg)
+    elif isinstance(arg, list):
+        return arg
+    else:
+        raise ValueError(f'invalid type for headers: {arg} ({type(arg).__name__})')
+
+
+def _get_iobase_name(file: str) -> str:
+    if not file:
+        return '<none>'
+    
+    try:
+        name = file.name
+        if not name or not isinstance(name, str):
+            name = None
+    except AttributeError:
+        name = None
+
+    if name:
+        if name.startswith('<') and name.endswith('>'):
+            return name
+        else:
+            return f'<{name}>'
+
+    else:
+        return f"<{type(file).__name__}>"
+
+
+def _is_row(arg):
+    if isinstance(arg, list):
+        return True
+    if arg.__class__.__module__ == '__builtin__': # including strings
+        return False
+    return hasattr(arg, '__iter__') or hasattr(arg, '__getitem__')
```

## flexout/csv.py

 * *Ordering differences only*

```diff
@@ -1,190 +1,190 @@
-from __future__ import annotations
-import csv, _csv, os, locale, logging, sys
-from datetime import datetime, timezone
-from typing import Any
-
-if sys.version_info[0:2] < (3, 8):
-    from typing_extensions import Literal
-else:
-    from typing import Literal
-
-from . import filemgr
-from .base import BaseOut
-
-
-logger = logging.getLogger(__name__)
-
-
-class CsvOut(BaseOut):
-    def __init__(self, dialect: str|csv.Dialect|type[csv.Dialect] = None, timezone: Literal['local']|timezone = None, **kwargs):
-        super().__init__(**kwargs)
-
-        # For CSV files:
-        # - Set newline to '', otherwise newlines embedded inside quoted fields will not be interpreted correctly. See footnote of: https://docs.python.org/3/library/csv.html
-        # - Set encoding to utf-8-sig (UTF8 with BOM): CSV is for exchanges, encoding should not depend on the exporting operating system. BOM is necessary for correct display with Excel.
-        if self._newline is None:
-            self._newline = ''
-        if self._encoding is None:
-            self._encoding = 'utf-8-sig'
-
-        self._dialect = get_dialect(dialect)
-        dialect_str = (self._dialect if isinstance(self._dialect, str) else (self._dialect.__name__ if isinstance(self._dialect, type) else type(self._dialect).__name__)).replace('_', '-')
-
-        if dialect_str == 'excel':
-            self._excel_dialect = 'default'
-        elif dialect_str.startswith('excel-'):
-            self._excel_dialect = dialect_str[6:]
-        else:
-            self._excel_dialect = None
-        
-        self._timezone = timezone
-
-        self._headers_mapping: dict[int,int] = None
-
-
-    def _open_path(self):
-        if not hasattr(self, '_previous_headers'):
-            self._read_existing_file_if_any()
-
-        return super()._open_path()
-
-    
-    def _read_existing_file_if_any(self):
-        if hasattr(self, 'previous_headers'):
-            return
-        
-        # Determine headers of existing file
-        self._previous_headers: list[str] = None
-        if self._append and self._path and filemgr.exists(self._path):
-            with filemgr.open_file(self._path,  mode='r', newline=self._newline, encoding=self._encoding) as f:
-                reader = csv.reader(f, dialect=self._dialect)
-                try:
-                    self._previous_headers = next(reader)
-                except StopIteration:
-                    self._previous_headers = None
-
-
-    @property
-    def _writer(self) -> _csv._writer:
-        try:
-            return self.__writer
-        except AttributeError:
-            self.__writer = csv.writer(self.file, dialect=self._dialect)
-            return self.__writer
-
-
-    _headers_mapping_actual_len: int
-
-
-    def _output_headers(self):
-        if not hasattr(self, '_previous_headers'):
-            self._read_existing_file_if_any()
-        
-        if self._previous_headers:
-            # Determine mapping
-            additional_headers = []
-            for pos, header in enumerate(self._headers):
-                try:
-                    previous_pos = self._previous_headers.index(header)
-                except ValueError:
-                    additional_headers.append(header)
-                    previous_pos = len(self._previous_headers) + len(additional_headers) - 1
-
-                if previous_pos != pos:
-                    if self._headers_mapping is None:
-                        self._headers_mapping = {}
-                    self._headers_mapping[pos] = previous_pos
-
-            if additional_headers:
-                logger.warning(f"header missing in existing file: {', '.join(additional_headers)} - corresponding data will be appended without the header name")
-
-            self._headers_mapping_actual_len = len(self._headers) + len(additional_headers)
-
-        else:
-            self._writer.writerow(self._headers)
-            self.file.flush()
-
-
-    def _on_append(self, row: list):
-        if self._headers_mapping:
-            # Apply mapping
-            reordered_row = [None] * self._headers_mapping_actual_len
-            pos = 0
-            while pos < len(row):
-                reordered_row[self._headers_mapping.get(pos, pos)] = row[pos]
-                pos += 1
-            row = reordered_row
-
-        self._writer.writerow(row)
-        self.file.flush()
-
-
-    def _format_value(self, value: Any) -> str:
-        if value is None:
-            return None
-        elif isinstance(value, datetime):
-            # If output is expected in a given timezone, we make this datetime naive in the target timezone and display it in a format understandable by Excel
-            if value.tzinfo:
-                if self._timezone:
-                    value: datetime = value.astimezone(None if self._timezone == 'local' else self._timezone)
-                    use_tzinfo = False
-                else:
-                    use_tzinfo = True
-            else:
-                use_tzinfo = False
-
-            # Format microseconds. For excel, remove it if we can make Excel interprete the value as datetime
-            if self._excel_dialect or value.microsecond == 0:
-                mspart = ''
-            else:
-                mspart = '.' + value.strftime('%f')
-            
-            # Format tzinfo and microseconds
-            if use_tzinfo:
-                tzpart = value.strftime('%z')
-                if len(tzpart) == 5:
-                    tzpart = tzpart[0:3] + ':' + tzpart[3:]
-            else:
-                tzpart = ''
-
-            return value.strftime("%Y-%m-%d %H:%M:%S") + mspart + tzpart
-        elif isinstance(value, float) and self._excel_dialect == 'fr':
-            return str(value).replace('.', ',')
-        elif hasattr(value, 'value'): # example: ValueString
-            return getattr(value, 'value')
-        else:
-            return super()._format_value(value)
-
-
-class excel_fr(csv.excel):
-    """ Dialect for French version of Excel. """
-    delimiter = ";"
-
-
-def get_dialect(name: str|csv.Dialect|type[csv.Dialect] = None, default: str|csv.Dialect|type[csv.Dialect] = None) -> str|csv.Dialect|type[csv.Dialect]:
-    # Register my own dialects
-    available_dialects = csv.list_dialects()
-
-    if 'excel-fr' not in available_dialects:
-        csv.register_dialect('excel-fr', excel_fr())
-        available_dialects.append('excel-fr')
-
-    # Return if name or default given
-    if name:
-        return name
-    
-    if default:
-        return default
-    
-    default = os.environ.get("CSV_DIALECT", None)
-    if default:
-        return default
-
-    # If nothing provided, try to detect language
-    language_code, _ = locale.getlocale()
-    lang = language_code[0:2]
-    dialect = f"excel-{lang}"
-    if dialect in available_dialects:
-        return dialect
-
-    return 'excel'
+from __future__ import annotations
+import csv, _csv, os, locale, logging, sys
+from datetime import datetime, timezone
+from typing import Any
+
+if sys.version_info[0:2] < (3, 8):
+    from typing_extensions import Literal
+else:
+    from typing import Literal
+
+from . import filemgr
+from .base import BaseOut
+
+
+logger = logging.getLogger(__name__)
+
+
+class CsvOut(BaseOut):
+    def __init__(self, dialect: str|csv.Dialect|type[csv.Dialect] = None, timezone: Literal['local']|timezone = None, **kwargs):
+        super().__init__(**kwargs)
+
+        # For CSV files:
+        # - Set newline to '', otherwise newlines embedded inside quoted fields will not be interpreted correctly. See footnote of: https://docs.python.org/3/library/csv.html
+        # - Set encoding to utf-8-sig (UTF8 with BOM): CSV is for exchanges, encoding should not depend on the exporting operating system. BOM is necessary for correct display with Excel.
+        if self._newline is None:
+            self._newline = ''
+        if self._encoding is None:
+            self._encoding = 'utf-8-sig'
+
+        self._dialect = get_dialect(dialect)
+        dialect_str = (self._dialect if isinstance(self._dialect, str) else (self._dialect.__name__ if isinstance(self._dialect, type) else type(self._dialect).__name__)).replace('_', '-')
+
+        if dialect_str == 'excel':
+            self._excel_dialect = 'default'
+        elif dialect_str.startswith('excel-'):
+            self._excel_dialect = dialect_str[6:]
+        else:
+            self._excel_dialect = None
+        
+        self._timezone = timezone
+
+        self._headers_mapping: dict[int,int] = None
+
+
+    def _open_path(self):
+        if not hasattr(self, '_previous_headers'):
+            self._read_existing_file_if_any()
+
+        return super()._open_path()
+
+    
+    def _read_existing_file_if_any(self):
+        if hasattr(self, 'previous_headers'):
+            return
+        
+        # Determine headers of existing file
+        self._previous_headers: list[str] = None
+        if self._append and self._path and filemgr.exists(self._path):
+            with filemgr.open_file(self._path,  mode='r', newline=self._newline, encoding=self._encoding) as f:
+                reader = csv.reader(f, dialect=self._dialect)
+                try:
+                    self._previous_headers = next(reader)
+                except StopIteration:
+                    self._previous_headers = None
+
+
+    @property
+    def _writer(self) -> _csv._writer:
+        try:
+            return self.__writer
+        except AttributeError:
+            self.__writer = csv.writer(self.file, dialect=self._dialect)
+            return self.__writer
+
+
+    _headers_mapping_actual_len: int
+
+
+    def _output_headers(self):
+        if not hasattr(self, '_previous_headers'):
+            self._read_existing_file_if_any()
+        
+        if self._previous_headers:
+            # Determine mapping
+            additional_headers = []
+            for pos, header in enumerate(self._headers):
+                try:
+                    previous_pos = self._previous_headers.index(header)
+                except ValueError:
+                    additional_headers.append(header)
+                    previous_pos = len(self._previous_headers) + len(additional_headers) - 1
+
+                if previous_pos != pos:
+                    if self._headers_mapping is None:
+                        self._headers_mapping = {}
+                    self._headers_mapping[pos] = previous_pos
+
+            if additional_headers:
+                logger.warning(f"header missing in existing file: {', '.join(additional_headers)} - corresponding data will be appended without the header name")
+
+            self._headers_mapping_actual_len = len(self._headers) + len(additional_headers)
+
+        else:
+            self._writer.writerow(self._headers)
+            self.file.flush()
+
+
+    def _on_append(self, row: list):
+        if self._headers_mapping:
+            # Apply mapping
+            reordered_row = [None] * self._headers_mapping_actual_len
+            pos = 0
+            while pos < len(row):
+                reordered_row[self._headers_mapping.get(pos, pos)] = row[pos]
+                pos += 1
+            row = reordered_row
+
+        self._writer.writerow(row)
+        self.file.flush()
+
+
+    def _format_value(self, value: Any) -> str:
+        if value is None:
+            return None
+        elif isinstance(value, datetime):
+            # If output is expected in a given timezone, we make this datetime naive in the target timezone and display it in a format understandable by Excel
+            if value.tzinfo:
+                if self._timezone:
+                    value: datetime = value.astimezone(None if self._timezone == 'local' else self._timezone)
+                    use_tzinfo = False
+                else:
+                    use_tzinfo = True
+            else:
+                use_tzinfo = False
+
+            # Format microseconds. For excel, remove it if we can make Excel interprete the value as datetime
+            if self._excel_dialect or value.microsecond == 0:
+                mspart = ''
+            else:
+                mspart = '.' + value.strftime('%f')
+            
+            # Format tzinfo and microseconds
+            if use_tzinfo:
+                tzpart = value.strftime('%z')
+                if len(tzpart) == 5:
+                    tzpart = tzpart[0:3] + ':' + tzpart[3:]
+            else:
+                tzpart = ''
+
+            return value.strftime("%Y-%m-%d %H:%M:%S") + mspart + tzpart
+        elif isinstance(value, float) and self._excel_dialect == 'fr':
+            return str(value).replace('.', ',')
+        elif hasattr(value, 'value'): # example: ValueString
+            return getattr(value, 'value')
+        else:
+            return super()._format_value(value)
+
+
+class excel_fr(csv.excel):
+    """ Dialect for French version of Excel. """
+    delimiter = ";"
+
+
+def get_dialect(name: str|csv.Dialect|type[csv.Dialect] = None, default: str|csv.Dialect|type[csv.Dialect] = None) -> str|csv.Dialect|type[csv.Dialect]:
+    # Register my own dialects
+    available_dialects = csv.list_dialects()
+
+    if 'excel-fr' not in available_dialects:
+        csv.register_dialect('excel-fr', excel_fr())
+        available_dialects.append('excel-fr')
+
+    # Return if name or default given
+    if name:
+        return name
+    
+    if default:
+        return default
+    
+    default = os.environ.get("CSV_DIALECT", None)
+    if default:
+        return default
+
+    # If nothing provided, try to detect language
+    language_code, _ = locale.getlocale()
+    lang = language_code[0:2]
+    dialect = f"excel-{lang}"
+    if dialect in available_dialects:
+        return dialect
+
+    return 'excel'
```

## flexout/excel.py

 * *Ordering differences only*

```diff
@@ -1,400 +1,400 @@
-"""
-Required: pip install openpyxl defusedxml
-"""
-from __future__ import annotations
-import logging, sys
-from typing import Any
-from datetime import datetime, timezone
-from pathlib import Path
-
-if sys.version_info[0:2] < (3, 8):
-    from typing_extensions import Literal
-else:
-    from typing import Literal
-
-from . import filemgr
-from .base import BaseOut
-
-try:
-    from openpyxl import load_workbook, Workbook, DEFUSEDXML
-    from openpyxl.worksheet.worksheet import Worksheet
-    from openpyxl.worksheet.table import Table, TableColumn, TableFormula, TableStyleInfo
-    from openpyxl.worksheet.formula import DataTableFormula, ArrayFormula
-    from openpyxl.cell.cell import Cell
-    from openpyxl.styles.differential import DifferentialStyle, DifferentialStyleList
-    from openpyxl.styles.fills import PatternFill
-    from openpyxl.utils import range_boundaries, get_column_letter
-
-    _import_error = None
-
-    logger = logging.getLogger(__name__)
-
-    _cache = {
-        'defusedxml_alert': False,
-    }
-
-
-    class ExcelOut(BaseOut):
-        @classmethod
-        def is_available(cls):
-            return _import_error is None
-        
-
-        def __init__(self, timezone: Literal['local']|timezone = None, **kwargs):
-            super().__init__(**kwargs)
-
-            self._timezone = timezone
-
-            if not self.is_available():
-                raise ValueError(f"cannot use {self.__class__.__name__}: {_import_error}")
-
-            if not DEFUSEDXML and not _cache['defusedxml_alert']:
-                logger.warning("By default openpyxl does not guard against quadratic blowup or billion laughs xml attacks. To guard against these attacks install defusedxml.")
-                _cache['defusedxml_alert'] = True
-
-            if not self._table_name:
-                self._table_name = self._DEFAULT_TABLE_NAME
-
-
-        def _format_value(self, value: Any) -> str:
-            if value is None:
-                return None
-            elif isinstance(value, datetime) and value.tzinfo:
-                # Excel does not support timezones in datetimes
-                if self._timezone:
-                    value = value.astimezone(None if self._timezone == 'local' else self._timezone)
-                return value.replace(tzinfo=None)
-            else:
-                return super()._format_value(value)
-
-
-        def _open_path(self):                
-            if not self._path:
-                raise ValueError(f'cannot open path for {self._name}')
-                
-            if not hasattr(self, '_workbook'):
-                self._read_existing_file_if_any()
-
-            # Open path for binary writting
-            return filemgr.open_file(self._path, mode='wb', newline=self._newline, encoding=self._encoding, mkdir=True)
-
-
-        _workbook: Workbook
-        _worksheet: Worksheet
-        _previous_table: Table|None
-        
-        def _read_existing_file_if_any(self):
-            # Open workbook and search for existing table
-            if filemgr.exists(self._path):
-                with filemgr.open_file(self._path, 'rb') as fd:
-                    self._workbook: Workbook = load_workbook(fd)
-
-                self._previous_table = None
-                for name in self._workbook.sheetnames:
-                    self._worksheet: Worksheet = self._workbook[name]
-                    if self._table_name in self._worksheet.tables:
-                        self._previous_table = self._worksheet.tables[self._table_name]
-                        break
-
-                if not self._previous_table:
-                    # table not found: we create a new worksheet
-                    self._worksheet: Worksheet = self._workbook.create_sheet(title=self._table_name)
-
-            else:
-                self._workbook: Workbook = Workbook()
-                self._worksheet: Worksheet = self._workbook.active
-                self._worksheet.title = self._table_name
-                self._previous_table = None
-
-
-        _headers_mapping: dict[int,int]|None
-        _unmanaged_col_indices: list[int]|None
-        _column_formats: dict[int,dict[str,Any]]|None
-        _previous_last_row_index: int|None
-        _first_col_index: int
-        _first_row_index: int
-        _last_col_index: int
-        _next_row_index: int
-        _warned_additional_columns: bool
-
-
-        def _output_headers(self):
-            self._headers_mapping = None
-            self._unmanaged_col_indices = None
-            self._column_formats = None
-
-            if not hasattr(self, '_workbook'):
-                self._read_existing_file_if_any()
-            
-            if self._previous_table:
-                # Get existing table boundaries
-                self._first_col_index, self._first_row_index, self._last_col_index, self._previous_last_row_index = range_boundaries(self._previous_table.ref)
-
-                # Determines previous headers   
-                previous_headers: list[str] = []
-                column: TableColumn
-                for i, column in enumerate(self._previous_table.tableColumns):
-                    previous_headers.append(column.name)
-                    self._prepare_column_format(col_index=self._first_col_index + i, column=column)
-
-                # Determines headers mapping
-                new_headers = []
-                for pos, header in enumerate(self._headers):
-                    try:
-                        previous_pos = previous_headers.index(header)
-                    except ValueError:
-                        new_headers.append(header)
-                        previous_pos = len(previous_headers) + len(new_headers) - 1
-
-                    if previous_pos != pos:
-                        if self._headers_mapping is None:
-                            self._headers_mapping = {}
-                        self._headers_mapping[pos] = previous_pos
-
-                # Determines header columns that are not handled by us
-                for pos, header in enumerate(previous_headers):
-                    if not header in self._headers:
-                        if self._unmanaged_col_indices is None:
-                            self._unmanaged_col_indices = []
-                        self._unmanaged_col_indices.append(self._first_col_index + pos)
-                
-                # Add new headers
-                if new_headers:
-                    logger.info(f"add header for table {self._table_name}: {', '.join(new_headers)} - was missing in existing table")
-
-                    for header in new_headers:
-                        self._last_col_index += 1
-                        self._set_cell(self._first_row_index, self._last_col_index, header, is_header=True)
-
-                        # Mark data as '?' (unknown) for the column if we append
-                        if self._append:
-                            r = self._first_row_index + 1
-                            while r <= self._previous_last_row_index:
-                                self._set_cell(r, self._last_col_index, '?')
-                                r += 1
-
-                # Determine next row
-                if self._append:
-                    self._next_row_index = self._previous_last_row_index + 1
-                else:
-                    self._next_row_index = self._first_row_index + 1
-            
-            else:
-                # Table does not exist: write headers
-                self._previous_last_row_index = None
-                self._first_col_index = 1
-                self._first_row_index = 1
-                self._last_col_index = 0
-
-                for header in self._headers:
-                    self._last_col_index += 1
-                    self._set_cell(self._first_col_index, self._last_col_index, header, is_header=True)
-
-                self._next_row_index = self._first_row_index + 1
-
-            self._warned_additional_columns = False
-
-
-        def _on_append(self, row: list):
-            if not self._headers:
-                raise ValueError(f"headers not appended yet")
-
-            # Write managed data
-            for i in range(0, len(row)):
-                if i >= len(self._headers):
-                    if not self._warned_additional_columns:
-                        logger.warning(f"ignore row values at index >= {len(self._headers)} (first occurence on row {len(self.rows)})")
-                        self._warned_additional_columns = True
-                else:
-                    col_index = self._first_col_index + (self._headers_mapping.get(i, i) if self._headers_mapping else i)
-                    self._set_cell(self._next_row_index, col_index, row[i])
-
-            # Erase cell for unmanaged data
-            if self._unmanaged_col_indices:
-                for col_index in self._unmanaged_col_indices:
-                    self._erase_cell(self._next_row_index, col_index)
-
-            self._next_row_index += 1
-        
-        
-        def _before_close(self):
-            if not self._path:
-                raise ValueError(f"can only use ExcelOut with path target")
-
-            if not self._headers:
-                raise ValueError(f"cannot use ExcelOut without headers")
-
-            # Erase data outside of table
-            if self._previous_last_row_index is not None:
-                r = self._next_row_index
-                while r <= self._previous_last_row_index:
-                    c = self._first_col_index
-                    while c <= self._last_col_index:
-                        self._erase_cell(r, c, outside_table = True)
-                        c += 1
-                    r += 1
-
-            # Create table
-            table_ref = f"{get_column_letter(self._first_col_index)}{self._first_row_index}:{get_column_letter(self._last_col_index)}{self._next_row_index-1}"
-            if self._previous_table:
-                if self._previous_table.ref != table_ref:
-                    self._recreate_table(table_ref)
-            else:
-                table = Table(name=self._table_name, displayName=self._table_name, ref=table_ref)
-                table.tableStyleInfo = TableStyleInfo(name="TableStyleLight9", showFirstColumn=False, showLastColumn=False, showRowStripes=True, showColumnStripes=False)
-                self._worksheet.add_table(table)
-
-            # Save the file
-            self._workbook.save(self.file)
-
-
-        def _recreate_table(self, new_ref):
-            newcolumns = []
-
-            for i in range(0, self._last_col_index - self._first_col_index + 1):
-                name = self._worksheet.cell(self._first_row_index, self._first_col_index + i).value
-                newcolumn = TableColumn(id=i+1, name=name)
-                newcolumns.append(newcolumn)
-
-                if i < len(self._previous_table.tableColumns):
-                    prevcolumn: TableColumn = self._previous_table.tableColumns[i]
-                    newcolumn.dataCellStyle = prevcolumn.dataCellStyle
-                    newcolumn.dataDxfId = prevcolumn.dataDxfId # refers to workbook._differential_styles
-                    newcolumn.calculatedColumnFormula = prevcolumn.calculatedColumnFormula
-
-            newtable = Table(name=self._table_name, displayName=self._table_name, ref=new_ref, tableColumns=newcolumns, autoFilter=self._previous_table.autoFilter, sortState=self._previous_table.sortState)
-            newtable.tableStyleInfo = self._previous_table.tableStyleInfo
-            
-            del self._worksheet.tables[self._table_name]
-            self._worksheet.add_table(newtable)
-
-
-        # -------------------------------------------------------------------------
-        # Helpers
-        # -------------------------------------------------------------------------
-        _DEFAULT_TABLE_NAME = 'Flexout'
-
-        def _set_cell(self, row_index: int, col_index: int, value, is_header = False) -> Cell:
-            cell: Cell = self._worksheet.cell(row_index, col_index)
-
-            if not is_header:
-                self._apply_column_format(cell)
-
-            try:
-                cell.value = value
-            except ValueError as err:
-                if str(err).startswith('Cannot convert'):
-                    cell.value = str(value)
-                else:
-                    raise
-
-            return cell
-
-
-        def _erase_cell(self, row_index: int, col_index: int, outside_table = False) -> Cell:
-            cell: Cell = self._worksheet.cell(row_index, col_index)
-            cell.style = 'Normal'
-            
-            cell.value = None
-            if not outside_table:
-                self._apply_column_format(cell)
-            
-            return cell
-
-
-        def _apply_column_format(self, cell: Cell):
-            if not self._column_formats:
-                return
-
-            fmt = self._column_formats.get(cell.col_idx, None)
-            if fmt is None:
-                return
-
-            if 'formula' in fmt:
-                formula = fmt['formula']
-                if isinstance(formula, ArrayFormula):
-                    pass # TODO: not supported yet
-                else:
-                    cell.value = formula
-
-            if 'style' in fmt:
-                cell.style = fmt['style']
-
-            for fmt_key, fmt_value in fmt.items():
-                if fmt_key in ['formula', 'style']:
-                    continue
-                setattr(cell, fmt_key, fmt_value)
-
-
-        def _prepare_column_format(self, col_index: int, column: TableColumn) -> dict[str,Any]|None:
-            if not self._column_formats:
-                self._column_formats = {}
-
-            fmt: dict[str,Any] = None
-
-            # Read dataCellStyle
-            if column.dataCellStyle:
-                if fmt is None:
-                    fmt = {}
-
-                fmt['style'] = column.dataCellStyle
-            
-            # Read dxf
-            if column.dataDxfId is not None:
-                if fmt is None:
-                    fmt = {}
-
-                dxf: DifferentialStyle = self._workbook._differential_styles[column.dataDxfId]
-
-                if dxf.numFmt:
-                    fmt['number_format'] = dxf.numFmt.formatCode
-                else:
-                    if not 'style' in fmt:
-                        fmt['number_format'] = self._DEFAULT_NUMBER_FORMAT
-
-                fmt['alignment'] = dxf.alignment if dxf.alignment else self._DEFAULT_ALIGNMENT
-                fmt['border'] = dxf.border if dxf.border else self._DEFAULT_BORDER
-                fmt['font'] = dxf.font if dxf.font else self._DEFAULT_FONT
-                fmt['protection'] = dxf.protection if dxf.protection else self._DEFAULT_PROTECTION
-                fmt['fill'] = PatternFill(fill_type=dxf.fill.fill_type, bgColor=dxf.fill.fgColor, fgColor=dxf.fill.bgColor) if dxf.fill else self._DEFAULT_FILL # NOTE: fgcolor and bgcolor are inversed in DifferentialStyle
-
-            # Read formula
-            if column.calculatedColumnFormula:
-                if fmt is None:
-                    fmt = {}
-
-                formula = column.calculatedColumnFormula
-                if formula.array:
-                    fmt['formula'] = ArrayFormula(formula.attr_text)
-                else:
-                    fmt['formula'] = '=' + formula.attr_text
-            
-            # Register format
-            if fmt is not None:
-                self._column_formats[col_index] = fmt
-        
-
-        _DEFAULT_NUMBER_FORMAT = 'General'
-
-        _DEFAULT_FILL = PatternFill(fill_type=None)
-
-        _DEFAULT_ALIGNMENT = None # openpyxl.styles.alignment.Alignment
-        _DEFAULT_BORDER = None # openpyxl.styles.alignment.Border
-        _DEFAULT_FONT = None # openpyxl.styles.fonts.Font
-        _DEFAULT_PROTECTION = None # openpyxl.styles.protection.Protection
-
-
-# -----------------------------------------------------------------------------
-except ImportError as err:
-    _import_error = str(err)
-
-    class ExcelOut(BaseOut):
-        @classmethod
-        def is_available(cls):
-            return False
-        
-        def __init__(self, **kwargs):
-            super().__init__(**kwargs)
-
-            if not self.is_available():
-                raise ValueError(f"cannot use {self.__class__.__name__}: {_import_error}")
+"""
+Required: pip install openpyxl defusedxml
+"""
+from __future__ import annotations
+import logging, sys
+from typing import Any
+from datetime import datetime, timezone
+from pathlib import Path
+
+if sys.version_info[0:2] < (3, 8):
+    from typing_extensions import Literal
+else:
+    from typing import Literal
+
+from . import filemgr
+from .base import BaseOut
+
+try:
+    from openpyxl import load_workbook, Workbook, DEFUSEDXML
+    from openpyxl.worksheet.worksheet import Worksheet
+    from openpyxl.worksheet.table import Table, TableColumn, TableFormula, TableStyleInfo
+    from openpyxl.worksheet.formula import DataTableFormula, ArrayFormula
+    from openpyxl.cell.cell import Cell
+    from openpyxl.styles.differential import DifferentialStyle, DifferentialStyleList
+    from openpyxl.styles.fills import PatternFill
+    from openpyxl.utils import range_boundaries, get_column_letter
+
+    _import_error = None
+
+    logger = logging.getLogger(__name__)
+
+    _cache = {
+        'defusedxml_alert': False,
+    }
+
+
+    class ExcelOut(BaseOut):
+        @classmethod
+        def is_available(cls):
+            return _import_error is None
+        
+
+        def __init__(self, timezone: Literal['local']|timezone = None, **kwargs):
+            super().__init__(**kwargs)
+
+            self._timezone = timezone
+
+            if not self.is_available():
+                raise ValueError(f"cannot use {self.__class__.__name__}: {_import_error}")
+
+            if not DEFUSEDXML and not _cache['defusedxml_alert']:
+                logger.warning("By default openpyxl does not guard against quadratic blowup or billion laughs xml attacks. To guard against these attacks install defusedxml.")
+                _cache['defusedxml_alert'] = True
+
+            if not self._table_name:
+                self._table_name = self._DEFAULT_TABLE_NAME
+
+
+        def _format_value(self, value: Any) -> str:
+            if value is None:
+                return None
+            elif isinstance(value, datetime) and value.tzinfo:
+                # Excel does not support timezones in datetimes
+                if self._timezone:
+                    value = value.astimezone(None if self._timezone == 'local' else self._timezone)
+                return value.replace(tzinfo=None)
+            else:
+                return super()._format_value(value)
+
+
+        def _open_path(self):                
+            if not self._path:
+                raise ValueError(f'cannot open path for {self._name}')
+                
+            if not hasattr(self, '_workbook'):
+                self._read_existing_file_if_any()
+
+            # Open path for binary writting
+            return filemgr.open_file(self._path, mode='wb', newline=self._newline, encoding=self._encoding, mkdir=True)
+
+
+        _workbook: Workbook
+        _worksheet: Worksheet
+        _previous_table: Table|None
+        
+        def _read_existing_file_if_any(self):
+            # Open workbook and search for existing table
+            if filemgr.exists(self._path):
+                with filemgr.open_file(self._path, 'rb') as fd:
+                    self._workbook: Workbook = load_workbook(fd)
+
+                self._previous_table = None
+                for name in self._workbook.sheetnames:
+                    self._worksheet: Worksheet = self._workbook[name]
+                    if self._table_name in self._worksheet.tables:
+                        self._previous_table = self._worksheet.tables[self._table_name]
+                        break
+
+                if not self._previous_table:
+                    # table not found: we create a new worksheet
+                    self._worksheet: Worksheet = self._workbook.create_sheet(title=self._table_name)
+
+            else:
+                self._workbook: Workbook = Workbook()
+                self._worksheet: Worksheet = self._workbook.active
+                self._worksheet.title = self._table_name
+                self._previous_table = None
+
+
+        _headers_mapping: dict[int,int]|None
+        _unmanaged_col_indices: list[int]|None
+        _column_formats: dict[int,dict[str,Any]]|None
+        _previous_last_row_index: int|None
+        _first_col_index: int
+        _first_row_index: int
+        _last_col_index: int
+        _next_row_index: int
+        _warned_additional_columns: bool
+
+
+        def _output_headers(self):
+            self._headers_mapping = None
+            self._unmanaged_col_indices = None
+            self._column_formats = None
+
+            if not hasattr(self, '_workbook'):
+                self._read_existing_file_if_any()
+            
+            if self._previous_table:
+                # Get existing table boundaries
+                self._first_col_index, self._first_row_index, self._last_col_index, self._previous_last_row_index = range_boundaries(self._previous_table.ref)
+
+                # Determines previous headers   
+                previous_headers: list[str] = []
+                column: TableColumn
+                for i, column in enumerate(self._previous_table.tableColumns):
+                    previous_headers.append(column.name)
+                    self._prepare_column_format(col_index=self._first_col_index + i, column=column)
+
+                # Determines headers mapping
+                new_headers = []
+                for pos, header in enumerate(self._headers):
+                    try:
+                        previous_pos = previous_headers.index(header)
+                    except ValueError:
+                        new_headers.append(header)
+                        previous_pos = len(previous_headers) + len(new_headers) - 1
+
+                    if previous_pos != pos:
+                        if self._headers_mapping is None:
+                            self._headers_mapping = {}
+                        self._headers_mapping[pos] = previous_pos
+
+                # Determines header columns that are not handled by us
+                for pos, header in enumerate(previous_headers):
+                    if not header in self._headers:
+                        if self._unmanaged_col_indices is None:
+                            self._unmanaged_col_indices = []
+                        self._unmanaged_col_indices.append(self._first_col_index + pos)
+                
+                # Add new headers
+                if new_headers:
+                    logger.info(f"add header for table {self._table_name}: {', '.join(new_headers)} - was missing in existing table")
+
+                    for header in new_headers:
+                        self._last_col_index += 1
+                        self._set_cell(self._first_row_index, self._last_col_index, header, is_header=True)
+
+                        # Mark data as '?' (unknown) for the column if we append
+                        if self._append:
+                            r = self._first_row_index + 1
+                            while r <= self._previous_last_row_index:
+                                self._set_cell(r, self._last_col_index, '?')
+                                r += 1
+
+                # Determine next row
+                if self._append:
+                    self._next_row_index = self._previous_last_row_index + 1
+                else:
+                    self._next_row_index = self._first_row_index + 1
+            
+            else:
+                # Table does not exist: write headers
+                self._previous_last_row_index = None
+                self._first_col_index = 1
+                self._first_row_index = 1
+                self._last_col_index = 0
+
+                for header in self._headers:
+                    self._last_col_index += 1
+                    self._set_cell(self._first_col_index, self._last_col_index, header, is_header=True)
+
+                self._next_row_index = self._first_row_index + 1
+
+            self._warned_additional_columns = False
+
+
+        def _on_append(self, row: list):
+            if not self._headers:
+                raise ValueError(f"headers not appended yet")
+
+            # Write managed data
+            for i in range(0, len(row)):
+                if i >= len(self._headers):
+                    if not self._warned_additional_columns:
+                        logger.warning(f"ignore row values at index >= {len(self._headers)} (first occurence on row {len(self.rows)})")
+                        self._warned_additional_columns = True
+                else:
+                    col_index = self._first_col_index + (self._headers_mapping.get(i, i) if self._headers_mapping else i)
+                    self._set_cell(self._next_row_index, col_index, row[i])
+
+            # Erase cell for unmanaged data
+            if self._unmanaged_col_indices:
+                for col_index in self._unmanaged_col_indices:
+                    self._erase_cell(self._next_row_index, col_index)
+
+            self._next_row_index += 1
+        
+        
+        def _before_close(self):
+            if not self._path:
+                raise ValueError(f"can only use ExcelOut with path target")
+
+            if not self._headers:
+                raise ValueError(f"cannot use ExcelOut without headers")
+
+            # Erase data outside of table
+            if self._previous_last_row_index is not None:
+                r = self._next_row_index
+                while r <= self._previous_last_row_index:
+                    c = self._first_col_index
+                    while c <= self._last_col_index:
+                        self._erase_cell(r, c, outside_table = True)
+                        c += 1
+                    r += 1
+
+            # Create table
+            table_ref = f"{get_column_letter(self._first_col_index)}{self._first_row_index}:{get_column_letter(self._last_col_index)}{self._next_row_index-1}"
+            if self._previous_table:
+                if self._previous_table.ref != table_ref:
+                    self._recreate_table(table_ref)
+            else:
+                table = Table(name=self._table_name, displayName=self._table_name, ref=table_ref)
+                table.tableStyleInfo = TableStyleInfo(name="TableStyleLight9", showFirstColumn=False, showLastColumn=False, showRowStripes=True, showColumnStripes=False)
+                self._worksheet.add_table(table)
+
+            # Save the file
+            self._workbook.save(self.file)
+
+
+        def _recreate_table(self, new_ref):
+            newcolumns = []
+
+            for i in range(0, self._last_col_index - self._first_col_index + 1):
+                name = self._worksheet.cell(self._first_row_index, self._first_col_index + i).value
+                newcolumn = TableColumn(id=i+1, name=name)
+                newcolumns.append(newcolumn)
+
+                if i < len(self._previous_table.tableColumns):
+                    prevcolumn: TableColumn = self._previous_table.tableColumns[i]
+                    newcolumn.dataCellStyle = prevcolumn.dataCellStyle
+                    newcolumn.dataDxfId = prevcolumn.dataDxfId # refers to workbook._differential_styles
+                    newcolumn.calculatedColumnFormula = prevcolumn.calculatedColumnFormula
+
+            newtable = Table(name=self._table_name, displayName=self._table_name, ref=new_ref, tableColumns=newcolumns, autoFilter=self._previous_table.autoFilter, sortState=self._previous_table.sortState)
+            newtable.tableStyleInfo = self._previous_table.tableStyleInfo
+            
+            del self._worksheet.tables[self._table_name]
+            self._worksheet.add_table(newtable)
+
+
+        # -------------------------------------------------------------------------
+        # Helpers
+        # -------------------------------------------------------------------------
+        _DEFAULT_TABLE_NAME = 'Flexout'
+
+        def _set_cell(self, row_index: int, col_index: int, value, is_header = False) -> Cell:
+            cell: Cell = self._worksheet.cell(row_index, col_index)
+
+            if not is_header:
+                self._apply_column_format(cell)
+
+            try:
+                cell.value = value
+            except ValueError as err:
+                if str(err).startswith('Cannot convert'):
+                    cell.value = str(value)
+                else:
+                    raise
+
+            return cell
+
+
+        def _erase_cell(self, row_index: int, col_index: int, outside_table = False) -> Cell:
+            cell: Cell = self._worksheet.cell(row_index, col_index)
+            cell.style = 'Normal'
+            
+            cell.value = None
+            if not outside_table:
+                self._apply_column_format(cell)
+            
+            return cell
+
+
+        def _apply_column_format(self, cell: Cell):
+            if not self._column_formats:
+                return
+
+            fmt = self._column_formats.get(cell.col_idx, None)
+            if fmt is None:
+                return
+
+            if 'formula' in fmt:
+                formula = fmt['formula']
+                if isinstance(formula, ArrayFormula):
+                    pass # TODO: not supported yet
+                else:
+                    cell.value = formula
+
+            if 'style' in fmt:
+                cell.style = fmt['style']
+
+            for fmt_key, fmt_value in fmt.items():
+                if fmt_key in ['formula', 'style']:
+                    continue
+                setattr(cell, fmt_key, fmt_value)
+
+
+        def _prepare_column_format(self, col_index: int, column: TableColumn) -> dict[str,Any]|None:
+            if not self._column_formats:
+                self._column_formats = {}
+
+            fmt: dict[str,Any] = None
+
+            # Read dataCellStyle
+            if column.dataCellStyle:
+                if fmt is None:
+                    fmt = {}
+
+                fmt['style'] = column.dataCellStyle
+            
+            # Read dxf
+            if column.dataDxfId is not None:
+                if fmt is None:
+                    fmt = {}
+
+                dxf: DifferentialStyle = self._workbook._differential_styles[column.dataDxfId]
+
+                if dxf.numFmt:
+                    fmt['number_format'] = dxf.numFmt.formatCode
+                else:
+                    if not 'style' in fmt:
+                        fmt['number_format'] = self._DEFAULT_NUMBER_FORMAT
+
+                fmt['alignment'] = dxf.alignment if dxf.alignment else self._DEFAULT_ALIGNMENT
+                fmt['border'] = dxf.border if dxf.border else self._DEFAULT_BORDER
+                fmt['font'] = dxf.font if dxf.font else self._DEFAULT_FONT
+                fmt['protection'] = dxf.protection if dxf.protection else self._DEFAULT_PROTECTION
+                fmt['fill'] = PatternFill(fill_type=dxf.fill.fill_type, bgColor=dxf.fill.fgColor, fgColor=dxf.fill.bgColor) if dxf.fill else self._DEFAULT_FILL # NOTE: fgcolor and bgcolor are inversed in DifferentialStyle
+
+            # Read formula
+            if column.calculatedColumnFormula:
+                if fmt is None:
+                    fmt = {}
+
+                formula = column.calculatedColumnFormula
+                if formula.array:
+                    fmt['formula'] = ArrayFormula(formula.attr_text)
+                else:
+                    fmt['formula'] = '=' + formula.attr_text
+            
+            # Register format
+            if fmt is not None:
+                self._column_formats[col_index] = fmt
+        
+
+        _DEFAULT_NUMBER_FORMAT = 'General'
+
+        _DEFAULT_FILL = PatternFill(fill_type=None)
+
+        _DEFAULT_ALIGNMENT = None # openpyxl.styles.alignment.Alignment
+        _DEFAULT_BORDER = None # openpyxl.styles.alignment.Border
+        _DEFAULT_FONT = None # openpyxl.styles.fonts.Font
+        _DEFAULT_PROTECTION = None # openpyxl.styles.protection.Protection
+
+
+# -----------------------------------------------------------------------------
+except ImportError as err:
+    _import_error = str(err)
+
+    class ExcelOut(BaseOut):
+        @classmethod
+        def is_available(cls):
+            return False
+        
+        def __init__(self, **kwargs):
+            super().__init__(**kwargs)
+
+            if not self.is_available():
+                raise ValueError(f"cannot use {self.__class__.__name__}: {_import_error}")
```

## flexout/filemgr.py

 * *Ordering differences only*

```diff
@@ -1,292 +1,292 @@
-"""
-File manager.
-
-Optional requirement for Samba/Windows shares: pip install smbprotocol
-"""
-from __future__ import annotations
-import os, ntpath, sys, logging, shutil
-from pathlib import Path
-from enum import Enum
-
-try:
-    import smbclient
-    import smbclient.path as smbclient_path
-    import smbclient.shutil as smbclient_shutil
-except ImportError:
-    smbclient = None
-    smbclient_path = None
-    smbclient_shutil = None
-
-_cache = {
-    'smb_credentials': False
-}
-
-logger = logging.getLogger('__name__')
-
-
-
-def configure_smb_credentials(user: str = None, password: str = None):
-    if user or password:
-        if not smbclient:
-            logger.warning(f'ignore smb credentials: package `smbprotocol` not available')
-        else:
-            smbclient.ClientConfig(username=user, password=password)
-            _cache['smb_credentials'] = True
-
-
-def can_use_network_paths():
-    if sys.platform == 'win32' and not _cache['smb_credentials']:
-        return True  # Python is natively compatible with Samba shares on Windows
-
-    return smbclient is not None
-
-
-def _standardize(path: str) -> tuple[str,bool]:
-    """
-    Return (path, native).
-    """
-    if not path:
-        return path, True
-    
-    if isinstance(path, Path):
-        path = str(path)
-
-    path = os.path.expanduser(path)
-    
-    if not (path.startswith("\\\\") or path.startswith("//")):
-        return path, True  # not a network path
-        
-    if sys.platform == 'win32' and not _cache['smb_credentials']:
-        return path, True  # Python is natively compatible with Samba shares on Windows
-
-    return path, False
-
-
-def dirname(path: str):
-    path, native = _standardize(path)
-    
-    if native:
-        return os.path.dirname(path)
-    
-    return ntpath.dirname(path)
-
-
-def basename(path: str):
-    path, native = _standardize(path)
-
-    if native:
-        return os.path.basename(path)
-
-    return ntpath.basename(path)
-    
-
-def splitext(path: str):
-    path, native = _standardize(path)
-
-    if native:
-        return os.path.splitext(path)
-    
-    return ntpath.splitext(path)
-
-
-def exists(path: str):
-    path, native = _standardize(path)
-
-    if native:
-        return os.path.exists(path)
-
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_path.exists(path)
-
-
-def stat(path: str):
-    path, native = _standardize(path)
-
-    if native:
-        return os.stat(path)
-    
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient.stat(path)
-
-
-def makedirs(path: str, exist_ok: bool = False):
-    path, native = _standardize(path)
-
-    if native:
-        return os.makedirs(path, exist_ok=exist_ok)
-
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient.makedirs(path, exist_ok=exist_ok)
-
-
-def remove(path: str):
-    path, native = _standardize(path)
-
-    if native:
-        return os.remove(path)
-
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient.remove(path)
-
-
-def rmtree(path: str, ignore_errors=False, onerror=None):
-    path, native = _standardize(path)
-
-    if not native:
-        return shutil.rmtree(path, ignore_errors=ignore_errors, onerror=onerror)
-    
-    if not smbclient_shutil:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_shutil.rmtree(path, ignore_errors=ignore_errors, onerror=onerror)
-
-
-def open_file(path: str, mode="r", buffering: int = -1, encoding: str = None, errors: str = None, newline: str = None, mkdir: bool = False, **kwargs):
-    if mkdir:
-        dir_path = dirname(path)
-        if dir_path:
-            makedirs(dir_path, exist_ok=True)
-
-    path, native = _standardize(path)
-
-    if native:
-        return open(path, mode=mode, buffering=buffering, encoding=encoding, errors=errors, newline=newline, **kwargs)
-
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient.open_file(path, mode=mode, buffering=buffering, encoding=encoding, errors=errors, newline=newline, **kwargs)
-
-
-def read_bytes(path: str):
-    """
-    Open the file in bytes mode, read it, and close the file.
-    """
-    path, native = _standardize(path)
-
-    if native:
-        return Path(path).read_bytes()
-    
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    with smbclient.open_file(path, mode='rb') as f:
-        return f.read()
-
-
-def read_text(path: str, encoding: str = None, errors: str = None):
-    """
-    Open the file in text mode, read it, and close the file.
-    """
-    path, native = _standardize(path)
-
-    if native:
-        return Path(path).read_text(encoding=encoding, errors=errors)
-    
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    with smbclient.open_file(path, mode='r', encoding=encoding, errors=errors) as f:
-        return f.read()
-
-
-def write_bytes(path: str, data):
-    """
-    Open the file in bytes mode, write to it, and close the file.
-    """
-    path, native = _standardize(path)
-
-    if native:
-        return Path(path).write_bytes(data)
-    
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    with smbclient.open_file(path, mode='wb') as f:
-        return f.write(data)
-
-
-def write_text(path: str, data: str, encoding: str = None, errors: str = None, newline: str = None):
-    """
-    Open the file in text mode, write to it, and close the file.
-    """
-    path, native = _standardize(path)
-
-    if native:
-        return Path(path).write_text(data, encoding=encoding, errors=errors, newline=newline)
-
-    if not smbclient:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    with smbclient.open_file(path, mode='w', encoding=encoding, errors=errors, newline=newline) as f:
-        return f.write(data)
-
-
-def copy(src: str, dst: str, follow_symlinks=True):
-    src, src_native = _standardize(src)
-    dst, dst_native = _standardize(dst)
-    
-    if src_native and dst_native:
-        return shutil.copy(src, dst, follow_symlinks=follow_symlinks)
-    
-    if not smbclient_shutil:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_shutil.copy(src, dst, follow_symlinks=follow_symlinks)
-
-
-def copy2(src: str, dst: str, follow_symlinks=True):
-    src, src_native = _standardize(src)
-    dst, dst_native = _standardize(dst)
-    
-    if src_native and dst_native:
-        return shutil.copy2(src, dst, follow_symlinks=follow_symlinks)
-    
-    if not smbclient_shutil:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_shutil.copy2(src, dst, follow_symlinks=follow_symlinks)
-
-
-def copyfile(src: str, dst: str, follow_symlinks=True):
-    src, src_native = _standardize(src)
-    dst, dst_native = _standardize(dst)
-    
-    if src_native and dst_native:
-        return shutil.copyfile(src, dst, follow_symlinks=follow_symlinks)
-    
-    if not smbclient_shutil:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_shutil.copyfile(src, dst, follow_symlinks=follow_symlinks)
-
-
-def copystat(src: str, dst: str, follow_symlinks=True):
-    src, src_native = _standardize(src)
-    dst, dst_native = _standardize(dst)
-    
-    if src_native and dst_native:
-        return shutil.copystat(src, dst, follow_symlinks=follow_symlinks)
-    
-    if not smbclient_shutil:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_shutil.copystat(src, dst, follow_symlinks=follow_symlinks)
-
-
-def copymode(src: str, dst: str, follow_symlinks=True):
-    src, src_native = _standardize(src)
-    dst, dst_native = _standardize(dst)
-
-    if src_native and dst_native:
-        return shutil.copytree(src, dst, follow_symlinks=follow_symlinks)
-
-    if not smbclient_shutil:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_shutil.copymode(src, dst, follow_symlinks=follow_symlinks)
-
-
-def copytree(src: str, dst: str, symlinks=False, ignore=None, ignore_dangling_symlinks=False, dirs_exist_ok=False):
-    src, src_native = _standardize(src)
-    dst, dst_native = _standardize(dst)
-
-    if src_native and dst_native:
-        return shutil.copytree(src, dst, symlinks=symlinks, ignore=ignore, ignore_dangling_symlinks=ignore_dangling_symlinks, dirs_exist_ok=dirs_exist_ok)
-
-    if not smbclient_shutil:
-        raise ModuleNotFoundError(f'missing package `smbprotocol`')
-    return smbclient_shutil.copytree(src, dst, symlinks=symlinks, ignore=ignore, ignore_dangling_symlinks=ignore_dangling_symlinks, dirs_exist_ok=dirs_exist_ok)
+"""
+File manager.
+
+Optional requirement for Samba/Windows shares: pip install smbprotocol
+"""
+from __future__ import annotations
+import os, ntpath, sys, logging, shutil
+from pathlib import Path
+from enum import Enum
+
+try:
+    import smbclient
+    import smbclient.path as smbclient_path
+    import smbclient.shutil as smbclient_shutil
+except ImportError:
+    smbclient = None
+    smbclient_path = None
+    smbclient_shutil = None
+
+_cache = {
+    'smb_credentials': False
+}
+
+logger = logging.getLogger('__name__')
+
+
+
+def configure_smb_credentials(user: str = None, password: str = None):
+    if user or password:
+        if not smbclient:
+            logger.warning(f'ignore smb credentials: package `smbprotocol` not available')
+        else:
+            smbclient.ClientConfig(username=user, password=password)
+            _cache['smb_credentials'] = True
+
+
+def can_use_network_paths():
+    if sys.platform == 'win32' and not _cache['smb_credentials']:
+        return True  # Python is natively compatible with Samba shares on Windows
+
+    return smbclient is not None
+
+
+def _standardize(path: str) -> tuple[str,bool]:
+    """
+    Return (path, native).
+    """
+    if not path:
+        return path, True
+    
+    if isinstance(path, Path):
+        path = str(path)
+
+    path = os.path.expanduser(path)
+    
+    if not (path.startswith("\\\\") or path.startswith("//")):
+        return path, True  # not a network path
+        
+    if sys.platform == 'win32' and not _cache['smb_credentials']:
+        return path, True  # Python is natively compatible with Samba shares on Windows
+
+    return path, False
+
+
+def dirname(path: str):
+    path, native = _standardize(path)
+    
+    if native:
+        return os.path.dirname(path)
+    
+    return ntpath.dirname(path)
+
+
+def basename(path: str):
+    path, native = _standardize(path)
+
+    if native:
+        return os.path.basename(path)
+
+    return ntpath.basename(path)
+    
+
+def splitext(path: str):
+    path, native = _standardize(path)
+
+    if native:
+        return os.path.splitext(path)
+    
+    return ntpath.splitext(path)
+
+
+def exists(path: str):
+    path, native = _standardize(path)
+
+    if native:
+        return os.path.exists(path)
+
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_path.exists(path)
+
+
+def stat(path: str):
+    path, native = _standardize(path)
+
+    if native:
+        return os.stat(path)
+    
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient.stat(path)
+
+
+def makedirs(path: str, exist_ok: bool = False):
+    path, native = _standardize(path)
+
+    if native:
+        return os.makedirs(path, exist_ok=exist_ok)
+
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient.makedirs(path, exist_ok=exist_ok)
+
+
+def remove(path: str):
+    path, native = _standardize(path)
+
+    if native:
+        return os.remove(path)
+
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient.remove(path)
+
+
+def rmtree(path: str, ignore_errors=False, onerror=None):
+    path, native = _standardize(path)
+
+    if not native:
+        return shutil.rmtree(path, ignore_errors=ignore_errors, onerror=onerror)
+    
+    if not smbclient_shutil:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_shutil.rmtree(path, ignore_errors=ignore_errors, onerror=onerror)
+
+
+def open_file(path: str, mode="r", buffering: int = -1, encoding: str = None, errors: str = None, newline: str = None, mkdir: bool = False, **kwargs):
+    if mkdir:
+        dir_path = dirname(path)
+        if dir_path:
+            makedirs(dir_path, exist_ok=True)
+
+    path, native = _standardize(path)
+
+    if native:
+        return open(path, mode=mode, buffering=buffering, encoding=encoding, errors=errors, newline=newline, **kwargs)
+
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient.open_file(path, mode=mode, buffering=buffering, encoding=encoding, errors=errors, newline=newline, **kwargs)
+
+
+def read_bytes(path: str):
+    """
+    Open the file in bytes mode, read it, and close the file.
+    """
+    path, native = _standardize(path)
+
+    if native:
+        return Path(path).read_bytes()
+    
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    with smbclient.open_file(path, mode='rb') as f:
+        return f.read()
+
+
+def read_text(path: str, encoding: str = None, errors: str = None):
+    """
+    Open the file in text mode, read it, and close the file.
+    """
+    path, native = _standardize(path)
+
+    if native:
+        return Path(path).read_text(encoding=encoding, errors=errors)
+    
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    with smbclient.open_file(path, mode='r', encoding=encoding, errors=errors) as f:
+        return f.read()
+
+
+def write_bytes(path: str, data):
+    """
+    Open the file in bytes mode, write to it, and close the file.
+    """
+    path, native = _standardize(path)
+
+    if native:
+        return Path(path).write_bytes(data)
+    
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    with smbclient.open_file(path, mode='wb') as f:
+        return f.write(data)
+
+
+def write_text(path: str, data: str, encoding: str = None, errors: str = None, newline: str = None):
+    """
+    Open the file in text mode, write to it, and close the file.
+    """
+    path, native = _standardize(path)
+
+    if native:
+        return Path(path).write_text(data, encoding=encoding, errors=errors, newline=newline)
+
+    if not smbclient:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    with smbclient.open_file(path, mode='w', encoding=encoding, errors=errors, newline=newline) as f:
+        return f.write(data)
+
+
+def copy(src: str, dst: str, follow_symlinks=True):
+    src, src_native = _standardize(src)
+    dst, dst_native = _standardize(dst)
+    
+    if src_native and dst_native:
+        return shutil.copy(src, dst, follow_symlinks=follow_symlinks)
+    
+    if not smbclient_shutil:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_shutil.copy(src, dst, follow_symlinks=follow_symlinks)
+
+
+def copy2(src: str, dst: str, follow_symlinks=True):
+    src, src_native = _standardize(src)
+    dst, dst_native = _standardize(dst)
+    
+    if src_native and dst_native:
+        return shutil.copy2(src, dst, follow_symlinks=follow_symlinks)
+    
+    if not smbclient_shutil:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_shutil.copy2(src, dst, follow_symlinks=follow_symlinks)
+
+
+def copyfile(src: str, dst: str, follow_symlinks=True):
+    src, src_native = _standardize(src)
+    dst, dst_native = _standardize(dst)
+    
+    if src_native and dst_native:
+        return shutil.copyfile(src, dst, follow_symlinks=follow_symlinks)
+    
+    if not smbclient_shutil:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_shutil.copyfile(src, dst, follow_symlinks=follow_symlinks)
+
+
+def copystat(src: str, dst: str, follow_symlinks=True):
+    src, src_native = _standardize(src)
+    dst, dst_native = _standardize(dst)
+    
+    if src_native and dst_native:
+        return shutil.copystat(src, dst, follow_symlinks=follow_symlinks)
+    
+    if not smbclient_shutil:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_shutil.copystat(src, dst, follow_symlinks=follow_symlinks)
+
+
+def copymode(src: str, dst: str, follow_symlinks=True):
+    src, src_native = _standardize(src)
+    dst, dst_native = _standardize(dst)
+
+    if src_native and dst_native:
+        return shutil.copytree(src, dst, follow_symlinks=follow_symlinks)
+
+    if not smbclient_shutil:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_shutil.copymode(src, dst, follow_symlinks=follow_symlinks)
+
+
+def copytree(src: str, dst: str, symlinks=False, ignore=None, ignore_dangling_symlinks=False, dirs_exist_ok=False):
+    src, src_native = _standardize(src)
+    dst, dst_native = _standardize(dst)
+
+    if src_native and dst_native:
+        return shutil.copytree(src, dst, symlinks=symlinks, ignore=ignore, ignore_dangling_symlinks=ignore_dangling_symlinks, dirs_exist_ok=dirs_exist_ok)
+
+    if not smbclient_shutil:
+        raise ModuleNotFoundError(f'missing package `smbprotocol`')
+    return smbclient_shutil.copytree(src, dst, symlinks=symlinks, ignore=ignore, ignore_dangling_symlinks=ignore_dangling_symlinks, dirs_exist_ok=dirs_exist_ok)
```

## flexout/flexout.py

 * *Ordering differences only*

```diff
@@ -1,111 +1,111 @@
-from __future__ import annotations
-import sys, re
-import os.path
-import datetime
-from pathlib import Path
-from io import IOBase
-
-if sys.version_info[0:2] < (3, 8):
-    from typing_extensions import Literal
-else:
-    from typing import Literal
-
-from .base import BaseOut
-from .noop import NoopOut
-from .csv import CsvOut
-from .tabulate import TabulateOut
-from .excel import ExcelOut
-
-
-def flexout(out: Path|str|IOBase = None, format: Literal['csv']|Literal['tabulate']|Literal['excel']|type[BaseOut] = None,
-            headers: list[str] = None, append: bool = False, newline: str = None, encoding: str = None, dialect: str = None, timezone: Literal['local']|Literal['utc']|datetime.timezone = None,
-            **kwargs) -> BaseOut:
-    """
-    Write text or tabular data to a flexible, easily configurable output: CSV or Excel file, or tabulated stdout/stderr.
-
-    Parameters:
-
-    - `out`:
-        - `sys.stdout` (or `"stdout"` or `None`) (default): standard output
-        - `sys.stderr` (or `"stderr"`): standard error output
-        - a `str` or a `Path`: path to a file that will be opened and closed by flexout
-        - an `IOBase` (already opened)
-        - `False` for a noop (does nothing)
-
-    - `format`: `"csv"` (or `CsvOut`), `"tabulate"` (or `TabulateOut`, requires package `tabulate`) or `"excel"` (or `ExcelOut`, requires packages `openpyxl` and `defusedxml`).
-        
-    Example 1: export text to stdout or to a file:
-
-    ```
-    with flexout(filename or "stdout") as o:
-        o.file.write("Content")
-    ```
-    
-    Example 2: export tabular data to stdout or to a file:
-
-    ```
-    with flexout(filename or "stdout", headers=["Id", "Word"]) as o:
-        o.append(1, "Hello")
-        o.append(2, "World")
-    ```
-    """    
-    if out == False or out == "noop":
-        return NoopOut()
-
-    if isinstance(format, str):
-        if format == 'csv':
-            format = CsvOut
-        elif format == 'tabulate':
-            format = TabulateOut
-        elif format == 'excel':
-            format = ExcelOut
-
-    if format and not (isinstance(format, type) and issubclass(format, BaseOut)):
-        raise ValueError(f"invalid type for argument \"format\": {type(format).__name__}")
-    
-
-    target: IOBase|str = None
-    
-    if not out or out == "stdout" or out == sys.stdout:
-        target = sys.stdout
-        if format is None:
-            format = TabulateOut if TabulateOut.is_available() else CsvOut
-
-    elif out == "stderr" or out == sys.stderr:
-        target = sys.stderr
-        if format is None:
-            format = TabulateOut if TabulateOut.is_available() else CsvOut
-
-    elif isinstance(out, IOBase):
-        target = out
-        if format is None:
-            format = CsvOut
-
-    elif isinstance(out, (Path,str)):
-        if not isinstance(out, str):
-            target = str(out)
-        else:
-            target = out
-        
-        target = os.path.expanduser(target)
-        if kwargs:
-            target = target.format(**kwargs)
-
-        if format is None:
-            if re.search(r'\.xlsx(?:#[^\.]+)?$', target, re.IGNORECASE):
-                format = ExcelOut
-            else:
-                format = CsvOut
-    else:
-        raise ValueError(f"invalid type for argument \"out\": {type(out).__name__}")
-
-
-    # Prepare other arguments
-    if isinstance(timezone, str):
-        if timezone == 'utc':
-            timezone = datetime.timezone.utc
-            
-    safe_kwargs = {key: value for key, value in kwargs.items() if key not in ['target', 'headers', 'append', 'newline', 'encoding', 'dialect', 'timezone']}
-
-    # Instanciate and return format object
-    return format(target=target, headers=headers, append=append, newline=newline, encoding=encoding, dialect=dialect, timezone=timezone, **safe_kwargs)
+from __future__ import annotations
+import sys, re
+import os.path
+import datetime
+from pathlib import Path
+from io import IOBase
+
+if sys.version_info[0:2] < (3, 8):
+    from typing_extensions import Literal
+else:
+    from typing import Literal
+
+from .base import BaseOut
+from .noop import NoopOut
+from .csv import CsvOut
+from .tabulate import TabulateOut
+from .excel import ExcelOut
+
+
+def flexout(out: Path|str|IOBase = None, format: Literal['csv']|Literal['tabulate']|Literal['excel']|type[BaseOut] = None,
+            headers: list[str] = None, append: bool = False, newline: str = None, encoding: str = None, dialect: str = None, timezone: Literal['local']|Literal['utc']|datetime.timezone = None,
+            **kwargs) -> BaseOut:
+    """
+    Write text or tabular data to a flexible, easily configurable output: CSV or Excel file, or tabulated stdout/stderr.
+
+    Parameters:
+
+    - `out`:
+        - `sys.stdout` (or `"stdout"` or `None`) (default): standard output
+        - `sys.stderr` (or `"stderr"`): standard error output
+        - a `str` or a `Path`: path to a file that will be opened and closed by flexout
+        - an `IOBase` (already opened)
+        - `False` for a noop (does nothing)
+
+    - `format`: `"csv"` (or `CsvOut`), `"tabulate"` (or `TabulateOut`, requires package `tabulate`) or `"excel"` (or `ExcelOut`, requires packages `openpyxl` and `defusedxml`).
+        
+    Example 1: export text to stdout or to a file:
+
+    ```
+    with flexout(filename or "stdout") as o:
+        o.file.write("Content")
+    ```
+    
+    Example 2: export tabular data to stdout or to a file:
+
+    ```
+    with flexout(filename or "stdout", headers=["Id", "Word"]) as o:
+        o.append(1, "Hello")
+        o.append(2, "World")
+    ```
+    """    
+    if out == False or out == "noop":
+        return NoopOut()
+
+    if isinstance(format, str):
+        if format == 'csv':
+            format = CsvOut
+        elif format == 'tabulate':
+            format = TabulateOut
+        elif format == 'excel':
+            format = ExcelOut
+
+    if format and not (isinstance(format, type) and issubclass(format, BaseOut)):
+        raise ValueError(f"invalid type for argument \"format\": {type(format).__name__}")
+    
+
+    target: IOBase|str = None
+    
+    if not out or out == "stdout" or out == sys.stdout:
+        target = sys.stdout
+        if format is None:
+            format = TabulateOut if TabulateOut.is_available() else CsvOut
+
+    elif out == "stderr" or out == sys.stderr:
+        target = sys.stderr
+        if format is None:
+            format = TabulateOut if TabulateOut.is_available() else CsvOut
+
+    elif isinstance(out, IOBase):
+        target = out
+        if format is None:
+            format = CsvOut
+
+    elif isinstance(out, (Path,str)):
+        if not isinstance(out, str):
+            target = str(out)
+        else:
+            target = out
+        
+        target = os.path.expanduser(target)
+        if kwargs:
+            target = target.format(**kwargs)
+
+        if format is None:
+            if re.search(r'\.xlsx(?:#[^\.]+)?$', target, re.IGNORECASE):
+                format = ExcelOut
+            else:
+                format = CsvOut
+    else:
+        raise ValueError(f"invalid type for argument \"out\": {type(out).__name__}")
+
+
+    # Prepare other arguments
+    if isinstance(timezone, str):
+        if timezone == 'utc':
+            timezone = datetime.timezone.utc
+            
+    safe_kwargs = {key: value for key, value in kwargs.items() if key not in ['target', 'headers', 'append', 'newline', 'encoding', 'dialect', 'timezone']}
+
+    # Instanciate and return format object
+    return format(target=target, headers=headers, append=append, newline=newline, encoding=encoding, dialect=dialect, timezone=timezone, **safe_kwargs)
```

## flexout/noop.py

 * *Ordering differences only*

```diff
@@ -1,17 +1,17 @@
-from __future__ import annotations
-from io import IOBase
-from .base import BaseOut
-
-class NoopOut(BaseOut):
-    def __bool__(self):
-        return False
-
-    def __exit__(self, exc_type, exc_val, exc_tb):
-        return
-
-    @property
-    def file(self) -> IOBase|None:
-        return None
-
-    def print_title(self, title: str = None, out = None, level = None):
-        return None
+from __future__ import annotations
+from io import IOBase
+from .base import BaseOut
+
+class NoopOut(BaseOut):
+    def __bool__(self):
+        return False
+
+    def __exit__(self, exc_type, exc_val, exc_tb):
+        return
+
+    @property
+    def file(self) -> IOBase|None:
+        return None
+
+    def print_title(self, title: str = None, out = None, level = None):
+        return None
```

## flexout/tabulate.py

 * *Ordering differences only*

```diff
@@ -1,27 +1,27 @@
-from __future__ import annotations
-from .base import BaseOut
-
-try:
-    from tabulate import tabulate
-    _import_error = None
-except ImportError as err:
-    _import_error = str(err)
-
-
-class TabulateOut(BaseOut):
-    @classmethod
-    def is_available(cls):
-        return _import_error is None
-
-
-    def __init__(self, **kwargs):
-        super().__init__(**kwargs)
-        if not self.is_available():
-            raise ValueError(f"cannot use {self.__class__.__name__}: {_import_error}")
-    
-    
-    def _before_close(self):
-        if not self.rows and not self._headers:
-            return
-        
-        print(tabulate(self.rows, headers=self._headers), file=self.file)
+from __future__ import annotations
+from .base import BaseOut
+
+try:
+    from tabulate import tabulate
+    _import_error = None
+except ImportError as err:
+    _import_error = str(err)
+
+
+class TabulateOut(BaseOut):
+    @classmethod
+    def is_available(cls):
+        return _import_error is None
+
+
+    def __init__(self, **kwargs):
+        super().__init__(**kwargs)
+        if not self.is_available():
+            raise ValueError(f"cannot use {self.__class__.__name__}: {_import_error}")
+    
+    
+    def _before_close(self):
+        if not self.rows and not self._headers:
+            return
+        
+        print(tabulate(self.rows, headers=self._headers), file=self.file)
```

