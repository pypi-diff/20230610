# Comparing `tmp/functime-0.1.5-py3-none-any.whl.zip` & `tmp/functime-0.1.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,41 +1,40 @@
-Zip file size: 43734 bytes, number of entries: 39
--rw-r--r--  2.0 unx       29 b- defN 23-Jun-07 07:27 functime/__init__.py
--rw-r--r--  2.0 unx      117 b- defN 23-Jun-07 07:27 functime/__main__.py
--rw-r--r--  2.0 unx     1136 b- defN 23-Jun-07 07:27 functime/config.py
--rw-r--r--  2.0 unx     5946 b- defN 23-Jun-07 07:27 functime/cross_validation.py
--rw-r--r--  2.0 unx     2407 b- defN 23-Jun-07 07:27 functime/offsets.py
--rw-r--r--  2.0 unx    15901 b- defN 23-Jun-07 07:27 functime/preprocessing.py
--rw-r--r--  2.0 unx     1907 b- defN 23-Jun-07 07:27 functime/ranges.py
--rw-r--r--  2.0 unx     2556 b- defN 23-Jun-07 07:27 functime/stats.py
--rw-r--r--  2.0 unx      155 b- defN 23-Jun-07 07:27 functime/base/__init__.py
--rw-r--r--  2.0 unx     2793 b- defN 23-Jun-07 07:27 functime/base/metric.py
--rw-r--r--  2.0 unx     3111 b- defN 23-Jun-07 07:27 functime/base/model.py
--rw-r--r--  2.0 unx     2237 b- defN 23-Jun-07 07:27 functime/base/transformer.py
--rw-r--r--  2.0 unx       69 b- defN 23-Jun-07 07:27 functime/cli/__init__.py
--rw-r--r--  2.0 unx     1463 b- defN 23-Jun-07 07:27 functime/cli/_deploy.py
--rw-r--r--  2.0 unx     2474 b- defN 23-Jun-07 07:27 functime/cli/_list.py
--rw-r--r--  2.0 unx     3093 b- defN 23-Jun-07 07:27 functime/cli/_login.py
--rw-r--r--  2.0 unx     2169 b- defN 23-Jun-07 07:27 functime/cli/_usage.py
--rw-r--r--  2.0 unx     1328 b- defN 23-Jun-07 07:27 functime/cli/entrypoint.py
--rw-r--r--  2.0 unx      139 b- defN 23-Jun-07 07:27 functime/cli/utils.py
--rw-r--r--  2.0 unx      285 b- defN 23-Jun-07 07:27 functime/feature_extraction/__init__.py
--rw-r--r--  2.0 unx     3507 b- defN 23-Jun-07 07:27 functime/feature_extraction/calendar.py
--rw-r--r--  2.0 unx      421 b- defN 23-Jun-07 07:27 functime/forecasting/__init__.py
--rw-r--r--  2.0 unx     9770 b- defN 23-Jun-07 07:27 functime/forecasting/auto.py
--rw-r--r--  2.0 unx     4929 b- defN 23-Jun-07 07:27 functime/forecasting/base.py
--rw-r--r--  2.0 unx     3565 b- defN 23-Jun-07 07:27 functime/forecasting/forecasters.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 07:27 functime/io/__init__.py
--rw-r--r--  2.0 unx      768 b- defN 23-Jun-07 07:27 functime/io/auth.py
--rw-r--r--  2.0 unx     3057 b- defN 23-Jun-07 07:27 functime/io/client.py
--rw-r--r--  2.0 unx      494 b- defN 23-Jun-07 07:27 functime/io/serialize.py
--rw-r--r--  2.0 unx      202 b- defN 23-Jun-07 07:27 functime/io/utils.py
--rw-r--r--  2.0 unx      270 b- defN 23-Jun-07 07:27 functime/metrics/__init__.py
--rw-r--r--  2.0 unx     6939 b- defN 23-Jun-07 07:27 functime/metrics/point.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 07:27 functime/metrics/probabilistic.py
--rw-r--r--  2.0 unx    34522 b- defN 23-Jun-07 07:27 functime-0.1.5.dist-info/LICENSE
--rw-r--r--  2.0 unx     7712 b- defN 23-Jun-07 07:27 functime-0.1.5.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-07 07:27 functime-0.1.5.dist-info/WHEEL
--rw-r--r--  2.0 unx       52 b- defN 23-Jun-07 07:27 functime-0.1.5.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        9 b- defN 23-Jun-07 07:27 functime-0.1.5.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3166 b- defN 23-Jun-07 07:27 functime-0.1.5.dist-info/RECORD
-39 files, 128790 bytes uncompressed, 38706 bytes compressed:  69.9%
+Zip file size: 43890 bytes, number of entries: 38
+-rw-r--r--  2.0 unx       29 b- defN 23-Jun-10 02:32 functime/__init__.py
+-rw-r--r--  2.0 unx      117 b- defN 23-Jun-10 02:32 functime/__main__.py
+-rw-r--r--  2.0 unx     1141 b- defN 23-Jun-10 02:32 functime/config.py
+-rw-r--r--  2.0 unx     6010 b- defN 23-Jun-10 02:32 functime/cross_validation.py
+-rw-r--r--  2.0 unx     2059 b- defN 23-Jun-10 02:32 functime/offsets.py
+-rw-r--r--  2.0 unx    14946 b- defN 23-Jun-10 02:32 functime/preprocessing.py
+-rw-r--r--  2.0 unx     1909 b- defN 23-Jun-10 02:32 functime/ranges.py
+-rw-r--r--  2.0 unx     2556 b- defN 23-Jun-10 02:32 functime/stats.py
+-rw-r--r--  2.0 unx      155 b- defN 23-Jun-10 02:32 functime/base/__init__.py
+-rw-r--r--  2.0 unx     2793 b- defN 23-Jun-10 02:32 functime/base/metric.py
+-rw-r--r--  2.0 unx     3111 b- defN 23-Jun-10 02:32 functime/base/model.py
+-rw-r--r--  2.0 unx     2237 b- defN 23-Jun-10 02:32 functime/base/transformer.py
+-rw-r--r--  2.0 unx       81 b- defN 23-Jun-10 02:32 functime/cli/__init__.py
+-rw-r--r--  2.0 unx      139 b- defN 23-Jun-10 02:32 functime/cli/_styling.py
+-rw-r--r--  2.0 unx     1463 b- defN 23-Jun-10 02:32 functime/cli/deploy.py
+-rw-r--r--  2.0 unx     1438 b- defN 23-Jun-10 02:32 functime/cli/entrypoint.py
+-rw-r--r--  2.0 unx     2474 b- defN 23-Jun-10 02:32 functime/cli/list.py
+-rw-r--r--  2.0 unx     3093 b- defN 23-Jun-10 02:32 functime/cli/login.py
+-rw-r--r--  2.0 unx     1112 b- defN 23-Jun-10 02:32 functime/cli/token.py
+-rw-r--r--  2.0 unx     2172 b- defN 23-Jun-10 02:32 functime/cli/usage.py
+-rw-r--r--  2.0 unx      285 b- defN 23-Jun-10 02:32 functime/feature_extraction/__init__.py
+-rw-r--r--  2.0 unx     3507 b- defN 23-Jun-10 02:32 functime/feature_extraction/calendar.py
+-rw-r--r--  2.0 unx      421 b- defN 23-Jun-10 02:32 functime/forecasting/__init__.py
+-rw-r--r--  2.0 unx     4989 b- defN 23-Jun-10 02:32 functime/forecasting/_base.py
+-rw-r--r--  2.0 unx     9921 b- defN 23-Jun-10 02:32 functime/forecasting/auto.py
+-rw-r--r--  2.0 unx     3788 b- defN 23-Jun-10 02:32 functime/forecasting/forecasters.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-10 02:32 functime/io/__init__.py
+-rw-r--r--  2.0 unx      494 b- defN 23-Jun-10 02:32 functime/io/_serialize.py
+-rw-r--r--  2.0 unx     5664 b- defN 23-Jun-10 02:32 functime/io/client.py
+-rw-r--r--  2.0 unx      229 b- defN 23-Jun-10 02:32 functime/metrics/__init__.py
+-rw-r--r--  2.0 unx     6822 b- defN 23-Jun-10 02:32 functime/metrics/point.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-10 02:32 functime/metrics/probabilistic.py
+-rw-r--r--  2.0 unx    34523 b- defN 23-Jun-10 02:32 functime-0.1.6.dist-info/LICENSE
+-rw-r--r--  2.0 unx     7607 b- defN 23-Jun-10 02:32 functime-0.1.6.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-10 02:32 functime-0.1.6.dist-info/WHEEL
+-rw-r--r--  2.0 unx       52 b- defN 23-Jun-10 02:32 functime-0.1.6.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        9 b- defN 23-Jun-10 02:32 functime-0.1.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3094 b- defN 23-Jun-10 02:32 functime-0.1.6.dist-info/RECORD
+38 files, 130532 bytes uncompressed, 38972 bytes compressed:  70.1%
```

## zipnote {}

```diff
@@ -33,86 +33,83 @@
 
 Filename: functime/base/transformer.py
 Comment: 
 
 Filename: functime/cli/__init__.py
 Comment: 
 
-Filename: functime/cli/_deploy.py
+Filename: functime/cli/_styling.py
 Comment: 
 
-Filename: functime/cli/_list.py
+Filename: functime/cli/deploy.py
 Comment: 
 
-Filename: functime/cli/_login.py
+Filename: functime/cli/entrypoint.py
 Comment: 
 
-Filename: functime/cli/_usage.py
+Filename: functime/cli/list.py
 Comment: 
 
-Filename: functime/cli/entrypoint.py
+Filename: functime/cli/login.py
 Comment: 
 
-Filename: functime/cli/utils.py
+Filename: functime/cli/token.py
+Comment: 
+
+Filename: functime/cli/usage.py
 Comment: 
 
 Filename: functime/feature_extraction/__init__.py
 Comment: 
 
 Filename: functime/feature_extraction/calendar.py
 Comment: 
 
 Filename: functime/forecasting/__init__.py
 Comment: 
 
-Filename: functime/forecasting/auto.py
+Filename: functime/forecasting/_base.py
 Comment: 
 
-Filename: functime/forecasting/base.py
+Filename: functime/forecasting/auto.py
 Comment: 
 
 Filename: functime/forecasting/forecasters.py
 Comment: 
 
 Filename: functime/io/__init__.py
 Comment: 
 
-Filename: functime/io/auth.py
+Filename: functime/io/_serialize.py
 Comment: 
 
 Filename: functime/io/client.py
 Comment: 
 
-Filename: functime/io/serialize.py
-Comment: 
-
-Filename: functime/io/utils.py
-Comment: 
-
 Filename: functime/metrics/__init__.py
 Comment: 
 
 Filename: functime/metrics/point.py
 Comment: 
 
 Filename: functime/metrics/probabilistic.py
 Comment: 
 
-Filename: functime-0.1.5.dist-info/LICENSE
+Filename: functime-0.1.6.dist-info/LICENSE
 Comment: 
 
-Filename: functime-0.1.5.dist-info/METADATA
+Filename: functime-0.1.6.dist-info/METADATA
 Comment: 
 
-Filename: functime-0.1.5.dist-info/WHEEL
+Filename: functime-0.1.6.dist-info/WHEEL
 Comment: 
 
-Filename: functime-0.1.5.dist-info/entry_points.txt
+Filename: functime-0.1.6.dist-info/entry_points.txt
 Comment: 
 
-Filename: functime-0.1.5.dist-info/top_level.txt
+Filename: functime-0.1.6.dist-info/top_level.txt
 Comment: 
 
-Filename: functime-0.1.5.dist-info/RECORD
+Filename: functime-0.1.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## functime/config.py

```diff
@@ -5,15 +5,15 @@
 
 USER_CONFIG_PATH: str = os.environ.get("FUNCTIME_CONFIG_PATH") or os.path.expanduser(
     "~/.functime.toml"
 )
 
 FUNCTIME_SERVER_URL = (
     os.environ.get("FUNCTIME_SERVER_URL")
-    or "https://functional-analytics--functime-api-endpoint.modal.run"
+    or "https://functional-analytics--prod-functime-api-endpoint.modal.run"
 )
 AUTH0_DOMAIN = "functime.us.auth0.com"
 AUTH0_CLIENT_ID = "8NNUOaC3yI1PBdpsZdvxBwuKvVq03RpK"
 AUTH_FLOW_TIMEOUT = 120
 API_CALL_TIMEOUT = 60
 API_CALL_MAX_RETRIES = 3
```

## functime/cross_validation.py

```diff
@@ -42,15 +42,15 @@
         return y_train, y_test, X_train, X_test
 
     fn = get_y_split if X_splits is None else get_X_y_split
     return fn
 
 
 def train_test_split(test_size: int):
-    """Return train/test splits.
+    """Return a time-ordered train set and test set given `test_size`.
 
     Parameters
     ----------
     test_size : int
         Number of test samples.
 
     Returns
@@ -58,19 +58,21 @@
     splitter : Callable[pl.LazyFrame, pl.LazyFrame]
         Function that takes a panel LazyFrame and returns a LazyFrame of train / test splits.
     """
 
     def split(X: pl.LazyFrame) -> pl.LazyFrame:
         X = X.lazy()  # Defensive
         train_split = (
-            X.groupby(X.columns[0]).agg(pl.all().slice(0, pl.count() - test_size))
+            X.groupby(X.columns[0])
+            .agg(pl.all().slice(0, pl.count() - test_size))
             .explode(pl.all().exclude(X.columns[0]))
         )
         test_split = (
-            X.groupby(X.columns[0]).agg(pl.all().slice(-1 * test_size, test_size))
+            X.groupby(X.columns[0])
+            .agg(pl.all().slice(-1 * test_size, test_size))
             .explode(pl.all().exclude(X.columns[0]))
         )
         return train_split, test_split
 
     return split
```

## functime/offsets.py

```diff
@@ -12,15 +12,15 @@
 # 1mo (1 calendar month)
 # 1y (1 calendar year)
 # 1i (1 index count)
 
 OFFSET_ALIASES = {"s", "m", "h", "d", "w", "mo", "y", "i"}
 
 
-def strip_freq_alias(freq: str) -> Tuple[int, str]:
+def _strip_freq_alias(freq: str) -> Tuple[int, str]:
     """Return (index count, offset string) given Polars offset alias.
 
     For example, `freq = "3mo"` returns `(3, "mo")`.
     """
     freq = freq.lower()
     for x in OFFSET_ALIASES:
         if freq.endswith(x):
@@ -31,27 +31,16 @@
 
 def freq_to_sp(freq: str, include_dec: bool = False) -> Union[List[int], List[float]]:
     """Return seasonal periods given offset alias.
 
     Parameters
     ----------
     freq : str
-        Offset alias as dictated by the following string language:
-        - 1s    (1 second)
-        - 1m    (1 minute)
-        - 1h    (1 hour)
-        - 1d    (1 day)
-        - 1w    (1 week)
-        - 1mo   (1 calendar month)
-        - 1y    (1 calendar year)
-
-        Note: represent quarterly offset as "3mo" and
-        half-hourly offset as "30m".
-
-    include_dec : bool, default=False
+        Offset alias.
+    include_dec : bool
         If True, return floating point seasonal periods.
         Otherwise, all seasonal periods are rounded down
         to the nearest integer.
 
     Returns
     -------
     sp : list of int, list of float
@@ -69,15 +58,15 @@
         # 365.25/7 = 52.18 on average, allowing
         # for a leap year every fourth year
         "w": [52.18],
         "y": [1.0],
         "mo": [12.0],
         "3mo": [4.0],
     }
-    n, alias = strip_freq_alias(freq)
+    n, alias = _strip_freq_alias(freq)
     alias = (
         f"{n}{alias}"
         if ((alias.endswith("m") and n == 30) or (alias.endswith("mo") and n == 3))
         else alias
     )
 
     try:
```

## functime/preprocessing.py

```diff
@@ -1,85 +1,53 @@
-from typing import List, Mapping, Union
+from typing import List, Union
 
 import polars as pl
 from scipy.stats import boxcox_normmax
 from typing_extensions import Literal
 
 from functime.base import transformer
 from functime.base.model import ModelState
-from functime.offsets import strip_freq_alias
+from functime.offsets import _strip_freq_alias
 
 PL_FLOAT_DTYPES = [pl.Float32, pl.Float64]
 PL_INT_DTYPES = [pl.Int8, pl.Int16, pl.Int32, pl.Int64]
 PL_NUMERIC_DTYPES = [*PL_INT_DTYPES, *PL_FLOAT_DTYPES]
 PL_FLOAT_COLS = pl.col(PL_FLOAT_DTYPES)
 PL_INT_COLS = pl.col(PL_INT_DTYPES)
 
 
 def PL_NUMERIC_COLS(*exclude):
     return pl.col(PL_NUMERIC_DTYPES).exclude(exclude)
 
 
-def cache_categoricals(X: pl.DataFrame):
-    return X.with_columns(pl.col(pl.Categorical).cast(pl.Utf8).cast(pl.Categorical))
-
-
-def resample_panel(
-    X: pl.DataFrame, freq: str, agg_method: str, impute_method: Union[str, int, float]
-) -> pl.DataFrame:
-    entity_col, time_col, target_col = X.columns
-    agg_exprs = {
-        "sum": pl.sum(target_col),
-        "mean": pl.mean(target_col),
-        "median": pl.median(target_col),
-    }
-    X_new = (
-        # Defensive resampling
-        X.lazy()
-        .groupby_dynamic(time_col, every=freq, by=entity_col)
-        .agg(agg_exprs[agg_method])
-        # Must defensive sort columns otherwise time_col and target_col
-        # positions are incorrectly swapped in lazy
-        .select([entity_col, time_col, target_col])
-        # Reindex full (entity, time) index
-        .pipe(reindex_panel(freq=freq, sort=True))
-        # Impute gaps after reindex
-        .pipe(impute(impute_method))
-        # Defensive fill null with 0 for impute method `ffill`
-        .fill_null(0)
-        .collect()
-    )
-    return X_new
-
-
-def coerce_panel(y0: pl.DataFrame):
-    """Coerces panel `y1` to match `y0`'s column names, datatypes, and (entity, time) index."""
-
-    def transform(y1: pl.DataFrame):
-        entity_col, time_col = y0.columns[:2]
-        idx = y0.select([entity_col, time_col]).lazy()
-        y1_new = (
-            y1.lazy()
-            .rename({col0: col1 for col0, col1 in zip(y0.columns, y1.columns)})
-            .select([pl.col(col).cast(dtype) for col, dtype in y0.schema.items()])
-            .pipe(lambda df: idx.join(df, on=[entity_col, time_col], how="left"))
-        )
-        return y1_new
-
-    return transform
-
-
 @transformer
-def coerce_dtypes(schema: Mapping[str, pl.DataType]):
+def resample(freq: str, agg_method: str, impute_method: Union[str, int, float]):
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
-        X_new = X.with_columns(
-            [pl.col(col).cast(dtype) for col, dtype in schema.items()]
+        entity_col, time_col, target_col = X.columns
+        agg_exprs = {
+            "sum": pl.sum(target_col),
+            "mean": pl.mean(target_col),
+            "median": pl.median(target_col),
+        }
+        X_new = (
+            # Defensive resampling
+            X.lazy()
+            .groupby_dynamic(time_col, every=freq, by=entity_col)
+            .agg(agg_exprs[agg_method])
+            # Must defensive sort columns otherwise time_col and target_col
+            # positions are incorrectly swapped in lazy
+            .select([entity_col, time_col, target_col])
+            # Reindex full (entity, time) index
+            .pipe(reindex_panel(freq=freq, sort=True))
+            # Impute gaps after reindex
+            .pipe(impute(impute_method))
+            # Defensive fill null with 0 for impute method `ffill`
+            .fill_null(0)
         )
-        artifacts = {"X_new": X_new}
-        return artifacts
+        return X_new
 
     return transform
 
 
 @transformer
 def lag(lags: List[int]):
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
@@ -118,15 +86,15 @@
 def roll(
     window_sizes: List[int],
     stats: List[Literal["mean", "min", "max", "mlm", "sum", "std", "cv"]],
     freq: str,
 ):
     def transform(X: pl.LazyFrame) -> pl.LazyFrame:
         entity_col, time_col = X.columns[:2]
-        offset_n, offset_alias = strip_freq_alias(freq)
+        offset_n, offset_alias = _strip_freq_alias(freq)
         values = pl.all().exclude([entity_col, time_col])
         stat_exprs = {
             "mean": lambda w: values.mean().suffix(f"__rolling_mean_{w}"),
             "min": lambda w: values.min().suffix(f"__rolling_min_{w}"),
             "max": lambda w: values.max().suffix(f"__rolling_max_{w}"),
             "mlm": lambda w: (values.max() - values.min()).suffix(f"__rolling_mlm_{w}"),
             "sum": lambda w: values.sum().suffix(f"__rolling_sum_{w}"),
```

## functime/ranges.py

```diff
@@ -1,12 +1,12 @@
 from typing import Optional
 
 import polars as pl
 
-from functime.offsets import strip_freq_alias
+from functime.offsets import _strip_freq_alias
 
 
 def make_future_ranges(
     time_col: str,
     cutoffs: pl.DataFrame,
     fh: int,
     freq: Optional[str] = None,
@@ -27,15 +27,15 @@
                         step=int(freq[:-1]),
                         eager=False,
                     ).alias(time_col),
                 ]
             )
         else:
             time_unit = time_unit or "us"
-            offset_n, offset_alias = strip_freq_alias(freq)
+            offset_n, offset_alias = _strip_freq_alias(freq)
             # Make date ranges
             future_ranges = cutoffs.select(
                 [
                     pl.col(entity_col),
                     pl.date_range(
                         pl.col("low"),
                         pl.col("low")
```

## functime/base/__init__.py

 * *Ordering differences only*

```diff
@@ -1,4 +1,4 @@
-from functime.base.transformer import Transformer, transformer
 from functime.base.metric import metric
+from functime.base.transformer import Transformer, transformer
 
 __all__ = ["Transformer", "transformer", "metric"]
```

## functime/cli/__init__.py

```diff
@@ -1,3 +1,3 @@
-from .entrypoint import entrypoint_cli
+from functime.cli.entrypoint import entrypoint_cli
 
 __all__ = ["entrypoint_cli"]
```

## functime/cli/entrypoint.py

```diff
@@ -1,18 +1,19 @@
 import typer
 
-from ._deploy import deploy_cli
-from ._list import list_cli
-from ._login import login_cli
-from ._usage import usage_cli
+from functime.cli.deploy import deploy_cli
+from functime.cli.list import list_cli
+from functime.cli.login import login_cli
+from functime.cli.token import token_cli
+from functime.cli.usage import usage_cli
 
 
 def version_callback(value: bool):
     if value:
-        __version__ = "0.1.5"
+        __version__ = "0.1.6"
 
         typer.echo(f"functime version: {__version__}")
         raise typer.Exit()
 
 
 entrypoint_cli_typer = typer.Typer(
     no_args_is_help=True,
@@ -31,17 +32,16 @@
     ctx: typer.Context,
     version: bool = typer.Option(None, "--version", callback=version_callback),
 ):
     pass
 
 
 entrypoint_cli_typer.add_typer(deploy_cli)
-entrypoint_cli_typer.command("login", help="Authenticate and login with Auth0.")(
-    login_cli
-)
+entrypoint_cli_typer.add_typer(token_cli)
+entrypoint_cli_typer.command("login", help="Authenticate and login.")(login_cli)
 entrypoint_cli_typer.command("list", help="List deployed estimators.")(list_cli)
 entrypoint_cli_typer.command("usage", help="View your usage.")(usage_cli)
 entrypoint_cli = typer.main.get_command(entrypoint_cli_typer)
 entrypoint_cli.list_commands(None)  # type: ignore
 
 if __name__ == "__main__":
     # this module is only called from tests, otherwise the parent package __init__.py is used as the entrypoint
```

## functime/forecasting/__init__.py

```diff
@@ -2,15 +2,15 @@
     AutoElasticNet,
     AutoKNN,
     AutoLasso,
     AutoLightGBM,
     AutoLinearModel,
     AutoRidge,
 )
-from .forecasters import KNN, ElasticNet, Lasso, LinearModel, Ridge, LightGBM
+from .forecasters import KNN, ElasticNet, Lasso, LightGBM, LinearModel, Ridge
 
 __all__ = [
     "AutoElasticNet",
     "AutoKNN",
     "AutoLasso",
     "AutoLightGBM",
     "AutoLinearModel",
```

## functime/forecasting/auto.py

```diff
@@ -1,10 +1,10 @@
 from typing import Any, Literal, Mapping, Optional
 
-from .base import ForecasterClient
+from ._base import ForecasterClient
 
 FORECAST_STRATEGIES = Optional[Literal["direct", "recursive", "ensemble"]]
 
 
 class BaseAutoForecaster(ForecasterClient):
     def __init__(
         self,
@@ -34,14 +34,20 @@
             time_budget=time_budget,
             search_space=search_space,
             points_to_evaluate=points_to_evaluate,
             num_samples=num_samples,
             **kwargs,
         )
 
+    @property
+    def best_params(self):
+        if not self.is_fitted:
+            return None
+        return self._extra_params.get("best_params")
+
 
 class AutoElasticNet(BaseAutoForecaster):
     """ElasticNet forecaster with automated hyperparameter tuning.
 
     Parameters
     ----------
     freq : str
```

## functime/forecasting/forecasters.py

```diff
@@ -1,33 +1,35 @@
 from typing import Literal, Optional, Union
 
-from .base import ForecasterClient
+from ._base import ForecasterClient
 
 FORECAST_STRATEGIES = Optional[Literal["direct", "recursive", "ensemble"]]
 
 
 class BaseForecaster(ForecasterClient):
     def __init__(
         self,
-        lags: int,
         freq: Union[str, None],
+        lags: int,
         max_horizons: Optional[int] = None,
         strategy: FORECAST_STRATEGIES = None,
         **kwargs,
     ):
         super().__init__(
             freq=freq, lags=lags, max_horizons=max_horizons, strategy=strategy, **kwargs
         )
 
 
 class ElasticNet(BaseForecaster):
     """ElasticNet forecaster.
 
     Parameters
     ----------
+    freq : str
+        Offset alias.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -38,14 +40,16 @@
 
 
 class KNN(BaseForecaster):
     """K-nearest neighbors forecaster.
 
     Parameters
     ----------
+    freq : str
+        Offset alias.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -56,14 +60,16 @@
 
 
 class Lasso(BaseForecaster):
     """LASSO regression forecaster.
 
     Parameters
     ----------
+    freq : str
+        Offset alias.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -74,14 +80,16 @@
 
 
 class LightGBM(BaseForecaster):
     """LightGBM forecaster.
 
     Parameters
     ----------
+    freq : str
+        Offset alias.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -92,14 +100,16 @@
 
 
 class LinearModel(BaseForecaster):
     """Linear autoregressive forecaster.
 
     Parameters
     ----------
+    freq : str
+        Offset alias.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
@@ -110,14 +120,16 @@
 
 
 class Ridge(BaseForecaster):
     """Ridge regression forecaster.
 
     Parameters
     ----------
+    freq : str
+        Offset alias.
     lags : int
         Number of lagged target variables.
     max_horizons: Optional[int]
         Maximum number of horizons to predict directly.
         Only applied if `strategy` equals "direct" or "ensemble".
     strategy : Optional[str]
         Forecasting strategy. Currently supports "recursive", "direct",
```

## functime/io/client.py

```diff
@@ -1,64 +1,79 @@
 import time
 from typing import Mapping, Optional
 
 import httpx
+import typer
 from rich.console import Console
 
-from functime.config import API_CALL_MAX_RETRIES, API_CALL_TIMEOUT, FUNCTIME_SERVER_URL
-from functime.io.auth import get_access_token
+from functime.config import (
+    API_CALL_MAX_RETRIES,
+    API_CALL_TIMEOUT,
+    FUNCTIME_SERVER_URL,
+    USER_CONFIG_PATH,
+    _read_user_config,
+    _store_user_config,
+)
 
 
 class FunctimeH2Client:
     def __init__(
         self,
         n_retries: Optional[int] = None,
         timeout: Optional[int] = None,
         msg: Optional[str] = None,
+        credentials: Optional[Mapping[str, str]] = None,
     ):
+        self.console = Console()
         self.client = httpx.Client(base_url=FUNCTIME_SERVER_URL, http2=True)
         self.n_retries = n_retries or API_CALL_MAX_RETRIES
         self.timeout = timeout or API_CALL_TIMEOUT
-        self.token = get_access_token()
-        self.console = Console()
+        credentials = credentials or {}
+        self.auth_token = None
+        self.token_id = credentials.get("token_id")
+        self.token_secret = credentials.get("token_secret")
         self.loading_msg = msg or "Loading"
 
     def __enter__(self):
         self.client.__enter__()
+        self._get_access_token(
+            token_id=self.token_id,
+            token_secret=self.token_secret,
+        )
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.client.__exit__(exc_type, exc_value, traceback)
 
     def get(
         self,
         endpoint: str,
         headers: Optional[Mapping[str, str]] = None,
         **kwargs,
-    ):
+    ) -> httpx.Response:
         return self.request("GET", endpoint, headers=headers, **kwargs)
 
     def post(
         self,
         endpoint: str,
         headers: Optional[Mapping[str, str]] = None,
         **kwargs,
-    ):
+    ) -> httpx.Response:
         return self.request("POST", endpoint, headers=headers, **kwargs)
 
     def request(
         self,
         method: str,
         endpoint: str,
         headers: Optional[Mapping[str, str]] = None,
         **kwargs,
-    ):
+    ) -> httpx.Response:
         for retry in range(self.n_retries):
             headers = headers or {}
-            headers.update({"Authorization": f"Bearer {self.token}"})
+            headers.update({"Authorization": f"Bearer {self.auth_token}"})
             try:
                 with self.console.status(
                     f"[blue]{self.loading_msg}...[/blue]", spinner="dots"
                 ):
                     response = self.client.request(
                         method=method,
                         url=endpoint,
@@ -73,18 +88,70 @@
                 with self.console.status(
                     f"[yellow]Retrying in {timeout} seconds...[/yellow]", spinner="dots"
                 ):
                     time.sleep(timeout)
             except httpx.HTTPError as e:
                 if e.response.status_code == 401:
                     with self.console.status(
-                        "[yellow]Retrying with new token...[/yellow]", spinner="dots"
+                        "[blue]Re-authenticating...[/blue]", spinner="dots"
                     ):
-                        self.token = get_access_token(use_cache=False)
+                        self._get_access_token(force_refresh=True)
                     continue
                 if e.response.status_code == 400:
                     detail = e.response.json().get("detail")
                     raise ValueError(detail) from e
                 self.console.print(f"[red]{e}[/red]")
                 raise e
 
         raise httpx.HTTPError(f"Failed to authenticate after {self.n_retries} tries.")
+
+    def _get_access_token(
+        self,
+        *,
+        token_id: Optional[str] = None,
+        token_secret: Optional[str] = None,
+        force_refresh: bool = False,
+    ) -> None:
+        """Get access token from server.
+
+        Behavior
+        --------
+        - If either `token_id` or `token_secret` is not provided, then they are read from the config file.
+        - If both are provided, then they are used instead of the config file.
+        - If `force_refresh` is True, then the token is refreshed even if it is cached.
+        """
+        use_config = token_id is None or token_secret is None
+        if use_config:
+            config = _read_user_config()
+            if not force_refresh and "auth_token" in config:
+                # Use cached token when not forcing refresh
+                self.auth_token = config["auth_token"]
+                return
+            token_id, token_secret = config.get("token_id"), config.get("token_secret")
+        # Here the credentials should be set.
+        # If not then something is wrong.
+        if token_id is None or token_secret is None:
+            self.console.print(
+                f"\n[red]Missing credentials{f' in {USER_CONFIG_PATH}' if use_config else ''}. Please login first or set your tokens.[/red]"
+            )
+            raise typer.Exit(code=1)
+
+        try:
+            response = self.client.post(
+                "/token",
+                headers={"Content-Type": "application/x-www-form-urlencoded"},
+                data={
+                    "username": token_id,
+                    "password": token_secret,
+                },
+                timeout=self.timeout,
+            )
+            response.raise_for_status()
+        except httpx.HTTPStatusError as e:
+            if e.response.status_code == 401:
+                self.console.print(
+                    "\n[red]Invalid token credentials. Please login again.[/red]"
+                    "\n[red]If this error persists please contact us at [/red][magenta]team@functime.ai[/magenta]"
+                )
+            raise
+        self.auth_token = response.json()["access_token"]
+        _store_user_config({"auth_token": self.auth_token})
```

## functime/metrics/__init__.py

```diff
@@ -1,18 +1,8 @@
-from .point import (
-    mae,
-    mape,
-    mase,
-    mse,
-    overforecast,
-    rmse,
-    rmsse,
-    smape,
-    underforecast,
-)
+from .point import mae, mape, mase, mse, overforecast, rmse, rmsse, smape, underforecast
 
 __all__ = [
     "mae",
     "mape",
     "mase",
     "mse",
     "rmse",
```

## functime/metrics/point.py

```diff
@@ -1,11 +1,7 @@
-from dataclasses import dataclass
-from functools import partial, reduce
-from typing import Callable, List, Optional
-
 import numpy as np
 import polars as pl
 
 from functime.base import metric
 
 
 def _score(y_true, y_pred, formula: pl.Expr, alias: str):
```

## Comparing `functime/cli/_deploy.py` & `functime/cli/deploy.py`

 * *Files identical despite different names*

## Comparing `functime/cli/_list.py` & `functime/cli/list.py`

 * *Files identical despite different names*

## Comparing `functime/cli/_login.py` & `functime/cli/login.py`

 * *Files identical despite different names*

## Comparing `functime/cli/_usage.py` & `functime/cli/usage.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Union
 
 from rich.console import Console
 from rich.table import Table
 
-from functime.cli.utils import apply_color, format_url
+from functime.cli._styling import apply_color, format_url
 from functime.io.client import FunctimeH2Client
 
 
 def _get_usage_response(**params):
     with FunctimeH2Client() as client:
         response = client.get(
             "/usage",
```

## Comparing `functime/forecasting/base.py` & `functime/forecasting/_base.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from io import BytesIO
 from typing import Literal, Optional, Union
 
 import pandas as pd
 import polars as pl
 import pyarrow as pa
 
+from functime.io._serialize import deserialize_bytes, serialize_bytes
 from functime.io.client import FunctimeH2Client
-from functime.io.serialize import deserialize_bytes, serialize_bytes
 
 FORECAST_STRATEGIES = Optional[Literal["direct", "recursive", "naive"]]
 DF_TYPE = Union[pl.LazyFrame, pl.DataFrame, pa.Table, pd.DataFrame]
 SUPPORTED_FORECASTERS = [
     "auto_elastic_net",
     "auto_knn",
     "auto_lasso",
@@ -77,14 +77,15 @@
             X=X,
             model_id=self.model,
             msg="Running fit",
             **{k: v for k, v in self.model_kwargs.items() if v is not None},
         )
         response_json = response.json()
         self._stub_id = response_json["estimator_id"]
+        self._extra_params = response_json["extra_params"]
         return self
 
     def predict(self, fh: int, X: Optional[DF_TYPE] = None) -> pl.DataFrame:
         """Predict using the forecaster."""
         if not self.is_fitted:
             raise RuntimeError("Forecaster has not been fitted yet.")
         if X is not None:
```

## Comparing `functime-0.1.5.dist-info/LICENSE` & `functime-0.1.6.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -654,8 +654,8 @@
 of the code.  There are many ways you could offer source, and different
 solutions will be better for different programs; see section 13 for the
 specific requirements.
 
   You should also get your employer (if you work as a programmer) or school,
 if any, to sign a "copyright disclaimer" for the program, if necessary.
 For more information on this, and how to apply and follow the GNU AGPL, see
-<https://www.gnu.org/licenses/>.
+<https://www.gnu.org/licenses/>.
```

## Comparing `functime-0.1.5.dist-info/METADATA` & `functime-0.1.6.dist-info/METADATA`

 * *Files 15% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 Metadata-Version: 2.1
 Name: functime
-Version: 0.1.5
-Summary: The easiest way to run and deploy time-series ML (forecasting and classification) in the Cloud.
-Author-email: Chris Lo <chris@functime.ai>, Daryl Lim <daryl@functime.ai>
-Project-URL: Homepage, https://docs.functime.ai
+Version: 0.1.6
+Summary: The easiest way to run and scale time-series machine learning in the Cloud.
+Author-email: functime Team <team@functime.ai>, Chris Lo <chris@functime.ai>, Daryl Lim <daryl@functime.ai>
+Project-URL: Homepage, https://github.com/indexhub-ai/functime
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Science/Research
 Classifier: Intended Audience :: Developers
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Topic :: Scientific/Engineering
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
@@ -45,47 +45,48 @@
 ![functime](https://github.com/indexhub-ai/functime/raw/main/static/images/functime_banner.png)
 
 [![Python](https://img.shields.io/pypi/pyversions/functime)](https://pypi.org/project/functime/)
 [![PyPi](https://img.shields.io/pypi/v/functime?color=blue)](https://pypi.org/project/functime/)
 [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
 [![GitHub Publish to PyPI](https://github.com/indexhub-ai/functime/actions/workflows/publish.yml/badge.svg)](https://github.com/indexhub-ai/functime/actions/workflows/publish.yml)
 [![GitHub Build Docs](https://github.com/indexhub-ai/functime/actions/workflows/docs.yml/badge.svg)](https://github.com/indexhub-ai/functime/actions/workflows/docs.yml)
+[![GitHub Run Quickstart](https://github.com/indexhub-ai/functime/actions/workflows/quickstart.yml/badge.svg)](https://github.com/indexhub-ai/functime/actions/workflows/quickstart.yml)
 
 </div>
 
 ---
 **functime** is a powerful and easy-to-use [Cloud service](https://functime.ai) for AutoML forecasting and time-series embeddings.
 The `functime` [Python package](https://pypi.org/project/functime/) provides a scikit-learn API and command-line interface to interact with **functime Cloud**.
 
 Want to use **functime** for seamless time-series analytics across your data team?
 Looking for fully-managed production-grade AI/ML forecasting and time-series search?
 Book a [15 minute discovery call](https://calendly.com/functime-indexhub) to learn more about functime's Team / Enterprise plans.
 
 ## Highlights
 - **Fast:** Forecast 100,000 time series in seconds *on your laptop*
-- **Efficient:** Embarrassingly parallel feature engineering for time-series using [`Polars`](https://www.pola.rs/)
-- **Battle-tested:** Automated machine learning algorithms that deliver real business impact and win competitions
-- Every forecaster supports **exogenous features**
+- **Efficient:** Embarrassingly parallel [feature engineering](https://docs.functime.ai/ref/preprocessing/) for time-series using [`Polars`](https://www.pola.rs/)
+- **Battle-tested:** Machine learning algorithms that deliver real business impact and win competitions
+- **Exogenous features:** supported by every forecaster
 - **Backtesting** with expanding window and sliding window splitters
-- Automated lags and **hyperparameter tuning** using [`FLAML`](https://github.com/microsoft/FLAML)
+- **AutoML**: Automated lags and hyperparameter tuning using [`FLAML`](https://github.com/microsoft/FLAML)
 - Utilities to add calendar effects, special events (e.g. holidays), weather patterns, and economic trends
 - Supports recursive, direct, and ensemble forecast strategies
 
-View detailed [list of features](https://docs.functime.ai/features/) including forecasters, preprocessors, feature extractors, and time-series splitters.
+**Note:** All preprocessors, time-series splitters, and forecasting metrics are implemented with [`Polars`](https://www.pola.rs/) and open-sourced under the Apache-2.0 license. Contributions are always welcome.
 
 ## Getting Started
 1. First, install `functime` via the [pip](https://pypi.org/project/functime) package manager.
 ```bash
 pip install functime
 ```
-1. Then sign-up for a free `functime` Cloud account via the command-line interface (CLI).
+2. Then sign-up for a free `functime` Cloud account via the command-line interface (CLI).
 ```bash
 functime login
 ```
-1. That's it! You can begin forecasting at scale using the `scikit-learn` fit-predict interface.
+3. That's it! You can begin forecasting at scale using functime's `scikit-learn` fit-predict API.
 ```python
 import polars as pl
 from functime.cross_validation import train_test_split
 from functime.forecasting import LightGBM
 from functime.metrics import mase
 
 # Load example data
@@ -113,43 +114,36 @@
 │ str            ┆ datetime[ns]        ┆ f64         │
 ╞════════════════╪═════════════════════╪═════════════╡
 │ Wheat, US HRW  ┆ 2023-01-01 00:00:00 ┆ 240.337497  │
 │ Wheat, US HRW  ┆ 2023-02-01 00:00:00 ┆ 250.851552  │
 │ Wheat, US HRW  ┆ 2023-03-01 00:00:00 ┆ 252.102028  │
 │ Beef           ┆ 2023-01-01 00:00:00 ┆ 4.271976    │
 │ …              ┆ …                   ┆ …           │
-│ Coconut oil    ┆ 2023-03-01 00:00:00 ┆ 1140.930346 │
-│ Copper         ┆ 2023-01-01 00:00:00 ┆ 7329.806663 │
-│ Copper         ┆ 2023-02-01 00:00:00 ┆ 7484.565165 │
-│ Copper         ┆ 2023-03-01 00:00:00 ┆ 7486.160195 │
 └────────────────┴─────────────────────┴─────────────┘
 
 >>> scores.sort("mase")
 shape: (71, 2)
 ┌──────────────────────┬────────────┐
 │ commodity_type       ┆ mase       │
 │ ---                  ┆ ---        │
 │ str                  ┆ f64        │
 ╞══════════════════════╪════════════╡
 │ Rice, Viet Namese 5% ┆ 0.308148   │
 │ Palm kernel oil      ┆ 0.554886   │
 │ Coconut oil          ┆ 1.051424   │
 │ Cocoa                ┆ 1.32211    │
 │ …                    ┆ …          │
-│ Sugar, US            ┆ 73.346233  │
-│ Sugar, world         ┆ 81.304941  │
-│ Phosphate rock       ┆ 85.936644  │
-│ Sugar, EU            ┆ 170.319435 │
 └──────────────────────┴────────────┘
 ```
 
 ## Deployment
 `functime` deploys and trains your forecasting models the moment you call any `.fit` method.
 Run the `functime list` CLI command to list all deployed models.
 To view data and forecasts usage, run the `functime usage` CLI command.
+
 ![Example CLI usage](static/gifs/functime_cli_usage.gif)
 
 You can reuse a deployed model for predictions anywhere using the `stub_id` variable.
 ```python
 forecaster = LinearModel.from_deployment(stub_id)
 y_pred = forecaster.predict(fh=3)
 ```
```

## Comparing `functime-0.1.5.dist-info/RECORD` & `functime-0.1.6.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 functime/__init__.py,sha256=NM7kykIVEhdbgnsILzqU4tR0tYjnm-Z5vRxMJNSD78Q,29
 functime/__main__.py,sha256=HpYJUAIeN5HXQhaM5_kDwo441jDPe9GJ8dLjF9HE9VQ,117
-functime/config.py,sha256=jnEU-Kjusd8AJ3d07hq-dEc2Ju3qfm6BiTCz1awVytk,1136
-functime/cross_validation.py,sha256=jkSyc2k0ljvItLxPChwaUjksarVpUkChCaDa9fFalUw,5946
-functime/offsets.py,sha256=HZj-fd7UKDrQK_27xIR6L_yarMei2RXNvb7avOc4NI4,2407
-functime/preprocessing.py,sha256=FEPnlcG8AuJkM1XD-9pzvReWuTCdL3BOV7IP2qMx6s8,15901
-functime/ranges.py,sha256=f34nFIpUYng5LNSjjlDF9h6Nsm5EUEk5Csg_xb1pZNU,1907
+functime/config.py,sha256=ybZS5SKL6jaqeOQytE8CQFUfKlBcQ8AXoxWVYVIOngA,1141
+functime/cross_validation.py,sha256=mpMVwjtEiUA4FXXW7VkTiBayDh9tLB8MtAEOqBp50SM,6010
+functime/offsets.py,sha256=lm_fK56LzQwZUZIff3Ukymj1uB67cwH-Jt4vf1tYzCs,2059
+functime/preprocessing.py,sha256=ZvB3_aVjKhp6shLhBlMcisRCXUZdI-Neli3q7jeUisk,14946
+functime/ranges.py,sha256=L0XyUhs7ovEkGzAvJ408m3AmpGp1dDxVBRnOX259K40,1909
 functime/stats.py,sha256=hadK1-5bbLhtEOKEdre4thjV6Mv-RqUeJns1YvOvz00,2556
-functime/base/__init__.py,sha256=9QDn9FiViJnymBfzREfSP8kjciPOoQ9Ke74SqHLldHk,155
+functime/base/__init__.py,sha256=QhTMdB5mW3GgG7feOGltOa89cwEptd5ndcc4e4kUUUM,155
 functime/base/metric.py,sha256=f_lx6CV0tMbMB54I3pC2osP-6lzpu2692Xcqb_jWcy8,2793
 functime/base/model.py,sha256=RTTsmkRj0U1XpDdzEvKn1VRrnjwirQfulZW--TZ5LI8,3111
 functime/base/transformer.py,sha256=mL0ljSUtdJ6ZX-nEck553pbHk6odZdkqxnGkfYDqWJs,2237
-functime/cli/__init__.py,sha256=huBwrGbNmXh6nDoHQ7ifUMeBowl6DwsVzNXDSpT2ZOE,69
-functime/cli/_deploy.py,sha256=2I9yoD3DMzgavI7g7epo63m44VN0IA25DQ0YWe5lUqU,1463
-functime/cli/_list.py,sha256=kxlarIBbE7uyuP-l0oJXWFhqDVRG2HJ7J5DH2GygnRo,2474
-functime/cli/_login.py,sha256=are8-NBrkN6TVwBDxvnvAlQr7IBx_1nm-KA-hOpj9fI,3093
-functime/cli/_usage.py,sha256=3E4dvARjmUyxbpEOb5nFod2z3S_fqo1qlQicjPGwkiM,2169
-functime/cli/entrypoint.py,sha256=brPVNR1SNxXmM7JM_aLnAP7BujYVdOcmG49QYtLD-d8,1328
-functime/cli/utils.py,sha256=I0vvmyiNdrf_sugxJ10PkeON6hdHVTUMk0OOXEDJGUI,139
+functime/cli/__init__.py,sha256=VZ9aBV8IvuZx_C375Oet2ixLHXlY7yPKYSFNepsr06E,81
+functime/cli/_styling.py,sha256=I0vvmyiNdrf_sugxJ10PkeON6hdHVTUMk0OOXEDJGUI,139
+functime/cli/deploy.py,sha256=2I9yoD3DMzgavI7g7epo63m44VN0IA25DQ0YWe5lUqU,1463
+functime/cli/entrypoint.py,sha256=-ghyrhd3KPRzScV-Ao0HNrRCkX9TV6HlkysghHfGvFA,1438
+functime/cli/list.py,sha256=kxlarIBbE7uyuP-l0oJXWFhqDVRG2HJ7J5DH2GygnRo,2474
+functime/cli/login.py,sha256=are8-NBrkN6TVwBDxvnvAlQr7IBx_1nm-KA-hOpj9fI,3093
+functime/cli/token.py,sha256=yzNiXiqveOFGrUQCp1zCr-bvzzgITLhCZ7-HVMKXkRc,1112
+functime/cli/usage.py,sha256=T2Vlsk41s_fKXjkGK2Ki-qfZ7fanZCh3AUbAfuixeYo,2172
 functime/feature_extraction/__init__.py,sha256=GS4FtQUUuzJZAJJ4g7fgamtbZhAecz8iwaQsejPTVhs,285
 functime/feature_extraction/calendar.py,sha256=bNIE9xA0DnhMCnnQNNuyamDErCwbAJwH-zBnWjjHa-I,3507
-functime/forecasting/__init__.py,sha256=wRCNQ2LRTjiMEsXE-AqxtkLUB4sa_O_wZBL_KAgTYcg,421
-functime/forecasting/auto.py,sha256=BXizqIMhUlUayErWYWJObLWZuT41DWvng2cQe05r6og,9770
-functime/forecasting/base.py,sha256=Rt8tKVRhsZF-V8AkG-EU8FRjg5ojKlCGq5S-tUzNNXY,4929
-functime/forecasting/forecasters.py,sha256=JtmE11rf3K6ZSHjBfuqHo6utkM7szyZvgkviGVhpUuw,3565
+functime/forecasting/__init__.py,sha256=eQ2NVNZ9-FXG0vC7U9Fx7drScTmnyLToORdXfgpN5wk,421
+functime/forecasting/_base.py,sha256=7dHPy2AWtKPeG3T_dn33p932mL7VmsKnQusCDPtvjFY,4989
+functime/forecasting/auto.py,sha256=wG4aIwLxLck31LLrKDwNLWevznJhh--aN4fo_-C-Ivs,9921
+functime/forecasting/forecasters.py,sha256=QR-ZSQAS3JNkkNCs_Uiw1NyVltAoAhSeD9F4ABEqU50,3788
 functime/io/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-functime/io/auth.py,sha256=Rjw1IhQWb2MOT8vT2rYkeQSAHTUcg3b5Tm58_67tfq4,768
-functime/io/client.py,sha256=quoxv2BdF2cuQ8iRrnZXcSjTPZYJSYeFFJkxu_trE5U,3057
-functime/io/serialize.py,sha256=C1gLl-KZMMKLICWepIjiYIv8-gnjYlfF_eTFuB0YW-Q,494
-functime/io/utils.py,sha256=x7oLaA3gWT8Je0sHDotXFtSzfrcE_J9m__rDPCsL_SQ,202
-functime/metrics/__init__.py,sha256=K6opMFYKlUShIMq9IiGl8OEMcdaFEy-VcCy6RCVCk3A,270
-functime/metrics/point.py,sha256=mo05Jt7LAHS7xAgLrsW3JX2_NguWFk84Gw1fKd27nGM,6939
+functime/io/_serialize.py,sha256=C1gLl-KZMMKLICWepIjiYIv8-gnjYlfF_eTFuB0YW-Q,494
+functime/io/client.py,sha256=L8OiNUUCFgHddgfSty4sWzqvpI_2JAl8JdJeIghhOaA,5664
+functime/metrics/__init__.py,sha256=Bx-vU-jxkAg-zy2mVWYDtNOkluvgKJnL9uf0IhKIapw,229
+functime/metrics/point.py,sha256=r-aw7-au54c3oYzdVud0FK_9GQouFtmH3RjVdL8EJGY,6822
 functime/metrics/probabilistic.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-functime-0.1.5.dist-info/LICENSE,sha256=ILBn-G3jdarm2w8oOrLmXeJNU3czuJvVhDLBASWdhM8,34522
-functime-0.1.5.dist-info/METADATA,sha256=dry0Lx6A2FyZfWMY9HWedrAFLWbS9nI85cP_PDs-0XM,7712
-functime-0.1.5.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-functime-0.1.5.dist-info/entry_points.txt,sha256=y-9Na7pOh73f05jw87NkCt13P24wV_2qPEDF6ylwSXI,52
-functime-0.1.5.dist-info/top_level.txt,sha256=RUXkPSxtl5ViacwkIXqV7W8uyhA9yNRqrLMFS-jhFP4,9
-functime-0.1.5.dist-info/RECORD,,
+functime-0.1.6.dist-info/LICENSE,sha256=hIahDEOTzuHCU5J2nd07LWwkLW7Hko4UFO__ffsvB-8,34523
+functime-0.1.6.dist-info/METADATA,sha256=iGO4wPzivQU2ouWGdTjaLA3NG-B3pwOsC7xDO4BHPZc,7607
+functime-0.1.6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+functime-0.1.6.dist-info/entry_points.txt,sha256=y-9Na7pOh73f05jw87NkCt13P24wV_2qPEDF6ylwSXI,52
+functime-0.1.6.dist-info/top_level.txt,sha256=RUXkPSxtl5ViacwkIXqV7W8uyhA9yNRqrLMFS-jhFP4,9
+functime-0.1.6.dist-info/RECORD,,
```

