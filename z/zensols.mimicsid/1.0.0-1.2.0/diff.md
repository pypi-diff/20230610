# Comparing `tmp/zensols.mimicsid-1.0.0-py3-none-any.whl.zip` & `tmp/zensols.mimicsid-1.2.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,32 +1,33 @@
-Zip file size: 32973 bytes, number of entries: 30
--rw-rw-r--  2.0 unx      179 b- defN 23-Feb-10 17:40 zensols/mimicsid/__init__.py
--rw-rw-r--  2.0 unx     7748 b- defN 23-Feb-10 17:40 zensols/mimicsid/anon.py
--rw-rw-r--  2.0 unx     7222 b- defN 23-Feb-10 17:40 zensols/mimicsid/app.py
--rw-rw-r--  2.0 unx     1984 b- defN 23-Feb-10 17:40 zensols/mimicsid/cli.py
--rw-rw-r--  2.0 unx     4375 b- defN 23-Feb-10 17:40 zensols/mimicsid/domain.py
--rw-rw-r--  2.0 unx    11244 b- defN 23-Feb-10 17:40 zensols/mimicsid/model.py
--rw-rw-r--  2.0 unx     6897 b- defN 23-Feb-10 17:40 zensols/mimicsid/pred.py
--rw-rw-r--  2.0 unx     3738 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/app.conf
--rw-rw-r--  2.0 unx      234 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/default.conf
--rw-rw-r--  2.0 unx     1736 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/obj.conf
--rw-rw-r--  2.0 unx    17014 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/ontology.csv
--rw-rw-r--  2.0 unx     3491 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/batch.yml
--rw-rw-r--  2.0 unx     1855 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/default.conf
--rw-rw-r--  2.0 unx      660 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/header-default.yml
--rw-rw-r--  2.0 unx      239 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/header.yml
--rw-rw-r--  2.0 unx      977 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/model.conf
--rw-rw-r--  2.0 unx     2480 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/obj.conf
--rw-rw-r--  2.0 unx      535 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/section.conf
--rw-rw-r--  2.0 unx     2795 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/vectorizer.yml
--rw-rw-r--  2.0 unx      319 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/pkg/all.conf
--rw-rw-r--  2.0 unx      622 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/pkg/default.conf
--rw-rw-r--  2.0 unx      609 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/model/pkg/obj.conf
--rw-rw-r--  2.0 unx      270 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/pkg/all.conf
--rw-rw-r--  2.0 unx      631 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/pkg/default.conf
--rw-rw-r--  2.0 unx      609 b- defN 23-Feb-10 17:40 zensols/mimicsid/resources/pkg/obj.conf
--rw-rw-r--  2.0 unx    13118 b- defN 23-Feb-10 17:40 zensols.mimicsid-1.0.0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Feb-10 17:40 zensols.mimicsid-1.0.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx       51 b- defN 23-Feb-10 17:40 zensols.mimicsid-1.0.0.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       17 b- defN 23-Feb-10 17:40 zensols.mimicsid-1.0.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2792 b- defN 23-Feb-10 17:40 zensols.mimicsid-1.0.0.dist-info/RECORD
-30 files, 94533 bytes uncompressed, 28369 bytes compressed:  70.0%
+Zip file size: 35948 bytes, number of entries: 31
+-rw-rw-r--  2.0 unx      372 b- defN 23-Jun-09 22:03 zensols/mimicsid/__init__.py
+-rw-rw-r--  2.0 unx     8710 b- defN 23-Jun-09 22:03 zensols/mimicsid/anon.py
+-rw-rw-r--  2.0 unx     8774 b- defN 23-Jun-09 22:03 zensols/mimicsid/app.py
+-rw-rw-r--  2.0 unx     2245 b- defN 23-Jun-09 22:03 zensols/mimicsid/cli.py
+-rw-rw-r--  2.0 unx     6706 b- defN 23-Jun-09 22:03 zensols/mimicsid/domain.py
+-rw-rw-r--  2.0 unx    11248 b- defN 23-Jun-09 22:03 zensols/mimicsid/model.py
+-rw-rw-r--  2.0 unx     9794 b- defN 23-Jun-09 22:03 zensols/mimicsid/pred.py
+-rw-rw-r--  2.0 unx     3813 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/app.conf
+-rw-rw-r--  2.0 unx      234 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/default.conf
+-rw-rw-r--  2.0 unx     1736 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/obj.conf
+-rw-rw-r--  2.0 unx    17014 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/ontology.csv
+-rw-r--r--  2.0 unx      606 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/adm.conf
+-rw-rw-r--  2.0 unx     3491 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/batch.yml
+-rw-rw-r--  2.0 unx     1855 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/default.conf
+-rw-rw-r--  2.0 unx      660 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/header-default.yml
+-rw-rw-r--  2.0 unx      239 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/header.yml
+-rw-rw-r--  2.0 unx      977 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/model.conf
+-rw-rw-r--  2.0 unx     2504 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/obj.conf
+-rw-rw-r--  2.0 unx      535 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/section.conf
+-rw-rw-r--  2.0 unx     2795 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/vectorizer.yml
+-rw-rw-r--  2.0 unx      319 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/pkg/all.conf
+-rw-rw-r--  2.0 unx      622 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/pkg/default.conf
+-rw-rw-r--  2.0 unx      609 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/model/pkg/obj.conf
+-rw-rw-r--  2.0 unx      270 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/pkg/all.conf
+-rw-rw-r--  2.0 unx      631 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/pkg/default.conf
+-rw-rw-r--  2.0 unx      609 b- defN 23-Jun-09 22:03 zensols/mimicsid/resources/pkg/obj.conf
+-rw-rw-r--  2.0 unx    14009 b- defN 23-Jun-09 22:03 zensols.mimicsid-1.2.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-09 22:03 zensols.mimicsid-1.2.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       51 b- defN 23-Jun-09 22:03 zensols.mimicsid-1.2.0.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       17 b- defN 23-Jun-09 22:03 zensols.mimicsid-1.2.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2889 b- defN 23-Jun-09 22:03 zensols.mimicsid-1.2.0.dist-info/RECORD
+31 files, 104426 bytes uncompressed, 31186 bytes compressed:  70.1%
```

## zipnote {}

```diff
@@ -27,14 +27,17 @@
 
 Filename: zensols/mimicsid/resources/obj.conf
 Comment: 
 
 Filename: zensols/mimicsid/resources/ontology.csv
 Comment: 
 
+Filename: zensols/mimicsid/resources/model/adm.conf
+Comment: 
+
 Filename: zensols/mimicsid/resources/model/batch.yml
 Comment: 
 
 Filename: zensols/mimicsid/resources/model/default.conf
 Comment: 
 
 Filename: zensols/mimicsid/resources/model/header-default.yml
@@ -69,23 +72,23 @@
 
 Filename: zensols/mimicsid/resources/pkg/default.conf
 Comment: 
 
 Filename: zensols/mimicsid/resources/pkg/obj.conf
 Comment: 
 
-Filename: zensols.mimicsid-1.0.0.dist-info/METADATA
+Filename: zensols.mimicsid-1.2.0.dist-info/METADATA
 Comment: 
 
-Filename: zensols.mimicsid-1.0.0.dist-info/WHEEL
+Filename: zensols.mimicsid-1.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: zensols.mimicsid-1.0.0.dist-info/entry_points.txt
+Filename: zensols.mimicsid-1.2.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: zensols.mimicsid-1.0.0.dist-info/top_level.txt
+Filename: zensols.mimicsid-1.2.0.dist-info/top_level.txt
 Comment: 
 
-Filename: zensols.mimicsid-1.0.0.dist-info/RECORD
+Filename: zensols.mimicsid-1.2.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## zensols/mimicsid/__init__.py

```diff
@@ -1,9 +1,19 @@
 """MIMIC-III corpus parsing and section prediction with MedSecId.
 
 """
 __author__ = 'Paul Landes'
 
+
+def _silence_spacy_parser_warnings():
+    import warnings
+    warnings.filterwarnings(
+        'ignore', message='remove_empty_sentences is deprecated.*')
+
+
+_silence_spacy_parser_warnings()
+
+
 from .domain import *
 from .anon import *
 from .app import *
 from .cli import *
```

## zensols/mimicsid/anon.py

```diff
@@ -1,13 +1,13 @@
 """Stashes that use annotated sections when available.
 
 """
 __author__ = 'Paul Landes'
 
-from typing import Dict, Any, ClassVar, Iterable, Set
+from typing import Dict, Any, ClassVar, Iterable, Set, List, Tuple, Union
 from dataclasses import dataclass, field
 import logging
 import json
 import re
 from pathlib import Path
 from io import BytesIO
 from frozendict import frozendict
@@ -78,51 +78,82 @@
         rows = []
         for k in self._get_stash().keys():
             m: re.Match = self._KEY_REGEX.match(k)
             if m is not None:
                 rows.append(m.groups())
         return pd.DataFrame(rows, columns='hadm_id row_id category'.split())
 
+    @staticmethod
+    def category_to_id(name: str) -> str:
+        """Return the ID form for the category name."""
+        return name.replace(' ', '-').replace('/', '-').lower()
+
     def get_annotation(self, note_event: NoteEvent) -> Dict[str, Any]:
         """Get the raw annotation as Python dict of dics for a
         :class:`~zensols.mimic.NoteEvent`.
 
         """
         ne = note_event
-        cat = ne.category.replace(' ', '-').replace('/', '-').lower()
+        cat = self.category_to_id(ne.category)
         path = f'{self._ANN_ENTRY}/{ne.hadm_id}-{ne.row_id}-{cat}.json'
         item: bytearray = self._get_stash().get(path)
         if item is not None:
             return json.load(BytesIO(item))
 
+    @property
+    @persisted('_note_counts_by_admission')
+    def note_counts_by_admission(self) -> pd.DataFrame:
+        """The counts of each category and row IDs for each admission.
+
+        """
+        df: pd.DataFrame = self.note_ids
+        cats: List[str] = sorted(df['category'].drop_duplicates().tolist())
+        cols: List[str] = ['hadm_id'] + cats + ['total', 'row_ids']
+        rows: List[Tuple[str, int]] = []
+        for hadm_id, dfg in df.groupby('hadm_id'):
+            cnts = dfg.groupby('category').size()
+            row: List[Union[str, int]] = [hadm_id]
+            row.extend(map(lambda c: cnts[c] if c in cnts else 0, cats))
+            row.append(cnts.sum())
+            rows.append(row)
+            row.append(','.join(dfg['row_id']))
+        df = pd.DataFrame(rows, columns=cols)
+        return df.sort_values('total', ascending=False)
+
 
 @dataclass
 class AnnotationNoteFactory(NoteFactory):
     """Override to replace section with MedSecId annotations if they exist.
 
     """
     anon_resource: AnnotationResource = field(default=None)
     """Contains the annotations and ontolgy/metadata note to section data."""
 
     annotated_note_section: str = field(default=None)
     """The section to use for creating new annotated section, for those that
     found in the annotation set.
 
     """
-    def __call__(self, note_event: NoteEvent) -> Note:
-        anon: Dict[str, Any] = self.anon_resource.get_annotation(note_event)
+    def _create_missing_anon_note(self, note_event: NoteEvent) -> Note:
+        return super().__call__(note_event)
+
+    def _create_note(self, note_event: NoteEvent, anon: Dict[str, Any]) -> Note:
         if anon is not None:
             note = self._event_to_note(
                 note_event,
                 section=self.annotated_note_section,
                 params={'annotation': anon})
         else:
-            note = super().__call__(note_event)
+            note = self._create_missing_anon_note(note_event)
         return note
 
+    def __call__(self, note_event: NoteEvent) -> Note:
+        anon: Dict[str, Any] = self.anon_resource.get_annotation(note_event)
+        return self._create_note(note_event, anon)
+
 
 @dataclass
 class AnnotatedNoteStash(ReadOnlyStash, PrimeableStash):
     """A stash that returns :class:`~zensols.mimic.Note` instances by thier
     unique ``row_id`` keys.
 
     """
@@ -142,29 +173,29 @@
 
     @property
     @persisted('_row_hadm_map')
     def row_to_hadm_ids(self) -> Dict[str, str]:
         """A mapping of row to hospital admission IDs."""
         with time('calc key diff'):
             df: pd.DataFrame = self.anon_resource.note_ids
-            stash: Stash = self.corpus.hospital_adm_stash
             rows: Dict[str, str] = dict(
                 df['row_id hadm_id'.split()].itertuples(index=False))
-            hadm_ids: Set[str] = set(df['hadm_id'].drop_duplicates())
-            remaining: Set[str] = hadm_ids - set(stash.keys())
+        return frozendict(rows)
+
+    def prime(self):
+        stash: Stash = self.corpus.hospital_adm_stash
+        df: pd.DataFrame = self.anon_resource.note_ids
+        hadm_ids: Set[str] = set(df['hadm_id'].drop_duplicates())
+        remaining: Set[str] = hadm_ids - set(stash.keys())
         if len(remaining) > 0:
             if logger.isEnabledFor(logging.INFO):
                 logger.info(f'priming {len(remaining)} admissions')
             with time(f'wrote {len(remaining)} admissions'):
                 for hadm_id in remaining:
                     stash[hadm_id]
-        return frozendict(rows)
-
-    def prime(self):
-        self.row_to_hadm_ids
 
     def clear(self):
         self._row_hadm_map.clear()
 
     def load(self, row_id: str) -> AnnotatedNote:
         row_to_hadm: Dict[str, str] = self.row_to_hadm_ids
         stash: Stash = self.corpus.hospital_adm_stash
@@ -175,23 +206,20 @@
             if isinstance(note, AnnotatedNote):
                 return note
             else:
                 logger.warning('No annotation found for hadm_id: ' +
                                f'{hadm_id}, row_id: {row_id}')
 
     def keys(self) -> Iterable[str]:
-        self.prime()
         return self.anon_resource.note_ids['row_id'].tolist()
 
     def exists(self, row_id: str) -> bool:
-        self.prime()
         return any(self.anon_resource.note_ids['row_id'] == row_id)
 
     def __len__(self) -> int:
-        self.prime()
         return len(self.anon_resource.note_ids)
 
 
 @dataclass
 class NoteStash(DelegateStash):
     """Creates notes of type :class:`~zensols.mimic.Note` or
     :class:`.AnnotatedNote` depending on if the note was annotated.
@@ -208,16 +236,7 @@
             if hadm_id is not None:
                 adm: HospitalAdmission = self.corpus.hospital_adm_stash[hadm_id]
                 note = adm[int(row_id)]
         return note
 
     def get(self, name: str, default: Any = None) -> Any:
         return Stash.get(self, name, default)
-
-    def keys(self) -> Iterable[str]:
-        return self.corpus.note_event_persister.get_keys()
-
-    def exists(self, row_id: str) -> bool:
-        return self.corpus.note_event_persister.exists(row_id)
-
-    def __len__(self) -> int:
-        return self.corpus.note_event_persister.get_count()
```

## zensols/mimicsid/app.py

```diff
@@ -1,13 +1,13 @@
 """Use the MedSecId section annotations with MIMIC-III corpus parsing.
 
 """
 __author__ = 'Paul Landes'
 
-from typing import Tuple, List
+from typing import Tuple, List, Dict, Any
 from dataclasses import dataclass, field
 from enum import Enum, auto
 import sys
 import logging
 from io import StringIO
 from pathlib import Path
 import pandas as pd
@@ -26,14 +26,15 @@
 
 class OutputFormat(Enum):
     """CLI note output formats."""
     sections = auto()
     verbose = auto()
     raw = auto()
     markdown = auto()
+    summary = auto()
 
 
 @dataclass
 class Application(FacadeApplication):
     """Use the MedSecId section annotations with MIMIC-III corpus parsing.
 
     """
@@ -56,52 +57,99 @@
 
         """
         stash: Stash = self.corpus.hospital_adm_stash
         logger.info('clearing admission cache')
         with loglevel('zensols'):
             stash.clear()
 
-    def dump_ontology(self, output: Path = Path('ontology.csv')):
-        """Writes the ontology."""
-        self.anon_resource.ontology.to_csv(output)
-        logger.info(f'wrote: {output}')
+    def dump_ontology(self, output: Path = None):
+        """Writes the ontology.
 
-    def dump_note_ids(self):
-        """Writes hadm_id and note row_ids available in the annotation set."""
-        output = Path('note-ids.csv')
-        df: pd.DataFrame = self.anon_resource.note_ids
-        df = df.sort_values('hadm_id row_id'.split())
-        df.to_csv(output)
+        :param output: the output file
+
+        """
+        output = Path('ontology.csv') if output is None else output
+        self.anon_resource.ontology.to_csv(output)
         logger.info(f'wrote: {output}')
 
     def write_note(self, row_id: int,
                    output_format: OutputFormat = OutputFormat.sections):
         """Write an admission, note or section.
 
         :param row_id: the row ID of the note to write
 
         """
+        def summary_format():
+            for s in note.sections.values():
+                print(s, s.header_spans, len(s))
+
         row_id = str(row_id)
+        note: Note
         if row_id in self.note_stash:
-            note: Note = self.note_stash[row_id]
-            {OutputFormat.sections: note.write_human,
-             OutputFormat.verbose: note.write_sections,
-             OutputFormat.raw: lambda: print(note.text),
-             OutputFormat.markdown: note.write_markdown,
-             }[output_format]()
+            note = self.note_stash[row_id]
         else:
             hadm_id: int = self.corpus.note_event_persister.get_hadm_id(row_id)
             if hadm_id is None:
                 raise ApplicationError(f'Note ID {row_id} does not exist')
             else:
                 adm: HospitalAdmission = self.corpus.hospital_adm_stash[hadm_id]
                 note: Note = adm[int(row_id)]
                 logger.warning(
                     f'note ID {row_id} is not in the annotation set--using raw')
-                print(note.text)
+        {OutputFormat.sections: note.write_human,
+         OutputFormat.verbose: note.write_sections,
+         OutputFormat.raw: lambda: print(note.text),
+         OutputFormat.markdown: note.write_markdown,
+         OutputFormat.summary: summary_format,
+         }[output_format]()
+
+    def admission_notes(self, hadm_id: str, output: Path = None,
+                        keeps: str = None) -> pd.DataFrame:
+        """Create a CSV of note information by admission.
+
+        :param hadm_id: the admission ID
+
+        :param output: the output file
+
+        :param keeps: a comma-delimited list of column to keep in the output;
+                      defaults to all columns
+
+        """
+        if output is None:
+            output: Path = Path(f'notes-{hadm_id}.csv')
+        adm: HospitalAdmission = self.corpus.hospital_adm_stash.get(hadm_id)
+        rows: List[Dict[str, Any]] = []
+        note: Note
+        for note in adm.notes:
+            is_anon: bool = isinstance(note, AnnotatedNote)
+            dct: Dict[str, Any] = note.asdict()
+            for k in 'text sections'.split():
+                del dct[k]
+            dct['is_anon'] = is_anon
+            if is_anon:
+                dct['age_type'] = note.age_type.name
+            rows.append(dct)
+        df = pd.DataFrame(rows)
+        if keeps is not None:
+            df = df[keeps.split(',')]
+        df.to_csv(output)
+        logger.info(f'wrote: {output}')
+        return df
+
+    def note_counts_by_admission(self, output: Path = None) -> pd.DataFrame:
+        """Write the counts of each category and row IDs for each admission.
+
+        :param output: the output file
+
+        """
+        output = Path('admissions.csv') if output is None else output
+        df: pd.DataFrame = self.anon_resource.note_counts_by_admission
+        df.to_csv(output, index=False)
+        logger.info(f'wrote: {output}')
+        return df
 
 
 class PredOutputType(Enum):
     """The types of prediction output formats."""
     text = auto()
     json = auto()
```

## zensols/mimicsid/cli.py

```diff
@@ -2,40 +2,49 @@
 
 """
 __author__ = 'Paul Landes'
 
 from typing import List, Any, Dict
 import sys
 from zensols.config import ConfigFactory
+from zensols.mimic import Corpus
 from zensols.cli import ActionResult, CliHarness
 from zensols.cli import ApplicationFactory as CliApplicationFactory
 from . import SectionPredictor, NoteStash, AnnotationResource
 
 
 class ApplicationFactory(CliApplicationFactory):
     """The application factory for section identification.
 
     """
     def __init__(self, *args, **kwargs):
         kwargs['package_resource'] = 'zensols.mimicsid'
         super().__init__(*args, **kwargs)
 
     @classmethod
-    def section_predictor(cls) -> SectionPredictor:
+    def instance(cls, name: str) -> ConfigFactory:
         """Return the section predictor using the app context."""
         harness: CliHarness = cls.create_harness()
         fac: ConfigFactory = harness.get_config_factory()
-        return fac('mimicsid_section_predictor')
+        return fac(name)
+
+    @classmethod
+    def corpus(cls) -> Corpus:
+        """Return the section predictor using the app context."""
+        return cls.instance('mimic_corpus')
+
+    @classmethod
+    def section_predictor(cls) -> SectionPredictor:
+        """Return the section predictor using the app context."""
+        return cls.instance('mimicsid_section_predictor')
 
     @classmethod
     def annotation_resource(cls) -> AnnotationResource:
         """Contains resources to acces the MIMIC-III MedSecId annotations."""
-        harness: CliHarness = cls.create_harness()
-        fac: ConfigFactory = harness.get_config_factory()
-        return fac('mimicsid_anon_resource')
+        return cls.instance('mimicsid_anon_resource')
 
     @classmethod
     def note_stash(cls, host: str, port: str, db_name: str,
                    user: str, password: str) -> NoteStash:
         """Return the note stash using the app context, which is populated with
         the Postgres DB login provided as the parameters.
```

## zensols/mimicsid/domain.py

```diff
@@ -1,29 +1,30 @@
 """Annotated section and note domain specific classes.
 
 """
 __author__ = 'Paul Landes'
 
-from typing import Dict, Any, List
-from dataclasses import dataclass, field
+from typing import Dict, Any, List, ClassVar, Set, Iterable
+from dataclasses import dataclass, field, InitVar
 from enum import Enum, auto
 import sys
 from io import TextIOBase
 import re
+from zensols.persist import persisted, PersistableContainer
 from zensols.nlp import LexicalSpan, FeatureDocument
-from zensols.mimic import Note, Section, SectionContainer
+from zensols.mimic import Note, Section, SectionContainer, SectionAnnotatorType
 
 
 class AgeType(Enum):
     """An enumeration of all possible ages identified by the physicians per note
     in the annotation set.
 
     """
     adult = auto()
-    newbon = auto()
+    newborn = auto()
     pediatric = auto()
 
 
 @dataclass
 class AnnotatedSection(Section):
     """A section that uses the MedSecId annotations for section demarcation
     (:obj:`header_span`, :obj:`header_spans` and :obj:`body_span`) and
@@ -57,14 +58,17 @@
     def age_type(self) -> AgeType:
         """The age type of the discharge note as annotated by the physicians.
 
         """
         atstr = self.annotation['age_type']
         return AgeType[atstr]
 
+    def _get_section_annotator_type(self) -> SectionAnnotatorType:
+        return SectionAnnotatorType.HUMAN
+
     def _create_sec(self, sid: int, anon: Dict[str, Any]) -> Section:
         body_span = LexicalSpan(**anon['body_span'])
         header_spans: List[LexicalSpan] = []
         header_span: LexicalSpan = None
         for hspan in anon.get('header_spans', ()):
             header_spans.append(LexicalSpan(**hspan))
         if len(header_spans) > 0:
@@ -79,15 +83,15 @@
             id=sid,
             name=anon['id'],
             container=self,
             body_span=body_span,
             header_spans=header_spans,
             annotation=anon)
 
-    def _get_sections(self) -> List[Section]:
+    def _get_sections(self) -> Iterable[Section]:
         an = self.annotation
         assert self.hadm_id == an['hadm_id']
         assert self.row_id == an['row_id']
         assert self.category == an['category']
         secs: List[Section] = []
         sec_anon: Dict[str, Any]
         for sid, sec_anon in enumerate(an['sections']):
@@ -98,40 +102,98 @@
 
     def write_fields(self, depth: int = 0, writer: TextIOBase = sys.stdout):
         super().write_fields(depth, writer)
         self._write_line(f'age: {self.age_type.name}', depth, writer)
 
 
 @dataclass
-class PredictedSection(Section):
-    """A section with spans and ID/type predicted by the model.
-
-    """
-    doc: FeatureDocument = field(repr=False)
-    """The note document in :class:`.PredictedNote`."""
-
-    def _get_body_doc(self) -> FeatureDocument:
-        return self._narrow_doc(self.doc)
-
-
-@dataclass
-class PredictedNote(SectionContainer):
+class PredictedNote(PersistableContainer, SectionContainer):
     """A note with predicted sections.
 
     """
-    doc: FeatureDocument = field(repr=False)
-    """The used document that was parsed for prediction."""
+    _PERSITABLE_PROPERTIES: ClassVar[Set[str]] = {'sections'}
 
     predicted_sections: List[Section] = field(repr=False)
     """The sections predicted by the model.
 
     """
+    doc: InitVar[FeatureDocument] = field(repr=False)
+    """The used document that was parsed for prediction."""
+
+    def __post_init__(self, doc: FeatureDocument):
+        self._doc = doc
+        super().__init__()
+
+    @property
+    def _predicted_sections(self) -> List[Section]:
+        return self._predicted_sections_val
+
+    @_predicted_sections.setter
+    def _predicted_sections(self, sections: List[Section]):
+        self._predicted_sections_val = sections
+        if hasattr(self, '_sections'):
+            self._sections.clear()
+
     @property
     def text(self) -> str:
         """"The entire note text."""
-        return self.doc.text
+        return self._get_doc().text
 
-    def _get_sections(self) -> List[Section]:
+    @property
+    @persisted('_truncated_text', transient=True)
+    def truncted_text(self) -> str:
+        return self._trunc(self.text, 70).replace('\n', ' ').strip()
+
+    def _get_sections(self) -> Iterable[Section]:
         return self.predicted_sections
 
     def _get_doc(self) -> FeatureDocument:
-        return self.doc
+        return self._doc
+
+    def __setstate__(self, state: Dict[str, Any]):
+        super().__setstate__(state)
+        for sec in self.predicted_sections:
+            sec.container = self
+
+    def __str__(self):
+        text = self.truncted_text
+        if hasattr(self, 'row_id') and hasattr(self, 'category'):
+            return f'{self.row_id}: ({self.category}): {text}'
+        else:
+            return text
+
+
+PredictedNote.predicted_sections = PredictedNote._predicted_sections
+
+
+@dataclass(init=False)
+class MimicPredictedNote(Note):
+    """A note that comes from the MIMIC-III corpus with predicted sections.
+    This takes an instance of :class:`.PredictedNote` created by the model
+    during inference.  It creates :class:`~zensols.mimic.note.Section`
+    instances, and then discards the predicted note on pickling.
+
+    This method avoids having to serialize the
+    :class:`~zensols.nlp.container.FeatureDocument` (:obj:`.PredictedNote.doc`)
+    twice.
+
+    """
+    _PERSITABLE_TRANSIENT_ATTRIBUTES: ClassVar[Set[str]] = \
+        Note._PERSITABLE_TRANSIENT_ATTRIBUTES | {'_pred_note'}
+
+    def __init__(self, *args, predicted_note: PredictedNote, **kwargs):
+        self._pred_note = predicted_note
+        super().__init__(*args, **kwargs)
+
+    def _get_section_annotator_type(self) -> SectionAnnotatorType:
+        return SectionAnnotatorType.MODEL
+
+    def _get_sections(self) -> Iterable[Section]:
+        def map_sec(ps: Section) -> Section:
+            return Section(
+                id=ps.id,
+                name=ps.name,
+                container=self,
+                header_spans=ps.header_spans,
+                body_span=ps.body_span)
+
+        return map(map_sec, self._pred_note.predicted_sections)
```

## zensols/mimicsid/model.py

```diff
@@ -14,15 +14,15 @@
 from zensols.mimic import MimicTokenDecorator
 from zensols.deeplearn.batch import DataPoint
 from zensols.deeplearn.result import ResultsContainer
 from zensols.deepnlp.classify import (
     ClassificationPredictionMapper, TokenClassifyModelFacade
 )
 from zensols.mimic import Section
-from . import AnnotatedNote, AnnotatedSection, PredictedSection, PredictedNote
+from . import AnnotatedNote, AnnotatedSection, PredictedNote
 
 logger = logging.getLogger(__name__)
 
 
 class TokenType(Enum):
     """A custom token type feature that identifies specifies whether the token
     is::
@@ -246,21 +246,20 @@
             if len(toks) == 1:
                 span = toks[0].lexspan
             else:
                 begin = toks[0].lexspan.begin
                 end = toks[-1].lexspan.end
                 span = LexicalSpan(begin, end)
             assert span is not None
-            secs.append(PredictedSection(
+            secs.append(Section(
                 id=sid,
                 name=label,
                 container=None,
                 header_spans=(),
-                body_span=span,
-                doc=doc))
+                body_span=span))
 
     def _collate(self, docs: Tuple[FeatureDocument],
                  classes: Tuple[Tuple[str]]) -> List[PredictedNote]:
         """Collate predictions with feature tokens.
 
         :param docs: he documents used for prediction
 
@@ -277,15 +276,17 @@
             self._create_tok_list(doc, labels, tok_lists)
         # create predicted notes
         tok_lists: Tuple[str, List[FeatureToken]]
         doc: FeatureDocument
         for doc, tok_lists in zip(docs, doc_tok_lists):
             secs: List[AnnotatedSection] = []
             self._create_secions(tok_lists, doc, secs)
-            pn = PredictedNote(doc, secs)
+            pn = PredictedNote(
+                predicted_sections=secs,
+                doc=doc)
             sec: Section
             for sec in secs:
                 sec.container = pn
             notes.append(pn)
         return notes
 
     def _create_features(self, data: Union[FeatureDocument, str]) -> \
```

## zensols/mimicsid/pred.py

```diff
@@ -1,24 +1,23 @@
-from __future__ import annotations
 """Collates the predictions of both models.
 
 """
+from __future__ import annotations
 __author__ = 'Paul Landes'
-
 from typing import List, Tuple, Optional
-from dataclasses import dataclass, field
+from dataclasses import dataclass, field, InitVar
 import logging
 from pathlib import Path
 from zensols.config import ConfigFactory
 from zensols.persist import PersistableContainer, persisted, PersistedWork
 from zensols.nlp import LexicalSpan, FeatureDocument, FeatureDocumentParser
 from zensols.deeplearn.model import ModelPacker, ModelFacade
 from zensols.deeplearn.cli import FacadeApplication
-from zensols.mimic import Section
-from . import PredictedNote
+from zensols.mimic import Section, NoteEvent, Note, NoteFactory
+from . import PredictedNote, AnnotationNoteFactory, MimicPredictedNote
 from .model import SectionFacade
 
 logger = logging.getLogger(__name__)
 
 
 @dataclass
 class SectionPredictor(PersistableContainer):
@@ -37,25 +36,28 @@
     """
     name: str = field()
     """The name of this object instance definition in the configuration."""
 
     config_factory: ConfigFactory = field()
     """The config factory used to help find the packed model."""
 
-    section_id_model_packer: ModelPacker = field()
+    section_id_model_packer: ModelPacker = field(default=None)
     """The packer used to create the section identifier model."""
 
     header_model_packer: Optional[ModelPacker] = field(default=None)
     """The packer used to create the header token identifier model."""
 
     doc_parser: FeatureDocumentParser = field(default=None)
     """Used for parsing documents for predicton.  Default to using model's
     configured document parser.
 
     """
+    min_section_body_len: int = field(default=1)
+    """The minimum length of the body needed to make a section."""
+
     auto_deallocate: bool = field(default=True)
     """Whether or not to deallocate resources after every call to
     :meth:`predict`.  See class docs.
 
     """
     def __post_init__(self):
         self._section_id_app = PersistedWork('_section_id_app', self)
@@ -94,19 +96,23 @@
                 if hspan.overlaps_with(sspan) and hspan.begin == sspan.begin:
                     # skip over the colon and space after
                     if len(hspan) > 1 and \
                        sn.text[hspan.end - 1:hspan.end] == ':':
                         hspan = LexicalSpan(hspan.begin, hspan.end - 1)
                     hspans.append(hspan)
             if len(hspans) > 0:
+                p: int = None
                 for p in range(hspans[-1].end, sspan.end):
                     c: str = sn.text[p]
                     if c != ':' and c != ' ' and c != '\n' and c != '\t':
                         break
-                ssec.body_span = LexicalSpan(p, sspan.end)
+                if p is None:
+                    ssec.body_span = LexicalSpan(sspan.end, sspan.end)
+                else:
+                    ssec.body_span = LexicalSpan(p, sspan.end)
                 ssec.header_spans = tuple(hspans)
 
     def _merge_notes(self, snotes: List[PredictedNote],
                      hnotes: List[PredictedNote]):
         """Merge header tokens from ``hnotes`` to ``snotes``."""
         sn: PredictedNote
         hn: PredictedNote
@@ -119,29 +125,44 @@
         model_packer = getattr(model_pred, packer_name)
         if packer.version != model_packer.version:
             model_name: str = facade.model_settings.model_name
             logger.warning(
                 f'API {model_name} version ({packer.version}) does not ' +
                 f'match the trained model version ({model_packer.version})')
 
+    def _trim_notes(self, notes: List[PredictedNote]):
+        def filter_sec(sec: Section) -> bool:
+            return len(sec.body_span) > self.min_section_body_len
+
+        note: Note
+        for note in notes:
+            note.predicted_sections = list(
+                filter(filter_sec, note.predicted_sections))
+
     def _predict(self, doc_texts: List[str]) -> List[PredictedNote]:
         sid_fac: SectionFacade = self._get_section_id_app().get_cached_facade()
         self._validate_version('section_id_model_packer', sid_fac)
         head_app: FacadeApplication = self._get_header_app()
         doc_parser: FeatureDocumentParser = \
             sid_fac.doc_parser if self.doc_parser is None else self.doc_parser
         docs: Tuple[FeatureDocument] = tuple(map(doc_parser, doc_texts))
         snotes: List[PredictedNote] = sid_fac.predict(docs)
         if head_app is not None:
             head_fac: SectionFacade = head_app.get_cached_facade()
             self._validate_version('header_model_packer', head_fac)
             hnotes: List[PredictedNote] = head_fac.predict(docs)
             self._merge_notes(snotes, hnotes)
+        self._trim_notes(snotes)
         return snotes
 
+    def deallocate(self):
+        super().deallocate()
+        self._section_id_app.clear()
+        self._header_app.clear()
+
     def predict(self, doc_texts: List[str]) -> List[PredictedNote]:
         """Collate the predictions of both the section ID (type) and header
         token models.
 
         :param doc_texts: the text of the medical note to segment
 
         :return: a list of the predictions as notes for each respective
@@ -149,15 +170,69 @@
 
         """
         if self.auto_deallocate:
             try:
                 return self._predict(doc_texts)
             finally:
                 self.deallocate()
-                self._section_id_app.clear()
-                self._header_app.clear()
         else:
             return self._predict(doc_texts)
 
     def __call__(self, doc_texts: List[str]) -> List[PredictedNote]:
         """See :meth:`predict`."""
         return self.predict(doc_texts)
+
+
+@dataclass
+class PredictionNoteFactory(AnnotationNoteFactory):
+    """An note factory that predicts so that
+    :class:`~zensols.mimic.adm.HospitalAdmissionDbStash` predicts missing
+    sections.
+
+    **Implementation note:** The :obj:`section_predictor_name` is used with the
+    application context factory :obj:`config_factory` since declaring it in the
+    configuration creates an instance cycle.
+
+    """
+    config_factory: ConfigFactory = field()
+    """The factory to get the section predictor."""
+
+    mimic_pred_note_section: str = field(default=None)
+    """The section name holding the configuration of the
+    :class:`.MimicPredictedNote` class.
+
+    """
+    section_predictor_name: InitVar[str] = field(default=None)
+    """The name of the section predictor as an app config section name.  See
+    class docs.
+
+    """
+    def __post_init__(self, section_predictor_name: str):
+        self._section_predictor_name = section_predictor_name
+
+    @property
+    @persisted('_section_predictor')
+    def section_predictor(self) -> SectionPredictor:
+        """The section predictor (see class docs)."""
+        sp: SectionPredictor = self.config_factory(self._section_predictor_name)
+        # turn off deallocation to keep the same facade for all prediction calls
+        sp.auto_deallocate = False
+        return sp
+
+    def _create_missing_anon_note(self, note_event: NoteEvent) -> Note:
+        sp: SectionPredictor = self.section_predictor
+        note: Note = None
+        try:
+            logger.info(f'predicting note: {note_event}')
+            pred_note: PredictedNote = sp.predict([note_event.text])[0]
+            if len(pred_note.sections) == 0:
+                note = None
+            else:
+                note: MimicPredictedNote = self._event_to_note(
+                    note_event,
+                    section=self.mimic_pred_note_section,
+                    params={'predicted_note': pred_note})
+        except Exception as e:
+            logger.error(f'could not predict note: {note_event}: {e}', e)
+        if note is None:
+            note = NoteFactory.__call__(self, note_event)
+        return note
```

## zensols/mimicsid/resources/app.conf

```diff
@@ -34,15 +34,14 @@
     resource(zensols.util): resources/cli.conf,
     resource(zensols.util): resources/cli-config.conf,
     resource(zensols.util): resources/cleaner.conf,
     resource(zensols.deeplearn): resources/cli.conf,
     resource(zensols.deeplearn): resources/cli-pack.conf,
     resource(zensols.deepnlp): resources/cli.conf,
     resource(zensols.deepnlp): resources/cleaner.conf
-#    resource(zensols.mimicsid): resources/default.conf
 
 # configuration files are optional
 [config_cli]
 expect = False
 
 # -c config flag with file
 [config_import]
@@ -64,14 +63,15 @@
     resource(zensols.nlp): resources/obj.conf,
     resource(zensols.nlp): resources/mapper.conf,
     resource(zensols.mednlp): resources/obj.conf,
     resource(zensols.mimic): resources/obj.conf,
     resource(zensols.mimic): resources/decorator.conf,
     resource(zensols.mimicsid): resources/obj.conf,
     resource(zensols.mimicsid): resources/model/obj.conf,
+    resource(zensols.mimicsid): resources/model/adm.conf,
     ^{config_path},
     ^{override}
 
 # CLI config
 [app]
 class_name = zensols.mimicsid.Application
 corpus = instance: mimic_corpus
@@ -83,24 +83,25 @@
 note_stash = instance: mimicsid_note_stash
 section_predictor = instance: mimicsid_section_predictor
 
 [app_decorator]
 option_excludes = dict: {
   'corpus', 'anon_resource', 'note_stash', 'config_factory', 'model_packer_name'}
 option_overrides = dict:
-  {'hadm_id': {'long_name': 'adm'},
+  {'hadm_id': {'long_name': 'hadm'},
    'note_category': {'long_name': 'cat'},
    'section_id': {'long_name': 'sec'},
    'output_format': {'long_name': 'format', 'short_name': 'f'}}
 mnemonic_overrides = dict:
   {'dump_ontology': 'ontology',
-   'dump_note_ids': 'noteids',
-   'write_note': 'note'}
+   'write_note': 'note',
+   'admission_notes': 'notes',
+   'note_counts_by_admission': 'admissions'}
 
 [pred_app_decorator]
 option_excludes = dict: {'note_stash', 'config_factory', 'section_predictor'}
 mnemonic_overrides = dict: {'predict_sections': 'predict'}
 option_overrides = dict: {
    'input_path': {'long_name': 'input', 'metavar': '<FILE|DIR>'},
-   'output_path': {'long_name': 'pout'},
-   'file_limit': {'long_name': 'flimit'},
-   'out_type': {'long_name': 'predfmt'}}
+   'output_path': {'long_name': 'path', 'metavar': '<FILE|DIR|->'},
+   'file_limit': {'long_name': 'plimit'},
+   'out_type': {'long_name': 'pformat'}}
```

## zensols/mimicsid/resources/model/obj.conf

```diff
@@ -68,7 +68,8 @@
 
 ## Predictor
 #
 [mimicsid_section_predictor]
 class_name = zensols.mimicsid.pred.SectionPredictor
 section_id_model_packer = instance: deeplearn_model_packer
 header_model_packer = instance: mimisid_model_packer_header
+min_section_body_len = 1
```

## Comparing `zensols.mimicsid-1.0.0.dist-info/METADATA` & `zensols.mimicsid-1.2.0.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 Metadata-Version: 2.1
 Name: zensols.mimicsid
-Version: 1.0.0
+Version: 1.2.0
 Summary: Use the MedSecId section annotations with MIMIC-III corpus parsing.
 Home-page: https://github.com/plandes/mimicsid
-Download-URL: https://github.com/plandes/mimicsid/releases/download/v1.0.0/zensols.mimicsid-1.0.0-py3-none-any.whl
+Download-URL: https://github.com/plandes/mimicsid/releases/download/v1.2.0/zensols.mimicsid-1.2.0-py3-none-any.whl
 Author: Paul Landes
 Author-email: landes@mailc.net
 Keywords: tooling
 Description-Content-Type: text/markdown
-Requires-Dist: zensols.deepnlp (~=1.7.0)
-Requires-Dist: zensols.mimic (~=1.0.0)
+Requires-Dist: zensols.deepnlp (~=1.9.0)
+Requires-Dist: zensols.mimic (~=1.2.0)
 
 # MIMIC-III corpus parsing and section prediction with MedSecId
 
 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7150451.svg)](https://doi.org/10.5281/zenodo.7150451)
 [![PyPI][pypi-badge]][pypi-link]
 [![Python 3.9][python39-badge]][python39-link]
 [![Python 3.10][python310-badge]][python310-link]
@@ -206,43 +206,44 @@
 
 ### Preprocessing Step
 
 1. To train the model, first install the MIMIC-III Postgres database per the [mimic
    package] instructions in the *Installation* section.
 2. Add the MIMIC-III Postgres credentials and database configuration to
    `etc/batch.conf`.
-2. Vectorize the batches: `./mimicsid batch -c etc/batch.conf`.  This also
-   creates cached hospital admission and spaCy data parse files.
+3. Comment out the line `resource(zensols.mimicsid): resources/model/adm.conf`
+   in `resources/app.conf`.
+4. Vectorize the batches using the preprocessing script:
+   `$ ./src/bin/preprocess.sh`.  This also creates cached hospital admission and
+   spaCy data parse files.
 
 
 ### Training and Testing
 
 To get performance metrics on the test set by training on the training, use the
 command: `./mimicsid traintest -c models/glove300.conf` for the section ID
 model.  The configuration file can be any of those in the `models` directory.
 For the header model use:
 
 ```bash
 ./mimicsid traintest -c models/glove300.conf --override mimicsid_default.model_type=header
 ```
 
 
-## Training Usable Models
+## Training Production Models
 
 To train models used in your projects, train the model on both the training and
 test sets.  This still leaves the validation set to inform when to save for
 epochs where the loss decreases:
 
-1. Train section ID/type the model: `./mimicsid trainprod -p`
-2. Package the model creating a distribution file: `./mimicsid pack`
-3. Do the same for the header model:
-```bash
-$ ./mimicsid trainprod -c models/glove300.conf -p --override mimicsid_default.model_type=header
-$ ./mimicsid pack -c models/glove300.conf --override mimicsid_default.model_type=header
-```
+1. Update the `deeplearn_model_packer:version` in `resources/app.conf`.
+2. Preprocess (see the [preprocessing](#preprocessing-step)) section.
+3. Run the script that trains the models and packages them: `src/bin/package.sh`.
+4. Check for errors and verify models: `$ ./src/bin/verify-model.py`.
+5. Don't forget to revert files `etc/batch.conf` and `resources/app.conf`.
 
 
 ## Models
 
 You can mix and match models across section vs. header models (see [Performance
 Metrics](#performance-metrics)).  By default the package uses the best
 performing models but you can select the model you want by adding a
@@ -275,14 +276,25 @@
 |-------------------------------|---------|----------------------------------------|-------|-------|-------|-------|
 | `BiLSTM-CRF_tok (fastText)`   | Section | bilstm-crf-tok-fasttext-section-type   | 0.918 | 0.925 | 0.797 | 0.925 |
 | `BiLSTM-CRF_tok (GloVE 300D)` | Section | bilstm-crf-tok-glove-300d-section-type | 0.917 | 0.922 | 0.809 | 0.922 |
 | `BiLSTM-CRF_tok (fastText)`   | Header  | bilstm-crf-tok-fasttext-header         | 0.996 | 0.996 | 0.959 | 0.996 |
 | `BiLSTM-CRF_tok (GloVE 300D)` | Header  | bilstm-crf-tok-glove-300d-header       | 0.996 | 0.996 | 0.962 | 0.996 |
 
 
+The model version 0.0.3 validation results:
+
+| Name                          | Type    | Id                                     | wF1   | mF1   | MF1   | acc   |
+|-------------------------------|---------|----------------------------------------|-------|-------|-------|-------|
+| `BiLSTM-CRF_tok (fastText)`   | Section | bilstm-crf-tok-fasttext-section-type   | 0.918 | 0.925 | 0.797 | 0.925 |
+| `BiLSTM-CRF_tok (GloVE 300D)` | Section | bilstm-crf-tok-glove-300d-section-type | 0.917 | 0.922 | 0.809 | 0.922 |
+| `BiLSTM-CRF_tok (fastText)`   | Header  | bilstm-crf-tok-fasttext-header         | 0.996 | 0.996 | 0.959 | 0.996 |
+| `BiLSTM-CRF_tok (GloVE 300D)` | Header  | bilstm-crf-tok-glove-300d-header       | 0.996 | 0.996 | 0.962 | 0.996 |
+
+
+
 ## Citation
 
 If you use this project in your research please use the following BibTeX entry:
 
 ```bibtex
 @inproceedings{landes-etal-2022-new,
     title = "A New Public Corpus for Clinical Section Identification: {M}ed{S}ec{I}d",
```

## Comparing `zensols.mimicsid-1.0.0.dist-info/RECORD` & `zensols.mimicsid-1.2.0.dist-info/RECORD`

 * *Files 23% similar despite different names*

```diff
@@ -1,30 +1,31 @@
-zensols/mimicsid/__init__.py,sha256=26STYF62gRhDTwDmD2sxiqWOceUWryoT9lLjNNUXb9I,179
-zensols/mimicsid/anon.py,sha256=I-v3CmqRwZih_Al9PZR5LiwECrHoZVDbaKOfIL43aNQ,7748
-zensols/mimicsid/app.py,sha256=V4gqQjeiQrv3HDVdrc3QwSC_PoEEIWw5UH1rjAwuWTg,7222
-zensols/mimicsid/cli.py,sha256=hmhdCCjbI_MvCHzV7LOSoAZNP6OA_JfFFApBfgHjXwo,1984
-zensols/mimicsid/domain.py,sha256=XugCGBGmwF1ikGY9SFYV0KS9A12vf3GyrpdnBTZ1lWc,4375
-zensols/mimicsid/model.py,sha256=nI9HfiM_8y9tB2qyXlN9g-zddSue_e5Dee6z7LTq1iU,11244
-zensols/mimicsid/pred.py,sha256=o67V9DHvP_lFKgG6b92duGa_VzYqG1zgInMFN-e5pas,6897
-zensols/mimicsid/resources/app.conf,sha256=l7DezBP0p_f9x-iQWuWFu6dViWxqXG9gScYJX4Nl00g,3738
+zensols/mimicsid/__init__.py,sha256=JHKDMq4dryfbqqGeX7xX5Zu-yl-_j1iez0MQA62FksQ,372
+zensols/mimicsid/anon.py,sha256=ZSFOLZpGs67ACbgH-XNBj4VQiKJcxfDsM5Ymnw4Bxyk,8710
+zensols/mimicsid/app.py,sha256=LKvGiQAVt8Bsw8sFumU2t9LT2vL7truH9Uo8MOcaUss,8774
+zensols/mimicsid/cli.py,sha256=asqiTgZmD2xP5ZLxUeYAKhfwSVVORWmMsYiswf9tXfY,2245
+zensols/mimicsid/domain.py,sha256=qAamHW3IM8e4zuBZEop5-xlqKzv1ThZ0OoBGA20zZ2c,6706
+zensols/mimicsid/model.py,sha256=gXLDSXOUgXTg1aXgOozXvS47bbVcNiWCkouDCUwW8kE,11248
+zensols/mimicsid/pred.py,sha256=Rv8hCZ0W8f2iGNPybFvagHbfuOwjcS-4RChKYt0-Tqw,9794
+zensols/mimicsid/resources/app.conf,sha256=MuDw28WBJrZV0YfQaUQgXA0wVwBe_rVt9E9etQrZE9g,3813
 zensols/mimicsid/resources/default.conf,sha256=6NhgsH151w4uF0Q4jm-aNgSomxxyWpmNMnQmormLWqA,234
 zensols/mimicsid/resources/obj.conf,sha256=IdtXNDNCdTZWIMamSxvCs3wOGFBwGz9TnJPcwyhki1U,1736
 zensols/mimicsid/resources/ontology.csv,sha256=-j4-WCO7olEqGXSRhz8CLtBVzk9tgDDcmz5yatqKVT0,17014
+zensols/mimicsid/resources/model/adm.conf,sha256=i7vhpkaj6p9Iepv_mWobz8GuW5uKAmA-erb3KBMHM5g,606
 zensols/mimicsid/resources/model/batch.yml,sha256=6PXTkdbFSLNxmIK7N7whieD0NT89QBLHp9KeHh7rgrI,3491
 zensols/mimicsid/resources/model/default.conf,sha256=8Jv6lHGs3FWIizFMKthaf37wNy3AbGa8sfaImOXW9r4,1855
 zensols/mimicsid/resources/model/header-default.yml,sha256=kLAwSs5UNWcUyDS1CFqb8a25lJ7FuN92NHcey_GR4ME,660
 zensols/mimicsid/resources/model/header.yml,sha256=mNRuIK6nZVuBLLvy5mtLyNXVtIXg8xdjLwny9Bp5Jlg,239
 zensols/mimicsid/resources/model/model.conf,sha256=xzo8bSggaNJjyfZKs-VoyWUPAiySdRSzxwC6RtFsuF8,977
-zensols/mimicsid/resources/model/obj.conf,sha256=e7cESu55bGaROqyeRckEDZbC4CjJJes1WODAg67UTx0,2480
+zensols/mimicsid/resources/model/obj.conf,sha256=2ve48MkxgKIeIKP9Pet4mXJgN441-2ZG1nt2V7voZUQ,2504
 zensols/mimicsid/resources/model/section.conf,sha256=hUIv2Jirt2UkkM2xv5kqIQU93eY_ClOMsHHRncwUwQM,535
 zensols/mimicsid/resources/model/vectorizer.yml,sha256=SD8rHXqB4Bz-ofPsJZl2ZG7KaWrKOy7CgGVu67CyNwE,2795
 zensols/mimicsid/resources/model/pkg/all.conf,sha256=Pf-_Peswai-QmVEtU6_yHCpO17hATizoRwntlaRGCjw,319
 zensols/mimicsid/resources/model/pkg/default.conf,sha256=B_osNOKJVUqrvECEgNYlDOZAx6AKwW2MRhwnJ-qXXVU,622
 zensols/mimicsid/resources/model/pkg/obj.conf,sha256=6ECPTvU3Rzdh38zwOJjOiWKJWTsARUP9Z7I9xd2zDpw,609
 zensols/mimicsid/resources/pkg/all.conf,sha256=qDQo7EvGq3qw7_jkfXhE4I_xhk7RWypvtAaqfZ6WdAY,270
 zensols/mimicsid/resources/pkg/default.conf,sha256=Cu-gXV1Eleu1zdvUj8lP2gDAgcnOI-M3ojo4SsN7tM8,631
 zensols/mimicsid/resources/pkg/obj.conf,sha256=6ECPTvU3Rzdh38zwOJjOiWKJWTsARUP9Z7I9xd2zDpw,609
-zensols.mimicsid-1.0.0.dist-info/METADATA,sha256=4khlyGGth1CeQTFs6qkOp3A1k2YKGubzVDKsDDa-J1k,13118
-zensols.mimicsid-1.0.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-zensols.mimicsid-1.0.0.dist-info/entry_points.txt,sha256=qHKNomNkAWLkHcMEAQKGrEa19p7ktdKPdCMC0YEjYMM,51
-zensols.mimicsid-1.0.0.dist-info/top_level.txt,sha256=emPWDAeAZybgbxenG_I5wnf3qHa-HW6MwLlSmxAv5mo,17
-zensols.mimicsid-1.0.0.dist-info/RECORD,,
+zensols.mimicsid-1.2.0.dist-info/METADATA,sha256=kzvhyau5EcacxJL_UE5XZR3qmfvj6H_on5ru-XXe-eU,14009
+zensols.mimicsid-1.2.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+zensols.mimicsid-1.2.0.dist-info/entry_points.txt,sha256=qHKNomNkAWLkHcMEAQKGrEa19p7ktdKPdCMC0YEjYMM,51
+zensols.mimicsid-1.2.0.dist-info/top_level.txt,sha256=emPWDAeAZybgbxenG_I5wnf3qHa-HW6MwLlSmxAv5mo,17
+zensols.mimicsid-1.2.0.dist-info/RECORD,,
```

