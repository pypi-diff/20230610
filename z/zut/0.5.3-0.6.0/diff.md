# Comparing `tmp/zut-0.5.3-py3-none-any.whl.zip` & `tmp/zut-0.6.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,37 +1,55 @@
-Zip file size: 37751 bytes, number of entries: 35
--rw-rw-rw-  2.0 fat     1565 b- defN 22-Nov-16 10:36 zut/__init__.py
--rw-rw-rw-  2.0 fat      249 b- defN 22-Nov-10 19:06 zut/__main__.py
--rw-rw-rw-  2.0 fat      302 b- defN 22-Nov-15 08:03 zut/apps.py
--rw-rw-rw-  2.0 fat     6963 b- defN 22-Nov-10 18:14 zut/commands.py
--rw-rw-rw-  2.0 fat     9590 b- defN 22-Nov-10 14:03 zut/credentials.py
--rw-rw-rw-  2.0 fat     2720 b- defN 22-Nov-10 19:05 zut/env.py
--rw-rw-rw-  2.0 fat     5749 b- defN 22-Nov-10 09:39 zut/flexout.py
--rw-rw-rw-  2.0 fat    10853 b- defN 22-Nov-10 17:15 zut/format.py
--rw-rw-rw-  2.0 fat     2548 b- defN 22-Nov-10 11:15 zut/git.py
--rw-rw-rw-  2.0 fat     1536 b- defN 22-Nov-10 10:26 zut/gpg.py
--rw-rw-rw-  2.0 fat     3910 b- defN 22-Nov-10 11:45 zut/logging.py
--rw-rw-rw-  2.0 fat     9587 b- defN 22-Nov-10 17:45 zut/tools.py
--rw-rw-rw-  2.0 fat      181 b- defN 22-Nov-16 11:18 zut/version.py
--rw-rw-rw-  2.0 fat     4546 b- defN 22-Nov-10 11:02 zut/db/__init__.py
--rw-rw-rw-  2.0 fat       42 b- defN 22-Oct-19 07:42 zut/db/postgresql/010_extensions.sql
--rw-rw-rw-  2.0 fat      742 b- defN 22-Oct-19 07:42 zut/db/postgresql/020_slugen.sql
--rw-rw-rw-  2.0 fat     3272 b- defN 22-Nov-10 11:48 zut/db/postgresql/__init__.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-09 16:24 zut/django/management/__init__.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-09 16:24 zut/django/management/commands/__init__.py
--rw-rw-rw-  2.0 fat     6931 b- defN 22-Nov-09 16:24 zut/django/management/commands/reinit.py
--rw-rw-rw-  2.0 fat      467 b- defN 22-Nov-09 16:24 zut/django/management/commands/seed_zut.py
--rw-rw-rw-  2.0 fat     3271 b- defN 22-Nov-10 11:02 zut/django/middleware/__init__.py
--rw-rw-rw-  2.0 fat       71 b- defN 22-Nov-10 11:47 zut/django/templatetags/__init__.py
--rw-rw-rw-  2.0 fat     2808 b- defN 22-Nov-09 16:24 zut/django/templatetags/static_lib.py
--rw-rw-rw-  2.0 fat     1652 b- defN 22-Nov-09 16:24 zut/django/views/MarkdownTemplateView.py
--rw-rw-rw-  2.0 fat       56 b- defN 22-Nov-09 16:24 zut/django/views/__init__.py
--rw-rw-rw-  2.0 fat     8885 b- defN 22-Nov-16 10:49 zut/network/__init__.py
--rw-rw-rw-  2.0 fat     3850 b- defN 22-Nov-16 10:59 zut/network/commons.py
--rw-rw-rw-  2.0 fat     2961 b- defN 22-Nov-16 10:59 zut/network/winhttp.py
--rw-rw-rw-  2.0 fat     1066 b- defN 22-Nov-16 11:18 zut-0.5.3.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     3779 b- defN 22-Nov-16 11:18 zut-0.5.3.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 22-Nov-16 11:18 zut-0.5.3.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       42 b- defN 22-Nov-16 11:18 zut-0.5.3.dist-info/entry_points.txt
--rw-rw-rw-  2.0 fat        4 b- defN 22-Nov-16 11:18 zut-0.5.3.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     2780 b- defN 22-Nov-16 11:18 zut-0.5.3.dist-info/RECORD
-35 files, 103070 bytes uncompressed, 33345 bytes compressed:  67.6%
+Zip file size: 61454 bytes, number of entries: 53
+-rw-r--r--  2.0 unx     1879 b- defN 23-Jun-10 13:53 zut/__init__.py
+-rw-r--r--  2.0 unx      160 b- defN 23-Jun-10 14:06 zut/_version.py
+-rw-r--r--  2.0 unx      263 b- defN 23-Jun-10 13:46 zut/apps.py
+-rw-r--r--  2.0 unx      915 b- defN 23-Jun-10 13:46 zut/colors.py
+-rw-r--r--  2.0 unx     5337 b- defN 23-Jun-10 13:46 zut/commands.py
+-rw-r--r--  2.0 unx     9123 b- defN 23-Jun-10 13:46 zut/credentials.py
+-rw-r--r--  2.0 unx     1175 b- defN 23-Jun-10 13:53 zut/csv.py
+-rw-r--r--  2.0 unx     1436 b- defN 23-Jun-10 13:46 zut/datetime.py
+-rw-r--r--  2.0 unx    16858 b- defN 23-Jun-10 13:53 zut/excel.py
+-rw-r--r--  2.0 unx     8086 b- defN 23-Jun-10 13:46 zut/filesh.py
+-rw-r--r--  2.0 unx     2508 b- defN 23-Jun-10 13:46 zut/git.py
+-rw-r--r--  2.0 unx     1494 b- defN 23-Jun-10 13:46 zut/gpg.py
+-rw-r--r--  2.0 unx     4770 b- defN 23-Jun-10 13:46 zut/json.py
+-rw-r--r--  2.0 unx     4401 b- defN 23-Jun-10 13:46 zut/logging.py
+-rw-r--r--  2.0 unx     3441 b- defN 23-Jun-10 13:46 zut/misc.py
+-rw-r--r--  2.0 unx     3030 b- defN 23-Jun-10 13:46 zut/numeric.py
+-rw-r--r--  2.0 unx     1987 b- defN 23-Jun-10 13:46 zut/tabular.py
+-rw-r--r--  2.0 unx     1949 b- defN 23-Jun-10 13:46 zut/text.py
+-rw-r--r--  2.0 unx     1581 b- defN 23-Jun-10 13:46 zut/db/__init__.py
+-rw-r--r--  2.0 unx    13475 b- defN 23-Jun-10 13:46 zut/db/commons.py
+-rw-r--r--  2.0 unx     2288 b- defN 23-Jun-10 13:46 zut/db/mssql.py
+-rw-r--r--  2.0 unx     8293 b- defN 23-Jun-10 13:46 zut/db/pg.py
+-rw-r--r--  2.0 unx       41 b- defN 23-Jun-10 13:46 zut/db/sql_pg/010_extensions.sql
+-rw-r--r--  2.0 unx      464 b- defN 23-Jun-10 13:46 zut/db/sql_pg/020_slugify.sql
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-10 13:46 zut/django/management/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-10 13:46 zut/django/management/commands/__init__.py
+-rw-r--r--  2.0 unx     6745 b- defN 23-Jun-10 13:46 zut/django/management/commands/reinit.py
+-rw-r--r--  2.0 unx      454 b- defN 23-Jun-10 13:46 zut/django/management/commands/seed_zut.py
+-rw-r--r--  2.0 unx     3191 b- defN 23-Jun-10 13:46 zut/django/middleware/__init__.py
+-rw-r--r--  2.0 unx       70 b- defN 23-Jun-10 13:46 zut/django/templatetags/__init__.py
+-rw-r--r--  2.0 unx     2718 b- defN 23-Jun-10 13:46 zut/django/templatetags/static_lib.py
+-rw-r--r--  2.0 unx     1609 b- defN 23-Jun-10 13:46 zut/django/views/MarkdownTemplateView.py
+-rw-r--r--  2.0 unx       55 b- defN 23-Jun-10 13:46 zut/django/views/__init__.py
+-rw-r--r--  2.0 unx     1722 b- defN 23-Jun-10 13:53 zut/inout/InCsv.py
+-rw-r--r--  2.0 unx     1697 b- defN 23-Jun-10 13:46 zut/inout/InDb.py
+-rw-r--r--  2.0 unx     1401 b- defN 23-Jun-10 13:46 zut/inout/InExcel.py
+-rw-r--r--  2.0 unx     4023 b- defN 23-Jun-10 13:46 zut/inout/InTable.py
+-rw-r--r--  2.0 unx     4547 b- defN 23-Jun-10 13:46 zut/inout/OutCsv.py
+-rw-r--r--  2.0 unx     2513 b- defN 23-Jun-10 13:46 zut/inout/OutDb.py
+-rw-r--r--  2.0 unx     3151 b- defN 23-Jun-10 13:46 zut/inout/OutExcel.py
+-rw-r--r--  2.0 unx     3138 b- defN 23-Jun-10 13:53 zut/inout/OutFile.py
+-rw-r--r--  2.0 unx     9354 b- defN 23-Jun-10 13:46 zut/inout/OutTable.py
+-rw-r--r--  2.0 unx     1121 b- defN 23-Jun-10 13:46 zut/inout/OutTabulate.py
+-rw-r--r--  2.0 unx     6198 b- defN 23-Jun-10 13:46 zut/inout/__init__.py
+-rw-r--r--  2.0 unx     2734 b- defN 23-Jun-10 13:46 zut/inout/utils.py
+-rw-r--r--  2.0 unx     8906 b- defN 23-Jun-10 13:46 zut/network/__init__.py
+-rw-r--r--  2.0 unx     3729 b- defN 23-Jun-10 13:46 zut/network/commons.py
+-rw-r--r--  2.0 unx     2887 b- defN 23-Jun-10 13:46 zut/network/winhttp.py
+-rw-r--r--  2.0 unx     1048 b- defN 23-Jun-10 14:06 zut-0.6.0.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx     4693 b- defN 23-Jun-10 14:06 zut-0.6.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-10 14:06 zut-0.6.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        4 b- defN 23-Jun-10 14:06 zut-0.6.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4079 b- defN 23-Jun-10 14:06 zut-0.6.0.dist-info/RECORD
+53 files, 176833 bytes uncompressed, 55140 bytes compressed:  68.8%
```

## zipnote {}

```diff
@@ -1,56 +1,77 @@
 Filename: zut/__init__.py
 Comment: 
 
-Filename: zut/__main__.py
+Filename: zut/_version.py
 Comment: 
 
 Filename: zut/apps.py
 Comment: 
 
+Filename: zut/colors.py
+Comment: 
+
 Filename: zut/commands.py
 Comment: 
 
 Filename: zut/credentials.py
 Comment: 
 
-Filename: zut/env.py
+Filename: zut/csv.py
 Comment: 
 
-Filename: zut/flexout.py
+Filename: zut/datetime.py
 Comment: 
 
-Filename: zut/format.py
+Filename: zut/excel.py
+Comment: 
+
+Filename: zut/filesh.py
 Comment: 
 
 Filename: zut/git.py
 Comment: 
 
 Filename: zut/gpg.py
 Comment: 
 
+Filename: zut/json.py
+Comment: 
+
 Filename: zut/logging.py
 Comment: 
 
-Filename: zut/tools.py
+Filename: zut/misc.py
+Comment: 
+
+Filename: zut/numeric.py
+Comment: 
+
+Filename: zut/tabular.py
 Comment: 
 
-Filename: zut/version.py
+Filename: zut/text.py
 Comment: 
 
 Filename: zut/db/__init__.py
 Comment: 
 
-Filename: zut/db/postgresql/010_extensions.sql
+Filename: zut/db/commons.py
 Comment: 
 
-Filename: zut/db/postgresql/020_slugen.sql
+Filename: zut/db/mssql.py
 Comment: 
 
-Filename: zut/db/postgresql/__init__.py
+Filename: zut/db/pg.py
+Comment: 
+
+Filename: zut/db/sql_pg/010_extensions.sql
+Comment: 
+
+Filename: zut/db/sql_pg/020_slugify.sql
 Comment: 
 
 Filename: zut/django/management/__init__.py
 Comment: 
 
 Filename: zut/django/management/commands/__init__.py
 Comment: 
@@ -72,35 +93,68 @@
 
 Filename: zut/django/views/MarkdownTemplateView.py
 Comment: 
 
 Filename: zut/django/views/__init__.py
 Comment: 
 
+Filename: zut/inout/InCsv.py
+Comment: 
+
+Filename: zut/inout/InDb.py
+Comment: 
+
+Filename: zut/inout/InExcel.py
+Comment: 
+
+Filename: zut/inout/InTable.py
+Comment: 
+
+Filename: zut/inout/OutCsv.py
+Comment: 
+
+Filename: zut/inout/OutDb.py
+Comment: 
+
+Filename: zut/inout/OutExcel.py
+Comment: 
+
+Filename: zut/inout/OutFile.py
+Comment: 
+
+Filename: zut/inout/OutTable.py
+Comment: 
+
+Filename: zut/inout/OutTabulate.py
+Comment: 
+
+Filename: zut/inout/__init__.py
+Comment: 
+
+Filename: zut/inout/utils.py
+Comment: 
+
 Filename: zut/network/__init__.py
 Comment: 
 
 Filename: zut/network/commons.py
 Comment: 
 
 Filename: zut/network/winhttp.py
 Comment: 
 
-Filename: zut-0.5.3.dist-info/LICENSE.txt
-Comment: 
-
-Filename: zut-0.5.3.dist-info/METADATA
+Filename: zut-0.6.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: zut-0.5.3.dist-info/WHEEL
+Filename: zut-0.6.0.dist-info/METADATA
 Comment: 
 
-Filename: zut-0.5.3.dist-info/entry_points.txt
+Filename: zut-0.6.0.dist-info/WHEEL
 Comment: 
 
-Filename: zut-0.5.3.dist-info/top_level.txt
+Filename: zut-0.6.0.dist-info/top_level.txt
 Comment: 
 
-Filename: zut-0.5.3.dist-info/RECORD
+Filename: zut-0.6.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## zut/__init__.py

```diff
@@ -1,24 +1,31 @@
-from __future__ import annotations
-
-try:
-    # Version generated by setuptools_scm during build
-    from .version import __version__
-except ImportError:
-    __version__ = None
-
-# Top-level API (available directly from "zut" namespace). Requires only default dependencies (colorlog, python-dotenv)
-from .commands import add_func_command, add_module_command, add_package_commands, add_object_commands, command, run_command, exec_command, call_command
-from .env import get_venv, configure_env
-from .format import BLACK, RED, GREEN, YELLOW, BLUE, GRAY, BOLD_RED, human_bytes, slugen, ExtendedJSONDecoder, ExtendedJSONEncoder, get_default_csv_dialect_name, format_subprocess_result, format_help_text, format_description_text
-from .git import get_git_tags, get_git_hash, git_has_changes, check_git_version_tag
-from .gpg import download_gpg_key, verify_gpg_signature
-from .logging import configure_logging, get_logging_dictconfig
-from .network import configure_proxy, check_connectivity, check_socket
-from .tools import BaseTools, clean, lso
-
-# NOTE: Inner API: the following features require extra dependencies.
-# zut.credentials               -> [credentials]: keyring, pywin32, tabulate
-# zut.db and zut.db.postgresql  -> [postgresql]: psycopg2, and optionally [django]: see below
-# zut.django                    -> [django]: django, djangorestframework (for zut.django.middleware), cmarkgfm (for zut.django.views.MarkdownTemplateView)
-# zut.flexout                   -> [flexout]: tabulate
-# zut.network.winhttp           -> [winhttp]: pywin32
+from __future__ import annotations
+
+try:
+    # Version generated by setuptools_scm during build
+    from ._version import __version__
+except ImportError:
+    __version__ = None
+
+# Top-level API (available directly from "zut" namespace). Does not require any dependency.
+from .colors import Colors
+from .commands import add_func_command, add_module_command, add_package_commands, run_command, exec_command
+from .csv import get_default_csv_delimiter
+from .datetime import now_aware, make_aware, is_aware
+from .filesh import configure_smb_credentials  # other functions should be called directly with the module, e.g. `from zut import filesh`, then `filesh.open_file(...)`
+from .git import get_git_tags, get_git_hash, git_has_changes, check_git_version_tag
+from .gpg import download_gpg_key, verify_gpg_signature
+from .inout import out_file, out_table, in_table, transfer_table, OutFile, OutTable, OutTabulate, OutCsv, OutExcel, OutDb, InTable, InCsv, InExcel, InDb
+from .json import ExtendedJSONDecoder, ExtendedJSONEncoder
+from .logging import configure_logging, DEFAULT_LOGGING_DICTCONFIG
+from .misc import ZUT_ROOT, Literal, Protocol, Self, check_completed_subprocess, get_venv, is_list_or_tuple_of
+from .network import configure_proxy, check_connectivity, check_socket
+from .numeric import human_bytes, parse_decimal
+from .text import slugify, slugify_snake, remove_whitespaces, remove_consecutive_whitespaces, reconfigure_encoding
+
+# NOTE: Inner API: the following features require extra dependencies.
+# zut.credentials       -> [credentials]
+# zut.db                -> [pg] or [mssql]
+# zut.django            -> [django]: django, djangorestframework (for zut.django.middleware), cmarkgfm (for zut.django.views.MarkdownTemplateView)
+# zut.excel             -> [excel]
+# zut.filesh         -> [smb] (for operations on Samba/Windows shares)
+# zut.network.winhttp   -> [winhttp]
```

## zut/apps.py

```diff
@@ -1,14 +1,13 @@
-"""
-Indicate Django application directory. Allows zut to be added in INSTALLED_APP with simple name:
-
-    INSTALLED_APP = [
-        ...
-        'zut',
-        ...
-    ]
-"""
-from django.apps import AppConfig
-from pathlib import Path
-
-class ZutAppConfig(AppConfig):
-    name = "zut.django"
+"""
+Indicate Django application directory. Allows zut to be added in INSTALLED_APP with simple name:
+
+    INSTALLED_APP = [
+        ...
+        'zut',
+        ...
+    ]
+"""
+from django.apps import AppConfig
+
+class ZutAppConfig(AppConfig):
+    name = "zut.django"
```

## zut/commands.py

```diff
@@ -1,195 +1,163 @@
-"""
-Add and execute commands easily, based on argparse.
-Usefull for non-Django applications.
-For Django applications, use including command management instead.
-"""
-from __future__ import annotations
-import logging, sys, argparse
-from types import CodeType, FunctionType, ModuleType
-from pathlib import Path
-from importlib import import_module
-from importlib.util import find_spec
-from .format import RED, format_help_text, format_description_text
-
-logger = logging.getLogger(__name__)
-
-
-def command(add_arguments: FunctionType = None, doc: str = None, name: str = None):
-    """
-    A decorator to define options for command functions.
-    """
-    def decorator(func):
-        if name is not None:
-            func.command_name = name
-        if doc is not None:
-            func.__doc__ = doc
-        if add_arguments is not None:
-            func.add_arguments = add_arguments
-        
-        return func
-    
-    return decorator
-
-
-def add_func_command(parser: argparse.ArgumentParser, func: FunctionType, name: str = None, add_arguments_func: FunctionType = None):
-    """
-    Add function `func` as subcommand `name` of `parser`.
-    """
-    # Determine help strings (from function docstring)
-    description = format_description_text(func.__doc__)
-    help = format_help_text(func.__doc__)
-
-    # Determine command options
-    if name is None:
-        name = getattr(func, "command_name", func.__name__)
-
-    if add_arguments_func is None:
-        add_arguments_func = _get_add_arguments(func)
-
-    # Determine command parser object
-    subparsers = get_subparsers(parser)
-    cmdparser = subparsers.add_parser(name, help=help, description=description, formatter_class=argparse.RawTextHelpFormatter)
-
-    # Add command
-    if add_arguments_func:
-        add_arguments_func(cmdparser)
-
-    if "func" in cmdparser._defaults:
-        raise ValueError(f"{name} command already has a registered func")
-    cmdparser.set_defaults(func=func)
-    
-    return cmdparser
-
-
-def add_module_command(parser: argparse.ArgumentParser, module: str|ModuleType, name: str = None):
-    """
-    Add command from functions in a module. By default, command function is expected to be named "handler"
-    and arguments definition function is expected to be named "add_arguments".
-    """
-    if not isinstance(module, ModuleType):
-        module = import_module(module)
-
-    func = getattr(module, "handle")
-
-    if name is None:
-        name = getattr(func, "command_name", None)
-        if name is None:
-            name = module.__name__.split(".")[-1]
-    
-    add_arguments_func = getattr(module, "add_arguments", None)
-    if not add_arguments_func:
-        add_arguments_func = _get_add_arguments(func)
-    
-    add_func_command(parser, func, name=name, add_arguments_func=add_arguments_func)
-
-
-def add_package_commands(parser: argparse.ArgumentParser, package: str):
-    package_spec = find_spec(package)
-    if not package_spec:
-        raise KeyError(f"package not found: {package}")
-    if not package_spec.origin:
-        raise KeyError(f"not a package: {package} (did you forget __init__.py ?)")
-    package_path = Path(package_spec.origin).parent
-    
-    for module_path in package_path.iterdir():
-        if module_path.is_dir() or module_path.name.startswith("_") or not module_path.name.endswith(".py"):
-            continue
-
-        module = module_path.stem
-        add_module_command(parser, f"{package}.{module}")
-
-
-def add_object_commands(parser: argparse.ArgumentParser, instance: any, exclude = []):
-    for name in dir(instance):
-        if exclude and name in exclude:
-            continue
-
-        if name.startswith("_") or name in ["exec"]:
-            continue
-
-        func = getattr(instance, name)
-        if not callable(func):
-            continue
-
-        add_func_command(parser, func, add_arguments_func=getattr(instance, f"_{name}_add_arguments", None))
-
-
-def run_command(parser: argparse.ArgumentParser, *args, default_func: FunctionType = None, default_add_arguments_func: FunctionType = None):
-    """
-    Run the command-line application, returning command result.
-    """    
-    args, unknown = parser.parse_known_args(*args)
-    args = vars(args)
-    func = args.pop('func', None)
-
-    if func:
-        if unknown:
-            parser.print_usage(file=sys.stderr)
-            print(f"{parser.prog}: error: unrecognized arguments: {' '.join(unknown)}", file=sys.stderr)
-            return 2
-
-    elif default_func:
-        default_parser = argparse.ArgumentParser(prog=f"{parser.prog} (default)")
-
-        if not default_add_arguments_func:
-            default_add_arguments_func = _get_add_arguments(default_func)
-            if default_add_arguments_func:
-                default_add_arguments_func(default_parser)
-
-        args = vars(default_parser.parse_args(*args))
-        func = default_func
-
-    else:
-        print(RED % "missing command name", file=sys.stderr)
-        return 2
-
-    return func(**args)
-
-
-def exec_command(parser: argparse.ArgumentParser, *args, default_func: FunctionType = None, default_add_arguments_func: FunctionType = None):
-    """
-    Run the command-line application and exit with appropriate return code.
-    """
-    r = run_command(*args, parser=parser, default_func=default_func, default_add_arguments_func=default_add_arguments_func)
-    if not isinstance(r, int):
-        r = 0 if r is None or r is True else 1
-    sys.exit(r)
-
-
-def call_command(cmd: str, *args: any, parser: argparse.ArgumentParser = None):
-    if parser is None:
-        #TODO/ROADMAP: better detection of default parser?
-        from __main__ import parser
-
-    cmd_with_args = [cmd] + [str(arg) for arg in args]
-    return run_command(parser, *cmd_with_args)
-
-
-def _get_add_arguments(func: FunctionType) -> FunctionType:
-    """
-    Return the `add_arguments` function, defined as a function attribute, or nested in `func`.
-    Return `None` if inexistant.
-    """
-    add_arguments_func = getattr(func, 'add_arguments', None)
-
-    if add_arguments_func:
-        return add_arguments_func
-
-    consts = func.__code__.co_consts
-    for item in consts:
-        if isinstance(item, CodeType) and item.co_name == "add_arguments":
-            try:
-                return FunctionType(item, globals())
-            except:
-                logger.exception(f"cannot use `add_arguments` nested in function `{func.__name__}`")
-                return None
-
-
-def get_subparsers(parser: argparse.ArgumentParser) -> argparse._SubParsersAction:
-    """
-    Get or create the subparsers object associated with the given parser.
-    """
-    if parser._subparsers is not None:
-        return next(filter(lambda action: isinstance(action, argparse._SubParsersAction), parser._subparsers._actions))
-    else:
-        return parser.add_subparsers()
+"""
+Add and execute commands easily, based on argparse.
+Usefull for non-Django applications.
+For Django applications, use including command management instead.
+"""
+from __future__ import annotations
+import logging, sys
+from argparse import ArgumentParser, RawTextHelpFormatter, _SubParsersAction
+from types import FunctionType, ModuleType
+from pathlib import Path
+from importlib import import_module
+from importlib.util import find_spec
+from .colors import Colors
+
+logger = logging.getLogger(__name__)
+
+
+def add_func_command(parser: ArgumentParser, func: FunctionType, add_arguments: FunctionType = None, name: str = None, doc: str = None):
+    """
+    Add the given function as a subcommand of the parser.
+    """
+    if name is None:
+        name = func.__name__
+    if doc is None:
+        doc = func.__doc__
+
+    subparsers = get_subparsers(parser)
+    cmdparser: ArgumentParser = subparsers.add_parser(name, help=get_help_text(doc), description=get_description_text(doc), formatter_class=RawTextHelpFormatter)
+    cmdparser.set_defaults(func=func)
+
+    if add_arguments:
+        add_arguments(cmdparser)
+
+    return cmdparser
+
+
+def add_module_command(parser: ArgumentParser, module: str|ModuleType, name: str = None, doc: str = None):
+    """
+    Add the given module as a subcommand of the parser.
+    
+    The command function must be named `handler` and the arguments definition function, if any, must be named `add_arguments`.
+    """
+    if not isinstance(module, ModuleType):
+        module = import_module(module)
+
+    func = getattr(module, 'handle')
+
+    if name is None:
+        name = module.__name__.split(".")[-1]
+        if name.endswith('cmd') and len(name) > len('cmd'):
+            name = name[0:-len('cmd')]
+    
+    add_arguments = getattr(module, 'add_arguments', None)
+    add_func_command(parser, func, add_arguments=add_arguments, name=name, doc=doc)
+
+
+def add_package_commands(parser: ArgumentParser, package: str):
+    """
+    Add all modules in the given package as subcommands of the parser.
+    """
+    package_spec = find_spec(package)
+    if not package_spec:
+        raise KeyError(f"package not found: {package}")
+    if not package_spec.origin:
+        raise KeyError(f"not a package: {package} (did you forget __init__.py ?)")
+    package_path = Path(package_spec.origin).parent
+    
+    for module_path in package_path.iterdir():
+        if module_path.is_dir() or module_path.name.startswith("_") or not module_path.name.endswith(".py"):
+            continue
+
+        module = module_path.stem
+        add_module_command(parser, f"{package}.{module}")
+
+
+def get_subparsers(parser: ArgumentParser) -> _SubParsersAction:
+    """
+    Get or create the subparsers object associated with the given parser.
+    """
+    if isinstance(parser, _SubParsersAction):
+        return parser
+    elif parser._subparsers is not None:
+        return next(filter(lambda action: isinstance(action, _SubParsersAction), parser._subparsers._actions))
+    else:
+        return parser.add_subparsers()
+
+
+def get_help_text(docstring: str):
+    if docstring is None:
+        return None
+    
+    docstring = docstring.strip()
+    try:
+        return docstring[0:docstring.index('\n')].strip()
+    except:
+        return docstring
+
+
+def get_description_text(docstring: str):
+    if docstring is None:
+        return None
+    
+    description = None
+    indent_size = 0
+    
+    for line in docstring.splitlines(keepends=False):
+        if description:
+            description += '\n' + line[indent_size:]
+        else:
+            indent_size = 0
+            for char in line:
+                if char not in [' ', '\t']:
+                    description = line[indent_size:]
+                    break
+                else:
+                    indent_size += 1
+
+    return description
+
+
+def run_command(parser: ArgumentParser, *args, default_func: FunctionType = None, default_add_arguments: FunctionType = None):
+    """
+    Run the command-line application, returning command result.
+    """    
+    func_args, unknown = parser.parse_known_args(*args)
+    func_args = vars(func_args)
+    func = func_args.pop('func', None)
+
+    if func:
+        if unknown:
+            parser.print_usage(file=sys.stderr)
+            print(f"{parser.prog}: error: unrecognized arguments: {' '.join(unknown)}", file=sys.stderr)
+            return 2
+
+    elif default_func:
+        default_parser = ArgumentParser(prog=f"{parser.prog} (default)", formatter_class=RawTextHelpFormatter)
+
+        if default_add_arguments:
+            default_add_arguments(default_parser)
+
+        func_args = vars(default_parser.parse_args(*args))
+        func = default_func
+
+    else:
+        print(f"{Colors.RED}missing command name{Colors.RESET}", file=sys.stderr)
+        return 2
+
+    try:
+        return func(**func_args)
+    except KeyboardInterrupt:
+        logging.getLogger(__name__).error("interrupted")
+        return 1
+
+
+def exec_command(parser: ArgumentParser, *args, default_func: FunctionType = None, default_add_arguments: FunctionType = None):
+    """
+    Run the command-line application and exit with appropriate return code.
+    """
+    r = run_command(*args, parser=parser, default_func=default_func, default_add_arguments=default_add_arguments)
+
+    if not isinstance(r, int):
+        r = 0 if r is None or r is True else 1
+    exit(r)
```

## zut/credentials.py

```diff
@@ -1,246 +1,243 @@
-from __future__ import annotations
-import os, sys, subprocess
-from datetime import datetime     
-from getpass import getpass
-from tabulate import tabulate
-from .commands import command
-
-
-if sys.platform == "win32":
-    from keyring.backends.Windows import WinVaultKeyring
-    import win32cred
-
-    # See: https://docs.microsoft.com/en-us/windows/win32/api/wincred/ns-wincred-credentiala
-    CRED_TYPE_GENERIC = 1 # The credential is a generic credential. The credential will not be used by any particular authentication package. The credential will be stored securely but has no other significant characteristics.
-    CRED_TYPE_DOMAIN_PASSWORD = 2 # The credential is a password credential and is specific to Microsoft's authentication packages. The NTLM, Kerberos, and Negotiate authentication packages will automatically use this credential when connecting to the named target.
-    CRED_TYPE_DOMAIN_CERTIFICATE = 3 # The credential is a certificate credential and is specific to Microsoft's authentication packages. The Kerberos, Negotiate, and Schannel authentication packages automatically use this credential when connecting to the named target.
-
-    enumerate_additional_props = ["LastWritten", "TargetAlias", "Comment", "Type", "Flags", "CredentialBlob"]
-    ENUMERATE_HEADERS = ["Service", "Username", *enumerate_additional_props]
-
-    def enumerate_credentials(service=None, username=None):
-        if service is not None:
-            service = service.lower()
-        if username is not None:
-            username = username.lower()
-        
-        for cred in win32cred.CredEnumerate():
-            cred_service = cred["TargetName"]
-            cred_username = cred["UserName"]
-
-            # Filter
-            if service is not None:
-                if not service in cred_service.lower():
-                    continue
-            if username is not None:
-                if cred_username is None or not username in cred_username.lower():
-                    continue
-
-            # Additional properties
-            props = []
-            for prop in enumerate_additional_props:
-                if prop == "CredentialBlob":
-                    props.append("X" if cred[prop] else "")
-                elif prop == "Type":
-                    indication = ""
-                    if cred["Type"] == CRED_TYPE_GENERIC:
-                        indication = "generic"
-                    elif cred["Type"] == CRED_TYPE_DOMAIN_PASSWORD:
-                        indication = "domain password"
-                    elif cred["Type"] == CRED_TYPE_DOMAIN_CERTIFICATE:
-                        indication = "domain certificate"
-                    props.append(str(cred[prop]) + (" (%s)" % indication if indication else ""))
-                else:
-                    props.append(cred[prop])
-
-            yield [cred_service, cred_username, *props]
-    
-
-    def get_username(service):
-        for cred in win32cred.CredEnumerate():
-            if cred["Type"] == CRED_TYPE_GENERIC and cred["TargetName"] == service and cred["UserName"]:
-                return cred["UserName"]
-
-        # not found in credential manager
-        return None
-
-
-    _keyring = None
-
-    def _get_keyring():
-        global _keyring
-        if _keyring is None:
-            _keyring = WinVaultKeyring()
-        return _keyring
-
-    def get_password(service, username):
-        return _get_keyring().get_password(service, username)
-
-
-    def set_password(service, username, password):
-        return _get_keyring().set_password(service, username, password)
-
-
-    def delete_password(service, username):
-        return _get_keyring().delete_password(service, username)
-
-
-else:
-    import re
-    from glob import glob
-    from .format import format_subprocess_result
-
-    _several_slashes_re = re.compile(r"/{2,}")
-
-    def _sanitize_part(part):
-        """ Replace several slashes with only one """
-        if not part:
-            return part
-        part = part.replace("://", ":")
-        return _several_slashes_re.sub("/", part)
-        
-    def _get_key(service, username):
-        return os.path.join(
-            _sanitize_part(service),
-            _sanitize_part(username),
-        ).rstrip("/")
-    
-    ENUMERATE_HEADERS = ["Service", "Username", "LastWritten", "Path"]
-
-    def enumerate_credentials(service=None, username=None):
-        if service is not None:
-            service = _sanitize_part(service.lower())
-        if username is not None:
-            username = _sanitize_part(username.lower())
-
-        prefix = os.path.expanduser("~/.password-store/")
-        for path in glob(f"{prefix}**/*.gpg", recursive=True):
-            name_without_extension = path[:-4]
-            name_parts = name_without_extension[len(prefix):].rsplit("/", 1)
-            if len(name_parts) == 0:             
-                cred_service = ""
-                cred_username = ""
-            elif len(name_parts) == 1:                
-                cred_service = name_parts[0]
-                cred_username = ""
-            else:
-                cred_service = "/".join(name_parts[:-1])
-                cred_username = name_parts[-1]
-
-            # Filter
-            if service is not None:
-                if not service in cred_service.lower():
-                    continue
-            if username is not None:
-                if cred_username or not username in cred_username.lower():
-                    continue
-
-            last_written = datetime.fromtimestamp(os.path.getmtime(path))
-            yield [cred_service, cred_username, last_written, path]
-
-        
-    def get_username(service):
-        service = _sanitize_part(service)
-        for cred in enumerate_credentials():
-            if cred[0] == service:
-                return cred[1]
-
-        # not found in credential manager
-        return None
-
-    
-    _not_in_the_password_store_re = re.compile(r"^Error: .+ is not in the password store.$")
-    def get_password(service, username):
-        key = _get_key(service, username)
-        try:
-            cp = subprocess.run(["pass", "show", key], capture_output=True, check=True, text=True)
-        except subprocess.CalledProcessError as err:
-            if cp.returncode == 1 and _not_in_the_password_store_re.match(cp.stderr):
-                return None
-            else:
-                raise err
-        return cp.stdout.splitlines()[0]
-
-
-    def set_password(service, username, password):
-        if not service:
-            raise ValueError("service cannot be empty")
-
-        password = password.splitlines()[0]
-        inp = '%s\n' % password
-        inp *= 2
-        
-        key = _get_key(service, username)
-        subprocess.run(['pass', 'insert', '--force', key], input=inp, capture_output=True, check=True, text=True)
-
-
-    def delete_password(service, username):
-        key = _get_key(service, username)
-        subprocess.run(['pass', 'rm', '--force', key], check=True, capture_output=True)
-
-
-def add_arguments(parser):
-    parser.add_argument("action", nargs="?", choices=["list", "ls", "get", "set", "delete", "del", "rm"], default="list", help="action to perform")
-    parser.add_argument("service", nargs="?", help="service name")
-    parser.add_argument("username", nargs="?", help="user name")
-
-
-def handle(action: str = None, service: str = None, username: str = None):
-    """
-    List, get or set credentials from the credentials manager.
-    """    
-    if action == "get":
-        # Get a credential
-        if not service:
-            service = input("Service: ")
-        if not username:
-            username = input(f"Username for service \"{service}\": ")
-        print(get_password(service, username))
-
-    elif action == "set":
-        # Set a credential
-        if not service:
-            service = input("Service: ")
-        if not username:
-            username = input(f"Username for service \"{service}\": ")
-        set_password(service, username, getpass(f"Password for service \"{service}\" (username: \"{username}\"): "))
-
-    elif action in ["delete", "del", "rm"]:
-        # Delete a credential
-        if not service:
-            service = input("Service: ")
-        if not username:
-            username = input(f"Username for service \"{service}\": ")
-        delete_password(service, username)
-
-    else: # list
-
-        # Search/list available credentials
-        if sys.platform == "win32":
-            print("See: rundll32.exe keymgr.dll, KRShowKeyMgr")
-        else:
-            print("See: find ~/.password-store -type f -name '*.gpg'")
-            
-        rows = []
-        for cred in enumerate_credentials(service=service, username=username):
-            rows.append(cred)
-
-        rows.sort(key=lambda row: row[0].lower())
-
-        # Display LastWritten as simplified local time
-        try:
-            i = ENUMERATE_HEADERS.index("LastWritten")            
-            for row in rows:
-                localdt = row[i].astimezone()
-                row[i] = localdt.strftime("%H:%M" if localdt.date() == datetime.now().date() else "%Y-%m-%d")
-
-        except ValueError:
-            pass
-
-        print(tabulate(rows, ENUMERATE_HEADERS))
-
-
-class CredentialsMixin:
-    @command(add_arguments, doc=handle.__doc__)
-    def credentials(self, action: str = None, service: str = None, username: str = None):
-        return handle(action=action, service=service, username=username)
+from __future__ import annotations
+
+import os
+import subprocess
+import sys
+from argparse import ArgumentParser
+from datetime import datetime
+from getpass import getpass
+
+
+if sys.platform == "win32":
+    import win32cred
+    from keyring.backends.Windows import WinVaultKeyring
+
+    # See: https://docs.microsoft.com/en-us/windows/win32/api/wincred/ns-wincred-credentiala
+    CRED_TYPE_GENERIC = 1 # The credential is a generic credential. The credential will not be used by any particular authentication package. The credential will be stored securely but has no other significant characteristics.
+    CRED_TYPE_DOMAIN_PASSWORD = 2 # The credential is a password credential and is specific to Microsoft's authentication packages. The NTLM, Kerberos, and Negotiate authentication packages will automatically use this credential when connecting to the named target.
+    CRED_TYPE_DOMAIN_CERTIFICATE = 3 # The credential is a certificate credential and is specific to Microsoft's authentication packages. The Kerberos, Negotiate, and Schannel authentication packages automatically use this credential when connecting to the named target.
+
+    enumerate_additional_props = ["LastWritten", "TargetAlias", "Comment", "Type", "Flags", "CredentialBlob"]
+    ENUMERATE_HEADERS = ["Service", "Username", *enumerate_additional_props]
+
+    def enumerate_credentials(service=None, username=None):
+        if service is not None:
+            service = service.lower()
+        if username is not None:
+            username = username.lower()
+        
+        for cred in win32cred.CredEnumerate():
+            cred_service = cred["TargetName"]
+            cred_username = cred["UserName"]
+
+            # Filter
+            if service is not None:
+                if not service in cred_service.lower():
+                    continue
+            if username is not None:
+                if cred_username is None or not username in cred_username.lower():
+                    continue
+
+            # Additional properties
+            props = []
+            for prop in enumerate_additional_props:
+                if prop == "CredentialBlob":
+                    props.append("X" if cred[prop] else "")
+                elif prop == "Type":
+                    indication = ""
+                    if cred["Type"] == CRED_TYPE_GENERIC:
+                        indication = "generic"
+                    elif cred["Type"] == CRED_TYPE_DOMAIN_PASSWORD:
+                        indication = "domain password"
+                    elif cred["Type"] == CRED_TYPE_DOMAIN_CERTIFICATE:
+                        indication = "domain certificate"
+                    props.append(str(cred[prop]) + (" (%s)" % indication if indication else ""))
+                else:
+                    props.append(cred[prop])
+
+            yield [cred_service, cred_username, *props]
+    
+
+    def get_username(service):
+        for cred in win32cred.CredEnumerate():
+            if cred["Type"] == CRED_TYPE_GENERIC and cred["TargetName"] == service and cred["UserName"]:
+                return cred["UserName"]
+
+        # not found in credential manager
+        return None
+
+
+    _keyring = None
+
+    def _get_keyring():
+        global _keyring
+        if _keyring is None:
+            _keyring = WinVaultKeyring()
+        return _keyring
+
+    def get_password(service, username):
+        return _get_keyring().get_password(service, username)
+
+
+    def set_password(service, username, password):
+        return _get_keyring().set_password(service, username, password)
+
+
+    def delete_password(service, username):
+        return _get_keyring().delete_password(service, username)
+
+
+else: # sys.platform != "win32"
+    import re
+    from glob import glob
+
+    _several_slashes_re = re.compile(r"/{2,}")
+
+    def _sanitize_part(part):
+        """ Replace several slashes with only one """
+        if not part:
+            return part
+        part = part.replace("://", ":")
+        return _several_slashes_re.sub("/", part)
+        
+    def _get_key(service, username):
+        return os.path.join(
+            _sanitize_part(service),
+            _sanitize_part(username),
+        ).rstrip("/")
+    
+    ENUMERATE_HEADERS = ["Service", "Username", "LastWritten", "Path"]
+
+    def enumerate_credentials(service=None, username=None):
+        if service is not None:
+            service = _sanitize_part(service.lower())
+        if username is not None:
+            username = _sanitize_part(username.lower())
+
+        prefix = os.path.expanduser("~/.password-store/")
+        for path in glob(f"{prefix}**/*.gpg", recursive=True):
+            name_without_extension = path[:-4]
+            name_parts = name_without_extension[len(prefix):].rsplit("/", 1)
+            if len(name_parts) == 0:             
+                cred_service = ""
+                cred_username = ""
+            elif len(name_parts) == 1:                
+                cred_service = name_parts[0]
+                cred_username = ""
+            else:
+                cred_service = "/".join(name_parts[:-1])
+                cred_username = name_parts[-1]
+
+            # Filter
+            if service is not None:
+                if not service in cred_service.lower():
+                    continue
+            if username is not None:
+                if cred_username or not username in cred_username.lower():
+                    continue
+
+            last_written = datetime.fromtimestamp(os.path.getmtime(path))
+            yield [cred_service, cred_username, last_written, path]
+
+        
+    def get_username(service):
+        service = _sanitize_part(service)
+        for cred in enumerate_credentials():
+            if cred[0] == service:
+                return cred[1]
+
+        # not found in credential manager
+        return None
+
+    
+    _not_in_the_password_store_re = re.compile(r"^Error: .+ is not in the password store.$")
+    def get_password(service, username):
+        key = _get_key(service, username)
+        try:
+            cp = subprocess.run(["pass", "show", key], capture_output=True, check=True, text=True)
+        except subprocess.CalledProcessError as err:
+            if cp.returncode == 1 and _not_in_the_password_store_re.match(cp.stderr):
+                return None
+            else:
+                raise err
+        return cp.stdout.splitlines()[0]
+
+
+    def set_password(service, username, password):
+        if not service:
+            raise ValueError("service cannot be empty")
+
+        password = password.splitlines()[0]
+        inp = '%s\n' % password
+        inp *= 2
+        
+        key = _get_key(service, username)
+        subprocess.run(['pass', 'insert', '--force', key], input=inp, capture_output=True, check=True, text=True)
+
+
+    def delete_password(service, username):
+        key = _get_key(service, username)
+        subprocess.run(['pass', 'rm', '--force', key], check=True, capture_output=True)
+
+
+def add_arguments(parser: ArgumentParser):
+    parser.add_argument("action", nargs="?", choices=["list", "ls", "get", "set", "delete", "del", "rm"], default="list", help="action to perform")
+    parser.add_argument("service", nargs="?", help="service name")
+    parser.add_argument("username", nargs="?", help="user name")
+
+
+def handle(action: str = None, service: str = None, username: str = None):
+    """
+    List, get or set credentials from the credentials manager.
+    """    
+    if action == "get":
+        # Get a credential
+        if not service:
+            service = input("Service: ")
+        if not username:
+            username = input(f"Username for service \"{service}\": ")
+        print(get_password(service, username))
+
+    elif action == "set":
+        # Set a credential
+        if not service:
+            service = input("Service: ")
+        if not username:
+            username = input(f"Username for service \"{service}\": ")
+        set_password(service, username, getpass(f"Password for service \"{service}\" (username: \"{username}\"): "))
+
+    elif action in ["delete", "del", "rm"]:
+        # Delete a credential
+        if not service:
+            service = input("Service: ")
+        if not username:
+            username = input(f"Username for service \"{service}\": ")
+        delete_password(service, username)
+
+    else: # list
+        from tabulate import tabulate
+
+        # Search/list available credentials
+        if sys.platform == "win32":
+            print("See: rundll32.exe keymgr.dll, KRShowKeyMgr")
+        else:
+            print("See: find ~/.password-store -type f -name '*.gpg'")
+            
+        rows = []
+        for cred in enumerate_credentials(service=service, username=username):
+            rows.append(cred)
+
+        rows.sort(key=lambda row: row[0].lower())
+
+        # Display LastWritten as simplified local time
+        try:
+            i = ENUMERATE_HEADERS.index("LastWritten")            
+            for row in rows:
+                localdt = row[i].astimezone()
+                row[i] = localdt.strftime("%H:%M" if localdt.date() == datetime.now().date() else "%Y-%m-%d")
+
+        except ValueError:
+            pass
+
+
+        print(tabulate(rows, ENUMERATE_HEADERS))
```

## zut/git.py

```diff
@@ -1,82 +1,82 @@
-from __future__ import annotations
-import subprocess, re, logging
-from .format import BLUE
-
-logger = logging.getLogger(__name__)
-
-
-def get_git_tags(points_at: str = None, pattern: str = None) -> list[str]:
-    """
-    Get list of defined tags.
-    Use points_at="HEAD" for tags pointing on last commit.
-    """
-    cmd = ['git', 'tag', '--list']
-    if points_at:
-        cmd.append("--points-at")
-        cmd.append(points_at)
-    if pattern:
-        cmd.append(pattern)
-
-    cp = subprocess.run(cmd, check=True, text=True, capture_output=True)
-    tags = cp.stdout.strip()
-    if not tags:
-        return []
-    
-    return tags.splitlines()
-
-
-def get_git_hash(ref: str = "HEAD") -> None|str:
-    """
-    Get commit hash of a reference (branch, tag, etc).
-    Use ref="HEAD" for last commit and ref=None for last commit only if there is no changes.
-    """
-    try:
-        cp = subprocess.run(['git', 'rev-list', '-n', '1', ref], check=True, text=True, capture_output=True)
-    except subprocess.CalledProcessError:
-        if cp.returncode == 128:
-            return None
-
-    return cp.stdout.strip()
-
-
-def git_has_changes():
-    """
-    Indicate whether working directory has changes since last commit.
-    """
-    cp = subprocess.run(['git', 'status', '--porcelain'], check=True, text=True, capture_output=True)
-    return cp.stdout != ""
-
-
-def check_git_version_tag(version: str) -> bool:
-    if not isinstance(version, str):
-        raise ValueError(f"invalid type for argument \"version\": {type(version)}")
-    
-    ok = True
-
-    # Check version
-    if not re.match(r"^\d+\.\d+\.\d+(?:\-[a-z0-9\-]+)?$", version):
-        logger.error(f"version \"{version}\" does not match required regex")
-        ok = False
-
-    # Compare version with git tags
-    tags = get_git_tags(pattern="v*")
-    if not tags or not f"v{version}" in tags:
-        logger.warning(f"tag v{version} not found")
-        ok = False
-    
-    else:
-        # Ensure corresponding version tag matches current hash
-        tag_hash = get_git_hash(f"v{version}")
-        
-        if tag_hash:
-            head_hash = get_git_hash()
-            
-            if tag_hash != head_hash:
-                logger.error(f"tag v{version} points at {BLUE % tag_hash}, head points at {BLUE % head_hash}")
-                ok = False
-            
-            elif git_has_changes():
-                logger.error(f"git has changes since HEAD (tag v{version})")
-                ok = False
-
-    return ok
+from __future__ import annotations
+import subprocess, re, logging
+from .colors import Colors
+
+logger = logging.getLogger(__name__)
+
+
+def get_git_tags(points_at: str = None, pattern: str = None) -> list[str]:
+    """
+    Get list of defined tags.
+    Use points_at="HEAD" for tags pointing on last commit.
+    """
+    cmd = ['git', 'tag', '--list']
+    if points_at:
+        cmd.append("--points-at")
+        cmd.append(points_at)
+    if pattern:
+        cmd.append(pattern)
+
+    cp = subprocess.run(cmd, check=True, text=True, capture_output=True)
+    tags = cp.stdout.strip()
+    if not tags:
+        return []
+    
+    return tags.splitlines()
+
+
+def get_git_hash(ref: str = "HEAD") -> None|str:
+    """
+    Get commit hash of a reference (branch, tag, etc).
+    Use ref="HEAD" for last commit and ref=None for last commit only if there is no changes.
+    """
+    try:
+        cp = subprocess.run(['git', 'rev-list', '-n', '1', ref], check=True, text=True, capture_output=True)
+    except subprocess.CalledProcessError:
+        if cp.returncode == 128:
+            return None
+
+    return cp.stdout.strip()
+
+
+def git_has_changes():
+    """
+    Indicate whether working directory has changes since last commit.
+    """
+    cp = subprocess.run(['git', 'status', '--porcelain'], check=True, text=True, capture_output=True)
+    return cp.stdout != ""
+
+
+def check_git_version_tag(version: str) -> bool:
+    if not isinstance(version, str):
+        raise ValueError(f"invalid type for argument \"version\": {type(version)}")
+    
+    ok = True
+
+    # Check version
+    if not re.match(r"^\d+\.\d+\.\d+(?:\-[a-z0-9\-]+)?$", version):
+        logger.error(f"version \"{version}\" does not match required regex")
+        ok = False
+
+    # Compare version with git tags
+    tags = get_git_tags(pattern="v*")
+    if not tags or not f"v{version}" in tags:
+        logger.warning(f"tag v{version} not found")
+        ok = False
+    
+    else:
+        # Ensure corresponding version tag matches current hash
+        tag_hash = get_git_hash(f"v{version}")
+        
+        if tag_hash:
+            head_hash = get_git_hash()
+            
+            if tag_hash != head_hash:
+                logger.error(f"tag v{version} points at {Colors.BLUE}{tag_hash}{Colors.RESET}, head points at {Colors.BLUE}{head_hash}{Colors.RESET}")
+                ok = False
+            
+            elif git_has_changes():
+                logger.error(f"git has changes since HEAD (tag v{version})")
+                ok = False
+
+    return ok
```

## zut/gpg.py

```diff
@@ -1,40 +1,40 @@
-from __future__ import annotations
-import subprocess, logging
-from tempfile import TemporaryDirectory
-from pathlib import Path
-from .format import format_subprocess_result
-from .network import get_configured_proxy_url
-
-logger = logging.getLogger(__name__)
-
-
-def download_gpg_key(keyid: str, target_path: Path, keyserver: str = None, include_proxy_password: bool = False):
-    with TemporaryDirectory() as tmpdir:
-        # Retrieve the key
-        cmd = ["gpg", "--homedir", tmpdir]
-        
-        if keyserver:
-            cmd += ["--keyserver", keyserver]
-            
-            if keyserver.startswith("hkp://"):
-                proxy_url = get_configured_proxy_url(keyserver, include_password=include_proxy_password)
-                if proxy_url:
-                    cmd += ["--keyserver-options", f"http-proxy={proxy_url}"]
-
-        cmd += ["--recv-keys", keyid]
-        subprocess.run(cmd, capture_output=True, text=True, check=True)
-
-        # Export the key
-        cmd = ["gpg", "--homedir", tmpdir, "--output", target_path, "--export", keyid]
-        subprocess.run(cmd, capture_output=True, text=True, check=True)
-
-
-def verify_gpg_signature(sign_path: Path, public_key_path: Path):
-    cmd = ["gpg", "--no-default-keyring", "--keyring", public_key_path, "--verify", sign_path]
-    cp = subprocess.run(cmd, capture_output=True, text=True)
-    
-    if cp.returncode != 0:
-        logger.error("gpg verify: %s", format_subprocess_result(cp))
-        return False
-    
-    return True
+from __future__ import annotations
+import subprocess, logging
+from tempfile import TemporaryDirectory
+from pathlib import Path
+from .misc import check_completed_subprocess
+from .network import get_configured_proxy_url
+
+logger = logging.getLogger(__name__)
+
+
+def download_gpg_key(keyid: str, target_path: Path, keyserver: str = None, include_proxy_password: bool = False):
+    with TemporaryDirectory() as tmpdir:
+        # Retrieve the key
+        cmd = ["gpg", "--homedir", tmpdir]
+        
+        if keyserver:
+            cmd += ["--keyserver", keyserver]
+            
+            if keyserver.startswith("hkp://"):
+                proxy_url = get_configured_proxy_url(keyserver, include_password=include_proxy_password)
+                if proxy_url:
+                    cmd += ["--keyserver-options", f"http-proxy={proxy_url}"]
+
+        cmd += ["--recv-keys", keyid]
+        subprocess.run(cmd, capture_output=True, text=True, check=True)
+
+        # Export the key
+        cmd = ["gpg", "--homedir", tmpdir, "--output", target_path, "--export", keyid]
+        subprocess.run(cmd, capture_output=True, text=True, check=True)
+
+
+def verify_gpg_signature(sign_path: Path, public_key_path: Path):
+    cmd = ["gpg", "--no-default-keyring", "--keyring", public_key_path, "--verify", sign_path]
+    cp = subprocess.run(cmd, capture_output=True, text=True)
+    
+    if cp.returncode != 0:
+        check_completed_subprocess(cp, logger, label='gpg verify')
+        return False
+    
+    return True
```

## zut/logging.py

```diff
@@ -1,121 +1,129 @@
-from __future__ import annotations
-import logging, logging.config, os, atexit
-from .format import YELLOW, RED, BOLD_RED
-
-
-class CountHandler(logging.Handler):
-    level_fmts = {
-        'WARNING':  YELLOW,
-        'ERROR':    RED,
-        'CRITICAL': BOLD_RED,
-    }
-
-    def __init__(self, level=logging.WARNING):
-        self.counts: dict[int, int] = {}
-        atexit.register(self.print_counts)
-        super().__init__(level=level)
-
-    def print_counts(self):
-        msg = ""
-
-        levelnos = sorted(self.counts.keys(), reverse=True)
-        for levelno in levelnos:
-            levelname = logging.getLevelName(levelno)
-            colorfmt = self.level_fmts.get(levelname, '%s')
-            msg += (", " if msg else "") + colorfmt % levelname + ": %d" % self.counts[levelno]
-
-        if msg:
-            print("Logged " + msg)
-
-    def emit(self, record: logging.LogRecord):
-        if record.levelno >= self.level:
-            if not record.levelno in self.counts:
-                self.counts[record.levelno] = 1
-            else:
-                self.counts[record.levelno] += 1
-
-
-def get_logging_dictconfig(level: int|str = None, default_level: int|str = None, nocount: bool = False, config: dict = None):
-    if config:
-        config = {key: value for key, value in config.items()}
-    else:
-        config = {}
-
-    if not 'version' in config:
-        config['version'] = 1
-
-    if not 'disable_existing_loggers' in config:
-        config['disable_existing_loggers'] = False
-
-    # ---------- Formatters ----------
-    
-    if not 'formatters' in config:
-        config['formatters'] = {}
-
-    if not 'color' in config['formatters']:
-        config['formatters']['color'] = {
-            '()': 'colorlog.ColoredFormatter',
-            'format': '%(log_color)s%(levelname)-8s%(reset)s %(cyan)s[%(name)s]%(reset)s %(log_color)s%(message)s%(reset)s',
-            'log_colors': {
-                'DEBUG':    'fg_light_black',
-                'WARNING':  'yellow',
-                'ERROR':    'red',
-                'CRITICAL': 'bold_red',
-            },
-        }
-
-    # ---------- Handlers ----------
-
-    if not 'handlers' in config:
-        config['handlers'] = {}
-
-    if not 'console' in config['handlers']:
-        config['handlers']['console'] = {
-            'class': 'colorlog.StreamHandler',
-            'formatter': 'color',
-        }
-
-    if not nocount and not 'count' in config['handlers']:
-        config['handlers']['count'] = {
-            'class': 'zut.logging.CountHandler',
-            'level': 'WARNING',
-        }
-
-    # ---------- Root logger ----------
-
-    if not 'root' in config:
-        config['root'] = {}
-
-    if not 'handlers' in config['root']:
-        config['root']['handlers'] = ['console']
-        if not nocount:
-            config['root']['handlers'].append('count')
-
-    if level is not None or not 'level' in config['root']:
-        if level is None:
-            level = os.environ.get('LOG_LEVEL', '').upper()
-            if not level:
-                level = default_level if default_level else 'INFO'
-        
-        if isinstance(level, int):
-            level = logging.getLevelName(level)
-
-        config['root']['level'] = level
-
-    # ---------- Specific loggers ----------
-
-    if not 'loggers' in config:
-        config['loggers'] = {}
-
-    if not 'django' in config['loggers']:
-        config['loggers']['django'] = {
-            'level': os.environ.get('DJANGO_LOG_LEVEL', 'INFO').upper(),
-            'propagate': False,
-        }
-
-    return config
-
-
-def configure_logging(level: int|str = None, default_level: int|str = None, nocount: bool = False, config: dict = None):
-    config = get_logging_dictconfig(level=level, default_level=default_level, nocount=nocount, config=config)
-    logging.config.dictConfig(config)
+from __future__ import annotations
+import logging, logging.config, atexit, os
+from .colors import Colors
+
+
+def configure_logging(level: int|str = None, nocount: bool = False, config: dict = None):
+    merged = dict(DEFAULT_LOGGING_DICTCONFIG)
+
+    # Merge given config with default config
+    if config:
+        for prop, data in config.items():
+            if isinstance(data, dict) and prop in merged and isinstance(merged[prop], dict):
+                for key, value in data.items():
+                    if value is None:
+                        merged[prop].pop(key, None)
+                    else:
+                        merged[prop][key] = value
+            else:
+                merged[prop] = data
+
+    # Set root level if missing or if explicitely provided     
+    if level is not None or ('root' in merged and not 'level' in merged['root']):
+        if level is None:
+            level = os.environ.get('LOG_LEVEL', '').upper() or 'INFO'
+        
+        if isinstance(level, int):
+            level = logging.getLevelName(level)
+
+        merged['root']['level'] = level
+
+    # Remove count handler
+    if nocount:
+        if 'root' in merged and 'handlers' in merged['root']:
+            merged['root']['handlers'].pop('count', None)
+
+        if 'loggers' in merged:
+            for _, loggerconfig in merged['loggers'].items():
+                if 'handlers' in loggerconfig:
+                    loggerconfig['handlers'].pop('count', None)
+    
+    logging.config.dictConfig(merged)
+
+
+class ColoredRecord:
+    LEVELCOLORS = {
+        logging.DEBUG:     Colors.GRAY,
+        logging.INFO:      '',
+        logging.WARNING:   Colors.YELLOW,
+        logging.ERROR:     Colors.RED,
+        logging.CRITICAL:  Colors.BOLD_RED,
+    }
+
+    def __init__(self, record: logging.LogRecord):
+        # The internal dict is used by Python logging library when formatting the message.
+        # (inspired from library "colorlog").
+        self.__dict__.update(record.__dict__)
+        self.__dict__.update({
+            'levelcolor': self.LEVELCOLORS.get(record.levelno, ''),
+            'red': Colors.RED,
+            'green': Colors.GREEN,
+            'yellow': Colors.YELLOW,
+            'cyan': Colors.CYAN,
+            'gray': Colors.GRAY,
+            'bold_red': Colors.BOLD_RED,
+            'reset': Colors.RESET,
+        })
+
+
+class ColoredFormatter(logging.Formatter):
+    def formatMessage(self, record: logging.LogRecord) -> str:
+        """Format a message from a record object."""
+        wrapper = ColoredRecord(record)
+        message = super().formatMessage(wrapper)
+        return message
+
+
+class CountHandler(logging.Handler):
+    def __init__(self, level=logging.WARNING):
+        self.counts: dict[int, int] = {}
+        atexit.register(self.print_counts)
+        super().__init__(level=level)
+
+    def print_counts(self):
+        msg = ""
+
+        levelnos = sorted(self.counts.keys(), reverse=True)
+        for levelno in levelnos:
+            levelname = logging.getLevelName(levelno)
+            levelcolor = ColoredRecord.LEVELCOLORS.get(levelno, '')
+            msg += (", " if msg else "") + f"{levelcolor}%s{Colors.RESET}" % levelname + ": %d" % self.counts[levelno]
+
+        if msg:
+            print("Logged " + msg)
+
+    def emit(self, record: logging.LogRecord):
+        if record.levelno >= self.level:
+            if not record.levelno in self.counts:
+                self.counts[record.levelno] = 1
+            else:
+                self.counts[record.levelno] += 1
+
+
+DEFAULT_LOGGING_DICTCONFIG = {
+    'version': 1,
+    'disable_existing_loggers': False,
+    'formatters': {
+        'color': {
+            '()': ColoredFormatter.__module__ + '.' + ColoredFormatter.__qualname__,
+            'format': '%(levelcolor)s%(levelname)s%(reset)s %(gray)s[%(name)s]%(reset)s %(levelcolor)s%(message)s%(reset)s',
+        },
+    },
+    'handlers': {
+        'console': {
+            'class': 'logging.StreamHandler',
+            'formatter': 'color',
+        },
+        'count': {
+            'class': CountHandler.__module__ + '.' + CountHandler.__qualname__,
+            'level': 'WARNING',
+        },
+    },
+    'root': {
+        'handlers': ['console', 'count'],
+        'level': os.environ.get('LOG_LEVEL', '').upper() or 'INFO',
+    },
+    'loggers': {
+        'django': { 'level': os.environ.get('DJANGO_LOG_LEVEL', '').upper() or 'INFO', 'propagate': False },
+    },
+}
```

## zut/db/__init__.py

```diff
@@ -1,143 +1,47 @@
-from __future__ import annotations
-import logging
-from enum import Enum
-from pathlib import Path
-
-try:
-    # usage with Django: connection arguments are optionnal (default Django connection will be used) or can be a model class
-    from django.db import router, connections
-    from django.core.exceptions import ImproperlyConfigured
-    _with_django = True
-except:
-    # usage without Django: connection arguments are mandatory
-    _with_django = False
-
-
-logger = logging.getLogger(__name__)
-
-ZUT_DB_BASE_DIR = Path(__file__).parent
-
-class Backend(Enum):
-    POSTGRESQL = 1
-
-
-class BackendNotSupported(ValueError):
-    def __init__(self, info: Backend|type):
-        if isinstance(info, Backend):
-            message = f"backend not supported: {info.name}"
-        elif isinstance(info, type):
-            message = f"connection type not supported: {info.__module__}.{info.__name__}"
-        else:
-            message = info
-        super().__init__(message)
-
-
-def get_backend(connection):
-    search = type(connection).__module__ + "." + type(connection).__name__
-    if search == "django.utils.connection.ConnectionProxy":
-        search = connection._connections[connection._alias].vendor
-    elif hasattr(connection, "vendor"):
-        # e.g. django.db.backends.postgresql.base.DatabaseWrapper, django.contrib.gis.db.backends.postgis.base.DatabaseWrapper
-        search = connection.vendor
-
-    if search in ["postgresql", "psycopg2.extensions.connection"]:
-        return Backend.POSTGRESQL
-    else:
-        raise BackendNotSupported(type(connection))
-
-
-def get_connection(connection = None, model: type = None, for_write: bool = False):
-    if connection:
-        if model:
-            raise ValueError("connection and model options cannot be both used")
-        if not isinstance(connection, str):
-            return connection
-
-    if not _with_django:
-        raise ValueError("usage without connection option requires Django")
-
-    try:
-        if isinstance(connection, str):
-            alias = connection
-
-        elif model:
-            if not hasattr(model, "objects"):
-                raise ValueError(f"type {model.__name__} does not seem to be a Django model")
-
-            alias = router.db_for_write(model) if for_write else router.db_for_read(model)
-            if not alias:
-                alias = "default"
-
-        else:
-            alias = "default"
-
-        return connections[alias]
-
-    except ImproperlyConfigured:
-        raise ValueError(f"Django improperly configured: please provide \"connection\" option")
-
-
-def dictfetchall(cursor) -> list[dict]:
-    """
-    Return all rows from a cursor as a dict.
-    """ 
-    desc = cursor.description 
-    return [
-        dict(zip([col[0] for col in desc], row)) 
-        for row in cursor.fetchall() 
-    ]
-
-
-def deploy_sql(*paths: Path|str, encoding = "utf-8", connection = None):
-    connection = get_connection(connection=connection)
-
-    actual_paths: list[Path] = []
-    for path in paths:
-        if isinstance(path, str):
-            path = Path(path)
-        actual_paths.append(path)
-
-    actual_paths.sort()
-
-    for path in actual_paths:
-        if path.is_dir():
-            subpaths = sorted(path.iterdir())
-            deploy_sql(*subpaths, encoding=encoding, connection=connection)
-
-        elif not path.name.endswith(".sql"):
-            continue # ignore
-
-        elif path.name.endswith("_revert.sql"):
-            continue # ignore
-
-        else:
-            logger.info("execute %s", path)
-            sql = path.read_text(encoding=encoding)
-            with connection.cursor() as cursor:
-                cursor.execute(sql)
-
-
-def revert_sql(*paths: Path|str, encoding = "utf-8", connection=None):
-    connection = get_connection(connection=connection)
-
-    actual_paths: list[Path] = []
-    for path in paths:
-        if isinstance(path, str):
-            path = Path(path)
-        actual_paths.append(path)
-
-    actual_paths.sort(reverse=True)
-
-    for path in actual_paths:
-        if path.is_dir():
-            subpaths = sorted(path.iterdir())
-            revert_sql(*subpaths, encoding=encoding, connection=connection)
-
-        elif not path.name.endswith("_revert.sql"):
-            continue # ignore
-
-        else:
-            logger.info("execute %s", path)
-            sql = path.read_text(encoding=encoding)
-            with connection.cursor() as cursor:
-                cursor.execute(sql)
+from __future__ import annotations
+import re
+from urllib.parse import urlparse
+from .commons import DbWrapper
+from .mssql import MssqlWrapper
+from .pg import PgWrapper
+
+
+def get_db_with_schema_and_table(src: str) -> tuple[DbWrapper, str, str]:
+    if src.startswith('db:'):
+        src = src[3:]
+
+    r = urlparse(src)
+
+    if r.scheme == 'pg':
+        wrapper_cls = PgWrapper
+    elif r.scheme == 'mssql':
+        wrapper_cls = MssqlWrapper
+    elif r.scheme:
+        raise ValueError(f"unsupported db engine: {r.scheme}")
+    else:
+        raise ValueError(f"invalid db src: no scheme in {src}")
+    
+    if not wrapper_cls.is_available():
+        raise ValueError(f"cannot use db {r.scheme} ({wrapper_cls.__name__} not available)")
+    
+    if r.fragment:
+        raise ValueError(f"invalid db src: unexpected fragment: {r.fragment}")
+    if r.query:
+        raise ValueError(f"invalid db src: unexpected query: {r.query}")
+    if r.params:
+        raise ValueError(f"invalid db src: unexpected params: {r.params}")
+    
+    m = re.match(r'^/(?P<database>[^/@\:]+)(/((?P<schema>[^/@\:\.]+)\.)?(?P<table>[^/@\:\.]+))?$', r.path)
+    if not m:
+        raise ValueError(f"invalid db src: invalid path: {r.path}")
+    
+    database = m['database']
+    table = m['table']
+    schema = (m['schema'] or wrapper_cls.default_schema_name) if table else None
+    
+    return wrapper_cls(database=database, host=r.hostname, port=r.port, user=r.username, password=r.password), schema, table
+
+
+def get_db(src: str) -> DbWrapper:
+    db, _, _ = get_db_with_schema_and_table(src)
+    return db
```

## zut/django/management/commands/reinit.py

 * *Ordering differences only*

```diff
@@ -1,186 +1,186 @@
-from __future__ import annotations
-import logging, re
-from pathlib import Path
-from psycopg2.sql import SQL, Literal
-from django.conf import settings
-from django.db import connection
-from django.core.management import base, call_command, get_commands
-from zut.env import get_venv
-from zut.db import get_backend, Backend, BackendNotSupported
-
-logger = logging.getLogger(__name__)
-
-_migration_name_re = re.compile(r"^(\d+)_")
-
-class Command(base.BaseCommand):
-    def add_arguments(self, parser):
-        parser.add_argument("--drop", dest="action", action="store_const", const="drop")
-        parser.add_argument("--bak", dest="action", action="store_const", const="bak")
-        parser.add_argument("--bak-to", dest="action")
-        parser.add_argument("remake_migrations_for_apps", nargs="*", help="apps for which migrations are remade")
-
-    def handle(self, action: str = None, remake_migrations_for_apps: list[str] = [], **kwargs):
-        if not settings.DEBUG:
-            raise ValueError("reinit may be used only in DEBUG mode")
-        if not action:
-            raise ValueError("please confirm what to do with current data: --drop, --bak or --bak-to")
-
-        backend = get_backend(connection=connection)
-        if backend != Backend.POSTGRESQL:
-            raise BackendNotSupported(backend)
-
-        self.REMAKE_MIGRATIONS_AFTER: dict[str,int] = getattr(settings, "REMAKE_MIGRATIONS_AFTER", {})
-        self.BASE_DIR: Path = settings.BASE_DIR
-        self.remake_migrations_for_apps = remake_migrations_for_apps
-
-        if action == "drop":
-            self.drop()
-        else:
-            self.move_to_schema(action)
-
-        self.delete_nonmanual_migrations()
-        self.rename_manual_migrations()
-
-        logger.info("make migrations")
-        call_command("makemigrations")
-
-        self.restore_renamed_migrations()
-        
-        logger.info("migrate")
-        call_command("migrate")
-
-        logger.info("createsuperuser")
-        call_command("createsuperuser", "--noinput")
-
-        defined_commands = get_commands()
-
-        if "seed" in defined_commands:
-            logger.info("seed")
-            call_command("seed")
-
-
-    def move_to_schema(self, new_schema, old_schema="public"):
-        sql = """do language plpgsql
-    $$declare
-        old_schema name = {};
-        new_schema name = {};
-        sql_query text;
-    begin
-        sql_query = format('create schema %I', new_schema);
-
-        raise notice 'applying %', sql_query;
-        execute sql_query;
-    
-        for sql_query in
-            select
-                format('alter %s %I.%I set schema %I', case when table_type = 'VIEW' then 'view' else 'table' end, table_schema, table_name, new_schema)
-            from information_schema.tables
-            where table_schema = old_schema
-            and table_name not in ('geography_columns', 'geometry_columns', 'spatial_ref_sys') -- postgis
-        loop
-            raise notice 'applying %', sql_query;
-            execute sql_query;
-        end loop;
-    end;$$;
-    """
-
-        with connection.cursor() as cursor:
-            cursor.execute(SQL(sql).format(Literal(old_schema), Literal(new_schema if new_schema else "public")))
-
-
-    def drop(self, schema="public"):
-        sql = """do language plpgsql
-    $$declare
-        old_schema name = {};
-        sql_query text;
-    begin
-        -- First, remove foreign-key constraints
-        for sql_query in
-            select
-                format('alter table %I.%I drop constraint %I', table_schema, table_name, constraint_name)
-            from information_schema.table_constraints
-            where table_schema = old_schema and constraint_type = 'FOREIGN KEY'
-            and table_name not in ('geography_columns', 'geometry_columns', 'spatial_ref_sys') -- postgis
-        loop
-            raise notice 'applying %', sql_query;
-            execute sql_query;
-        end loop;
-
-        -- Then, drop tables
-        for sql_query in
-            select
-                format('drop %s if exists %I.%I cascade'
-                    ,case when table_type = 'VIEW' then 'view' else 'table' end
-                    ,table_schema
-                    ,table_name
-                )
-            from information_schema.tables
-            where table_schema = old_schema
-            and table_name not in ('geography_columns', 'geometry_columns', 'spatial_ref_sys') -- postgis
-        loop
-            raise notice 'applying %', sql_query;
-            execute sql_query;
-        end loop;
-    end;$$;
-    """
-
-        with connection.cursor() as cursor:
-            cursor.execute(SQL(sql).format(Literal(schema)))
-
-    def should_remake_migration(self, path: Path, remake_manuals=False):
-        if not remake_manuals and path.name.endswith("_manual.py"):
-            return False
-
-        if get_venv() in path.parents:
-            # exclude migrations located in ".venv" directory
-            return False
-
-        app_name = path.parent.parent.name
-        if self.remake_migrations_for_apps and not app_name in self.remake_migrations_for_apps:
-            return False
-
-        if self.REMAKE_MIGRATIONS_AFTER and app_name in self.REMAKE_MIGRATIONS_AFTER:
-            m = _migration_name_re.match(path.name)
-            if not m:
-                return False
-
-            migration_number = int(m.group(1))
-            if migration_number <= self.REMAKE_MIGRATIONS_AFTER[app_name]:
-                return False
-        
-            else:
-                return True
-
-        elif self.remake_migrations_for_apps and app_name in self.remake_migrations_for_apps:
-            return True
-
-        else:
-            return False
-
-    def delete_nonmanual_migrations(self):
-        """ Delete non-manual migrations """
-        for path in self.BASE_DIR.glob("*/migrations/0*.py"):
-            if self.should_remake_migration(path):
-                logger.info(f"delete {path}")
-                path.unlink()
-            else:
-                logger.info(f"preserve {path}")
-
-    def rename_manual_migrations(self):
-        self.renamed: dict[Path,Path] = {}
-
-        """ Rename manual migrations to py~ """
-        for path in self.BASE_DIR.glob("*/migrations/*_manual.py"):
-            if self.should_remake_migration(path, remake_manuals=True):
-                target = path.with_name(f"{path.name}~")
-                logger.info(f"rename {path} to {target}")
-                path.rename(target)
-                self.renamed[path] = target
-            else:
-                logger.info(f"preserve {path}")
-    
-    def restore_renamed_migrations(self):
-        """ Restore migrations from py~ """
-        for origin, renamed in self.renamed.items():
-            logger.info(f"rename {renamed} to {origin}")
-            renamed.rename(origin)
+from __future__ import annotations
+import logging, re
+from pathlib import Path
+from psycopg2.sql import SQL, Literal
+from django.conf import settings
+from django.db import connection
+from django.core.management import base, call_command, get_commands
+from zut.env import get_venv
+from zut.db import get_backend, Backend, BackendNotSupported
+
+logger = logging.getLogger(__name__)
+
+_migration_name_re = re.compile(r"^(\d+)_")
+
+class Command(base.BaseCommand):
+    def add_arguments(self, parser):
+        parser.add_argument("--drop", dest="action", action="store_const", const="drop")
+        parser.add_argument("--bak", dest="action", action="store_const", const="bak")
+        parser.add_argument("--bak-to", dest="action")
+        parser.add_argument("remake_migrations_for_apps", nargs="*", help="apps for which migrations are remade")
+
+    def handle(self, action: str = None, remake_migrations_for_apps: list[str] = [], **kwargs):
+        if not settings.DEBUG:
+            raise ValueError("reinit may be used only in DEBUG mode")
+        if not action:
+            raise ValueError("please confirm what to do with current data: --drop, --bak or --bak-to")
+
+        backend = get_backend(connection=connection)
+        if backend != Backend.POSTGRESQL:
+            raise BackendNotSupported(backend)
+
+        self.REMAKE_MIGRATIONS_AFTER: dict[str,int] = getattr(settings, "REMAKE_MIGRATIONS_AFTER", {})
+        self.BASE_DIR: Path = settings.BASE_DIR
+        self.remake_migrations_for_apps = remake_migrations_for_apps
+
+        if action == "drop":
+            self.drop()
+        else:
+            self.move_to_schema(action)
+
+        self.delete_nonmanual_migrations()
+        self.rename_manual_migrations()
+
+        logger.info("make migrations")
+        call_command("makemigrations")
+
+        self.restore_renamed_migrations()
+        
+        logger.info("migrate")
+        call_command("migrate")
+
+        logger.info("createsuperuser")
+        call_command("createsuperuser", "--noinput")
+
+        defined_commands = get_commands()
+
+        if "seed" in defined_commands:
+            logger.info("seed")
+            call_command("seed")
+
+
+    def move_to_schema(self, new_schema, old_schema="public"):
+        sql = """do language plpgsql
+    $$declare
+        old_schema name = {};
+        new_schema name = {};
+        sql_query text;
+    begin
+        sql_query = format('create schema %I', new_schema);
+
+        raise notice 'applying %', sql_query;
+        execute sql_query;
+    
+        for sql_query in
+            select
+                format('alter %s %I.%I set schema %I', case when table_type = 'VIEW' then 'view' else 'table' end, table_schema, table_name, new_schema)
+            from information_schema.tables
+            where table_schema = old_schema
+            and table_name not in ('geography_columns', 'geometry_columns', 'spatial_ref_sys') -- postgis
+        loop
+            raise notice 'applying %', sql_query;
+            execute sql_query;
+        end loop;
+    end;$$;
+    """
+
+        with connection.cursor() as cursor:
+            cursor.execute(SQL(sql).format(Literal(old_schema), Literal(new_schema if new_schema else "public")))
+
+
+    def drop(self, schema="public"):
+        sql = """do language plpgsql
+    $$declare
+        old_schema name = {};
+        sql_query text;
+    begin
+        -- First, remove foreign-key constraints
+        for sql_query in
+            select
+                format('alter table %I.%I drop constraint %I', table_schema, table_name, constraint_name)
+            from information_schema.table_constraints
+            where table_schema = old_schema and constraint_type = 'FOREIGN KEY'
+            and table_name not in ('geography_columns', 'geometry_columns', 'spatial_ref_sys') -- postgis
+        loop
+            raise notice 'applying %', sql_query;
+            execute sql_query;
+        end loop;
+
+        -- Then, drop tables
+        for sql_query in
+            select
+                format('drop %s if exists %I.%I cascade'
+                    ,case when table_type = 'VIEW' then 'view' else 'table' end
+                    ,table_schema
+                    ,table_name
+                )
+            from information_schema.tables
+            where table_schema = old_schema
+            and table_name not in ('geography_columns', 'geometry_columns', 'spatial_ref_sys') -- postgis
+        loop
+            raise notice 'applying %', sql_query;
+            execute sql_query;
+        end loop;
+    end;$$;
+    """
+
+        with connection.cursor() as cursor:
+            cursor.execute(SQL(sql).format(Literal(schema)))
+
+    def should_remake_migration(self, path: Path, remake_manuals=False):
+        if not remake_manuals and path.name.endswith("_manual.py"):
+            return False
+
+        if get_venv() in path.parents:
+            # exclude migrations located in ".venv" directory
+            return False
+
+        app_name = path.parent.parent.name
+        if self.remake_migrations_for_apps and not app_name in self.remake_migrations_for_apps:
+            return False
+
+        if self.REMAKE_MIGRATIONS_AFTER and app_name in self.REMAKE_MIGRATIONS_AFTER:
+            m = _migration_name_re.match(path.name)
+            if not m:
+                return False
+
+            migration_number = int(m.group(1))
+            if migration_number <= self.REMAKE_MIGRATIONS_AFTER[app_name]:
+                return False
+        
+            else:
+                return True
+
+        elif self.remake_migrations_for_apps and app_name in self.remake_migrations_for_apps:
+            return True
+
+        else:
+            return False
+
+    def delete_nonmanual_migrations(self):
+        """ Delete non-manual migrations """
+        for path in self.BASE_DIR.glob("*/migrations/0*.py"):
+            if self.should_remake_migration(path):
+                logger.info(f"delete {path}")
+                path.unlink()
+            else:
+                logger.info(f"preserve {path}")
+
+    def rename_manual_migrations(self):
+        self.renamed: dict[Path,Path] = {}
+
+        """ Rename manual migrations to py~ """
+        for path in self.BASE_DIR.glob("*/migrations/*_manual.py"):
+            if self.should_remake_migration(path, remake_manuals=True):
+                target = path.with_name(f"{path.name}~")
+                logger.info(f"rename {path} to {target}")
+                path.rename(target)
+                self.renamed[path] = target
+            else:
+                logger.info(f"preserve {path}")
+    
+    def restore_renamed_migrations(self):
+        """ Restore migrations from py~ """
+        for origin, renamed in self.renamed.items():
+            logger.info(f"rename {renamed} to {origin}")
+            renamed.rename(origin)
```

## zut/django/management/commands/seed_zut.py

 * *Ordering differences only*

```diff
@@ -1,13 +1,13 @@
-from __future__ import annotations
-import logging
-from django.core.management import base
-from django.db import connection
-from zut.db import deploy_sql, ZUT_DB_BASE_DIR, get_backend
-
-logger = logging.getLogger(__name__)
-
-class Command(base.BaseCommand):
-    def handle(self, action=None, **kwargs):
-        backend = get_backend(connection=connection)
-        backend_dir = ZUT_DB_BASE_DIR.joinpath(backend.name.lower())
-        deploy_sql(backend_dir)
+from __future__ import annotations
+import logging
+from django.core.management import base
+from django.db import connection
+from zut.db import deploy_sql, ZUT_DB_BASE_DIR, get_backend
+
+logger = logging.getLogger(__name__)
+
+class Command(base.BaseCommand):
+    def handle(self, action=None, **kwargs):
+        backend = get_backend(connection=connection)
+        backend_dir = ZUT_DB_BASE_DIR.joinpath(backend.name.lower())
+        deploy_sql(backend_dir)
```

## zut/django/middleware/__init__.py

 * *Ordering differences only*

```diff
@@ -1,80 +1,80 @@
-import logging
-from django.http import HttpResponseForbidden
-from django.core.exceptions import ImproperlyConfigured
-
-try:
-    from django.contrib.auth.mixins import AccessMixin
-    from django.contrib.auth.views import LoginView, LogoutView, redirect_to_login
-    from django.views.generic.base import RedirectView
-    improperly_configured_error = None
-        
-    try:
-        from rest_framework.views import APIView
-        _with_rest_framework = True
-    except ImportError:
-        _with_rest_framework = False
-except ImproperlyConfigured as improperly_configured_error:
-    # delay exception in class instantiation to avoid failure during unittest discovery
-    pass
-
-
-logger = logging.getLogger(__name__)
-
-class StaffAuthorizationMiddleware:
-    no_default_for = ["/", "/status"]
-
-    def __init__(self, get_response):
-        if improperly_configured_error:
-            raise improperly_configured_error
-        self.get_response = get_response
-
-    def __call__(self, request):
-        return self.get_response(request)
-
-    def process_view(self, request, view_func, view_args, view_kwargs):
-        if request.path in self.no_default_for:
-            return # no default permission
-
-        if view_func.__module__.startswith("django.contrib.admin."):
-            return # no default permission
-
-        if not hasattr(view_func, "view_class"):
-            # function-based view
-            if not self.is_authorized(request.user):
-                logger.debug("function-based view %s: default authorization required", ".".join([view_func.__module__, view_func.__name__]))
-                return self._deny_or_login(request)
-            
-        else:
-            # class-based view
-            view = view_func.view_class
-
-            if issubclass(view, (LoginView, LogoutView, RedirectView)):
-                return # no default permission
-
-            if _with_rest_framework and issubclass(view, APIView):
-                # API view (Django Rest Framework)
-                if not view.permission_classes:
-                    if not self.is_authorized(request.user):
-                        logger.debug("no permission_classes for rest_framework view %s: default authorization required required", ".".join([view.__module__, view.__name__]))
-                        return HttpResponseForbidden() # do not redirect to login page (this is supposed to be accessed by javascript or as an API)
-
-            else:
-                # Standard class-based view
-                if not issubclass(view, AccessMixin):
-                    if not self.is_authorized(request.user):
-                        logger.debug("no AccessMixin for view %s: default authorization required", ".".join([view.__module__, view.__name__]))
-                        return self._deny_or_login(request)
-
-    def is_authorized(self, user):
-        return user.is_staff
-
-    def _deny_or_login(self, request):
-        if request.user.is_authenticated:
-            return HttpResponseForbidden()
-        else:
-            return redirect_to_login(next=request.get_full_path())
-
-
-class AdminAuthorizationMiddleware(StaffAuthorizationMiddleware):
-    def is_authorized(self, user):
-        return user.is_admin
+import logging
+from django.http import HttpResponseForbidden
+from django.core.exceptions import ImproperlyConfigured
+
+try:
+    from django.contrib.auth.mixins import AccessMixin
+    from django.contrib.auth.views import LoginView, LogoutView, redirect_to_login
+    from django.views.generic.base import RedirectView
+    improperly_configured_error = None
+        
+    try:
+        from rest_framework.views import APIView
+        _with_rest_framework = True
+    except ImportError:
+        _with_rest_framework = False
+except ImproperlyConfigured as improperly_configured_error:
+    # delay exception in class instantiation to avoid failure during unittest discovery
+    pass
+
+
+logger = logging.getLogger(__name__)
+
+class StaffAuthorizationMiddleware:
+    no_default_for = ["/", "/status"]
+
+    def __init__(self, get_response):
+        if improperly_configured_error:
+            raise improperly_configured_error
+        self.get_response = get_response
+
+    def __call__(self, request):
+        return self.get_response(request)
+
+    def process_view(self, request, view_func, view_args, view_kwargs):
+        if request.path in self.no_default_for:
+            return # no default permission
+
+        if view_func.__module__.startswith("django.contrib.admin."):
+            return # no default permission
+
+        if not hasattr(view_func, "view_class"):
+            # function-based view
+            if not self.is_authorized(request.user):
+                logger.debug("function-based view %s: default authorization required", ".".join([view_func.__module__, view_func.__name__]))
+                return self._deny_or_login(request)
+            
+        else:
+            # class-based view
+            view = view_func.view_class
+
+            if issubclass(view, (LoginView, LogoutView, RedirectView)):
+                return # no default permission
+
+            if _with_rest_framework and issubclass(view, APIView):
+                # API view (Django Rest Framework)
+                if not view.permission_classes:
+                    if not self.is_authorized(request.user):
+                        logger.debug("no permission_classes for rest_framework view %s: default authorization required required", ".".join([view.__module__, view.__name__]))
+                        return HttpResponseForbidden() # do not redirect to login page (this is supposed to be accessed by javascript or as an API)
+
+            else:
+                # Standard class-based view
+                if not issubclass(view, AccessMixin):
+                    if not self.is_authorized(request.user):
+                        logger.debug("no AccessMixin for view %s: default authorization required", ".".join([view.__module__, view.__name__]))
+                        return self._deny_or_login(request)
+
+    def is_authorized(self, user):
+        return user.is_staff
+
+    def _deny_or_login(self, request):
+        if request.user.is_authenticated:
+            return HttpResponseForbidden()
+        else:
+            return redirect_to_login(next=request.get_full_path())
+
+
+class AdminAuthorizationMiddleware(StaffAuthorizationMiddleware):
+    def is_authorized(self, user):
+        return user.is_admin
```

## zut/django/templatetags/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-#TODO/ROADMAP: additional tags and filters: timeordate, hostlink, etc
+#TODO/ROADMAP: additional tags and filters: timeordate, hostlink, etc
```

## zut/django/templatetags/static_lib.py

 * *Ordering differences only*

```diff
@@ -1,90 +1,90 @@
-import logging
-from django import template
-from django.utils.safestring import mark_safe
-from django.templatetags.static import static
-from django.conf import settings
-
-logger = logging.getLogger(__name__)
-
-register = template.Library()
-
-# avoid logging warnings for every request
-_missing_version: list[str] = []
-_missing_integrity: list[str] = []
-
-def _get_lib_url(package, file, version=None):
-    LOCAL_STATIC_LIB = getattr(settings, "LOCAL_STATIC_LIB", False)
-    if LOCAL_STATIC_LIB:
-        return f"{static(LOCAL_STATIC_LIB if isinstance(LOCAL_STATIC_LIB, str) else 'lib')}/{package}/{file}"
-    else:
-        if version:
-            return f"https://cdn.jsdelivr.net/npm/{package}@{version}/{file}"
-        else:
-            return f"https://cdn.jsdelivr.net/npm/{package}/{file}"
-
-
-@register.simple_tag
-def style_lib(package, file, version=None, integrity=None):
-    """
-    Usage example in Django base template:
-
-        {% load static %}
-        {% load static_lib %}
-        ...
-        <head>
-        ...
-        {% style_lib  'bootstrap' 'dist/css/bootstrap.min.css' '5.2.0' 'sha256-7ZWbZUAi97rkirk4DcEp4GWDPkWpRMcNaEyXGsNXjLg=' %}
-        ...
-        </head>
-    """
-    url = _get_lib_url(package, file, version)
-
-    if not version and not url in _missing_version:
-        logger.warning(f"missing version for style_lib: {url}")
-        _missing_version.append(url)
-        
-    html = f"<link rel=\"stylesheet\" href=\"{url}\""
-    
-    if integrity:
-        html += f" integrity=\"{integrity}\" crossorigin=\"anonymous\""
-    else:
-        logger.warning(f"missing integrity hash for style_lib: {url}")
-        _missing_integrity.append(url)
-
-    html += f" />"
-    return mark_safe(html)
-
-
-@register.simple_tag
-def script_lib(package, file, version=None, integrity=None, defer=False):
-    """
-    Usage example in Django base template:
-
-        {% load static %}
-        {% load static_lib %}
-        ...
-        <head>
-        ...
-        {% script_lib 'bootstrap' 'dist/js/bootstrap.bundle.min.js' '5.2.0' 'sha256-wMCQIK229gKxbUg3QWa544ypI4OoFlC2qQl8Q8xD8x8=' %}
-        ...
-        </head>
-    """
-    url = _get_lib_url(package, file, version)
-    
-    if not version and not url in _missing_version:
-        logger.warning(f"missing version for script_lib: {url}")
-        _missing_version.append(url)
-
-    html = f"<script"
-    if defer:
-        html=" defer"
-    html += f" src=\"{url}\""
-    
-    if integrity:
-        html += f" integrity=\"{integrity}\" crossorigin=\"anonymous\""
-    elif not url in _missing_integrity:
-        logger.warning(f"missing integrity hash for script_lib: {url}")
-        _missing_integrity.append(url)
-
-    html += f"></script>"
-    return mark_safe(html)
+import logging
+from django import template
+from django.utils.safestring import mark_safe
+from django.templatetags.static import static
+from django.conf import settings
+
+logger = logging.getLogger(__name__)
+
+register = template.Library()
+
+# avoid logging warnings for every request
+_missing_version: list[str] = []
+_missing_integrity: list[str] = []
+
+def _get_lib_url(package, file, version=None):
+    LOCAL_STATIC_LIB = getattr(settings, "LOCAL_STATIC_LIB", False)
+    if LOCAL_STATIC_LIB:
+        return f"{static(LOCAL_STATIC_LIB if isinstance(LOCAL_STATIC_LIB, str) else 'lib')}/{package}/{file}"
+    else:
+        if version:
+            return f"https://cdn.jsdelivr.net/npm/{package}@{version}/{file}"
+        else:
+            return f"https://cdn.jsdelivr.net/npm/{package}/{file}"
+
+
+@register.simple_tag
+def style_lib(package, file, version=None, integrity=None):
+    """
+    Usage example in Django base template:
+
+        {% load static %}
+        {% load static_lib %}
+        ...
+        <head>
+        ...
+        {% style_lib  'bootstrap' 'dist/css/bootstrap.min.css' '5.2.0' 'sha256-7ZWbZUAi97rkirk4DcEp4GWDPkWpRMcNaEyXGsNXjLg=' %}
+        ...
+        </head>
+    """
+    url = _get_lib_url(package, file, version)
+
+    if not version and not url in _missing_version:
+        logger.warning(f"missing version for style_lib: {url}")
+        _missing_version.append(url)
+        
+    html = f"<link rel=\"stylesheet\" href=\"{url}\""
+    
+    if integrity:
+        html += f" integrity=\"{integrity}\" crossorigin=\"anonymous\""
+    else:
+        logger.warning(f"missing integrity hash for style_lib: {url}")
+        _missing_integrity.append(url)
+
+    html += f" />"
+    return mark_safe(html)
+
+
+@register.simple_tag
+def script_lib(package, file, version=None, integrity=None, defer=False):
+    """
+    Usage example in Django base template:
+
+        {% load static %}
+        {% load static_lib %}
+        ...
+        <head>
+        ...
+        {% script_lib 'bootstrap' 'dist/js/bootstrap.bundle.min.js' '5.2.0' 'sha256-wMCQIK229gKxbUg3QWa544ypI4OoFlC2qQl8Q8xD8x8=' %}
+        ...
+        </head>
+    """
+    url = _get_lib_url(package, file, version)
+    
+    if not version and not url in _missing_version:
+        logger.warning(f"missing version for script_lib: {url}")
+        _missing_version.append(url)
+
+    html = f"<script"
+    if defer:
+        html=" defer"
+    html += f" src=\"{url}\""
+    
+    if integrity:
+        html += f" integrity=\"{integrity}\" crossorigin=\"anonymous\""
+    elif not url in _missing_integrity:
+        logger.warning(f"missing integrity hash for script_lib: {url}")
+        _missing_integrity.append(url)
+
+    html += f"></script>"
+    return mark_safe(html)
```

## zut/django/views/MarkdownTemplateView.py

 * *Ordering differences only*

```diff
@@ -1,43 +1,43 @@
-from __future__ import annotations
-from cmarkgfm import github_flavored_markdown_to_html
-from django.views.generic import TemplateView
-from django.template.loader import get_template
-from html.parser import HTMLParser
-
-class MarkdownTemplateView(TemplateView):
-    extends = "base.html"
-
-    def render_to_response(self, context, **response_kwargs):
-        markdown_template = get_template(self.template_name)
-        markdown_text = markdown_template.render(context, self.request)
-        html_content = github_flavored_markdown_to_html(markdown_text)
-
-        new_context = {}
-        new_context["extends"] = self.extends
-        new_context["title"] = MarkdownTemplateView.find_html_tag_content(html_content, "h1")
-        new_context["html_content"] = html_content
-        return super().render_to_response(new_context, **response_kwargs)
-
-    def get_template_names(self):
-        return ["_content.html"] # located in main/templates
-
-    @staticmethod
-    def find_html_tag_content(html: str, tag: str):        
-        class HTMLTagParser(HTMLParser):
-            def __init__(self, searched_tag):
-                super().__init__()
-                self.searched_tag = searched_tag
-                self.match = False
-                self.data = None
-
-            def handle_starttag(self, tag, attributes):
-                self.match = tag == self.searched_tag
-
-            def handle_data(self, data):
-                if self.match:
-                    self.data = data
-                    self.match = False
-
-        parser = HTMLTagParser(tag)
-        parser.feed(html)
-        return parser.data
+from __future__ import annotations
+from cmarkgfm import github_flavored_markdown_to_html
+from django.views.generic import TemplateView
+from django.template.loader import get_template
+from html.parser import HTMLParser
+
+class MarkdownTemplateView(TemplateView):
+    extends = "base.html"
+
+    def render_to_response(self, context, **response_kwargs):
+        markdown_template = get_template(self.template_name)
+        markdown_text = markdown_template.render(context, self.request)
+        html_content = github_flavored_markdown_to_html(markdown_text)
+
+        new_context = {}
+        new_context["extends"] = self.extends
+        new_context["title"] = MarkdownTemplateView.find_html_tag_content(html_content, "h1")
+        new_context["html_content"] = html_content
+        return super().render_to_response(new_context, **response_kwargs)
+
+    def get_template_names(self):
+        return ["_content.html"] # located in main/templates
+
+    @staticmethod
+    def find_html_tag_content(html: str, tag: str):        
+        class HTMLTagParser(HTMLParser):
+            def __init__(self, searched_tag):
+                super().__init__()
+                self.searched_tag = searched_tag
+                self.match = False
+                self.data = None
+
+            def handle_starttag(self, tag, attributes):
+                self.match = tag == self.searched_tag
+
+            def handle_data(self, data):
+                if self.match:
+                    self.data = data
+                    self.match = False
+
+        parser = HTMLTagParser(tag)
+        parser.feed(html)
+        return parser.data
```

## zut/django/views/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-from .MarkdownTemplateView import MarkdownTemplateView
+from .MarkdownTemplateView import MarkdownTemplateView
```

## zut/network/__init__.py

```diff
@@ -1,237 +1,241 @@
-from __future__ import annotations
-import logging, os, re, urllib.request, socket, base64
-from types import FunctionType
-from urllib.parse import unquote, urlparse
-from contextlib import closing
-from unittest import TestCase
-from ..format import RED, GREEN, GRAY
-from .commons import ProxyConfig, _proxyconfig, report_failure
-
-try:
-    from .winhttp import check_winhttp_connectivity
-    _with_winhttp = True
-except ImportError:
-    _with_winhttp = False
-
-try:
-    from ..credentials import get_password
-    _with_credentials = True
-except ImportError:
-    _with_credentials = False
-
-
-logger = logging.getLogger(__name__)
-
-IP_ADDRESS_PATTERN = re.compile(r"^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$")
-
-
-def check_socket(host, port, timeout=1):
-    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
-        sock.settimeout(timeout)
-        try:
-            returncode = sock.connect_ex((host, port))
-            if returncode == 0:
-                return True
-            else:
-                logger.debug("socket connnect_ex returned %d", returncode)
-                return False
-        except Exception as e:
-            logger.debug("socket connnect_ex: %s", e)
-            return False
-
-
-class SimpleProxyHandler(urllib.request.BaseHandler):
-    # Inspired from urllib.request.ProxyHandler   
-    handler_order = 100 # Proxies must be in front
-
-    def __init__(self, config: ProxyConfig):
-        self.config = config
-
-    def finalize(self) -> str:
-        # Get proxy url (for logs)
-        proxy_logurl = self.config.get_proxy_url(include_password="*")
-        logger.debug(f"use proxy for urllib: {proxy_logurl}")
-
-        # Check proxy existency
-        if not check_socket(self.config.host, self.config.port):
-            logger.warning(f"cannot connect to proxy for urllib: {proxy_logurl}")
-
-        # Prepare usefull variables for add_header and set_proxy
-        self.hostport = self.config.hostport
-        self.scheme = self.config.scheme
-
-        if self.config.username:
-            if not self.config.password:
-                if self.config.password_func:
-                    raise ValueError(f"password function did not return any value for username: {self.config.username}")
-                else:
-                    raise ValueError(f"missing password for urllib proxy: {proxy_logurl}")
-            userpass = '%s:%s' % (self.config.username, self.config.password)
-            self.authorization = "Basic " + base64.b64encode(userpass.encode()).decode("ascii")
-        else:
-            self.authorization = None
-
-    def http_open(self, req):
-        if not req.host:
-            return None
-        
-        if urllib.request.proxy_bypass(req.host):
-            # NOTE: because Proxy-Authorization header is not encrypted, we must add it ONLY when we're actually talking to the proxy
-            return None
-
-        if not hasattr(self, "authorization"):
-            self.finalize()
-
-        if self.authorization:
-            req.add_header("Proxy-Authorization", self.authorization)
-        req.set_proxy(self.hostport, self.scheme)
-        return None
-    
-    def https_open(self, req):
-        return self.http_open(req)
-
-
-def configure_proxy(url: str = None, exclusions: str = None, password_func: FunctionType = None):
-    """
-    Configure proxy for urllib requests (and winhttp requests created with `zut.network.winhttp.create_winhttp_request`).
-    """
-    # Detect proxy URL
-    if url is None:
-        if "HTTP_PROXY" in os.environ:
-            url = os.environ["HTTP_PROXY"]
-        elif "http_proxy" in os.environ:
-            url = os.environ["http_proxy"]
-
-    # Detect proxy exclusions
-    if exclusions is None:
-        if "NO_PROXY" in os.environ:
-            exclusions = os.environ["NO_PROXY"]
-        elif "no_proxy" in os.environ:
-            exclusions = os.environ["no_proxy"]
-
-    # Update proxy configuration
-    _proxyconfig.update(url, exclusions=exclusions)
-    
-    # Detect and register proxy func
-    if _proxyconfig.username and not _proxyconfig._password:
-        if password_func is None:
-            service = os.environ.get("PROXY_PASSWORD_SERVICE", None)
-            if service:
-                if not _with_credentials:
-                    logger.error(f"cannot register PROXY_PASSWORD_SERVICE \"{service}\": zut[credentials] optional dependencies are not installed")
-                else:
-                    password_func = lambda username: get_password(service, username)
-                
-        if password_func:
-            _proxyconfig.set_password_func(password_func)
-
-    def _del_if_exists(data: dict, attr: str):
-        if attr in data:
-            del data[attr]
-
-    # Remove environment variables (would take precedence in some cases, which might cause issues: e.g. should contain password or not?)
-    _del_if_exists(os.environ, "http_proxy")
-    _del_if_exists(os.environ, "https_proxy")
-    _del_if_exists(os.environ, "HTTP_PROXY")
-    _del_if_exists(os.environ, "HTTPS_PROXY")
-
-    # Ensure no_proxy is specified (must be passed as environment variable for urllib)
-    env_exclusions = _proxyconfig.env_exclusions_str
-    if env_exclusions:
-        os.environ["no_proxy"] = env_exclusions
-        os.environ["NO_PROXY"] = env_exclusions
-    else:
-        _del_if_exists(os.environ, "no_proxy")
-        _del_if_exists(os.environ, "NO_PROXY")
-
-    # Stop if no proxy specified/detected
-    if not _proxyconfig.host:
-        return
-    
-    # Register proxy for urllib
-    try:
-        handler = SimpleProxyHandler(_proxyconfig)
-        opener = urllib.request.build_opener(handler)
-        urllib.request.install_opener(opener)
-    except Exception as e:
-        logger.error("cannot register proxy for urllib: %s", e)
-
-
-def get_configured_proxy_url(for_url: str = None, include_password: bool = False) -> str:
-    """
-    Return currently configured proxy URL.
-    If `for_url` is given, return None if the proxy is excluded for this url.
-    """
-    if for_url:
-        o = urlparse(for_url)
-        if urllib.request.proxy_bypass(o.netloc if o.netloc else o.path):
-            return None
-    return _proxyconfig.get_proxy_url(include_password=include_password)
-
-
-def get_configured_proxy_hostport(for_url: str = None, include_password: bool = False) -> tuple[str,int]:
-    """
-    Return currently configured proxy host and port.
-    If `for_url` is given, return None if the proxy is excluded for this url.
-    """
-    if for_url:
-        o = urlparse(for_url)
-        if urllib.request.proxy_bypass(o.netloc if o.netloc else o.path):
-            return None
-    return _proxyconfig.host, _proxyconfig.port
-
-
-def get_configured_proxy_exclusions() -> list[str]:
-    """
-    Return currently configured proxy exclusions.
-    """
-    return _proxyconfig.exclusions
-
-
-def check_urllib_connectivity(url: str, expected_regex: re.Pattern|str, label=None, timeout: float = None, case: TestCase = None) -> bool:
-    """
-    Check network connectivity using urllib library.
-    - `timeout`: in seconds (defaults to 3 seconds).
-
-    Return `True` on success, `False` on failure.
-    """        
-    if not isinstance(expected_regex, re.Pattern):
-        expected_regex = re.compile(expected_regex)
-
-    if label is None:
-        label = url
-
-    if not timeout:
-        timeout = float(os.environ.get("CHECK_CONNECTIVITY_TIMEOUT", 3))
-
-    msg=f"{label} urllib"
-
-    try:
-        res = urllib.request.urlopen(url, timeout=timeout)
-        text = res.read().decode('utf-8')
-        text_startup = text[0:20].replace('\n', '\\n').replace('\r', '\\r') + ('' if len(text) > 20 else '')
-        
-        if not expected_regex.match(text):
-            report_failure(case, f"{msg}: response ({RED % text_startup}) does not match expected regex ({GRAY % expected_regex.pattern})")
-            return False
-
-        logger.info(f"{msg}: {GREEN % 'success'} (response: {GRAY % text_startup})")
-        return True
-    except urllib.error.URLError as e:
-        report_failure(case, f"{msg}: {RED % e.reason}")
-        return False
-
-
-def check_connectivity(url: str, expected_regex: re.Pattern|str, label=None, timeout: float = None, case: TestCase = None) -> bool:
-    """
-    Check network connectivity with urllib library, and winhttp library on Windows (if [winhttp] extra dependencies are installed).
-    - `timeout`: in seconds (defaults to 3 seconds).
-
-    Return `True` on success, `False` on failure.
-    """ 
-    ok = check_urllib_connectivity(url, expected_regex, label=label, timeout=timeout, case=case)
-
-    if _with_winhttp:
-        ok = ok and check_winhttp_connectivity(url, expected_regex, label=label, timeout=timeout, case=case)
-
-    return ok
+from __future__ import annotations
+import logging, os, re, urllib.request, socket, base64
+from types import FunctionType
+from urllib.parse import unquote, urlparse
+from contextlib import closing
+from unittest import TestCase
+from ..colors import Colors
+from .commons import ProxyConfig, _proxyconfig, report_failure
+
+try:
+    from .winhttp import check_winhttp_connectivity
+    _with_winhttp = True
+except ImportError:
+    _with_winhttp = False
+
+try:
+    from ..credentials import get_password
+    _with_credentials = True
+except ImportError:
+    _with_credentials = False
+
+
+logger = logging.getLogger(__name__)
+
+IP_ADDRESS_PATTERN = re.compile(r"^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$")
+
+
+def check_socket(host, port, timeout=1):
+    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
+        sock.settimeout(timeout)
+        try:
+            returncode = sock.connect_ex((host, port))
+            if returncode == 0:
+                return True
+            else:
+                logger.debug("socket connnect_ex returned %d", returncode)
+                return False
+        except Exception as e:
+            logger.debug("socket connnect_ex: %s", e)
+            return False
+
+
+class SimpleProxyHandler(urllib.request.BaseHandler):
+    # Inspired from urllib.request.ProxyHandler   
+    handler_order = 100 # Proxies must be in front
+
+    def __init__(self, config: ProxyConfig):
+        self.config = config
+
+    def finalize(self) -> str:
+        # Get proxy url (for logs)
+        proxy_logurl = self.config.get_proxy_url(include_password="*")
+        logger.debug(f"use proxy for urllib: {proxy_logurl}")
+
+        # Check proxy existency
+        if not check_socket(self.config.host, self.config.port):
+            logger.warning(f"cannot connect to proxy for urllib: {proxy_logurl}")
+
+        # Prepare usefull variables for add_header and set_proxy
+        self.hostport = self.config.hostport
+        self.scheme = self.config.scheme
+
+        if self.config.username:
+            if not self.config.password:
+                if self.config.password_func:
+                    raise ValueError(f"password function did not return any value for username: {self.config.username}")
+                else:
+                    raise ValueError(f"missing password for urllib proxy: {proxy_logurl}")
+            userpass = '%s:%s' % (self.config.username, self.config.password)
+            self.authorization = "Basic " + base64.b64encode(userpass.encode()).decode("ascii")
+        else:
+            self.authorization = None
+
+    def http_open(self, req):
+        if not req.host:
+            return None
+        
+        if urllib.request.proxy_bypass(req.host):
+            # NOTE: because Proxy-Authorization header is not encrypted, we must add it ONLY when we're actually talking to the proxy
+            return None
+
+        if not hasattr(self, "authorization"):
+            self.finalize()
+
+        if self.authorization:
+            req.add_header("Proxy-Authorization", self.authorization)
+        req.set_proxy(self.hostport, self.scheme)
+        return None
+    
+    def https_open(self, req):
+        return self.http_open(req)
+
+
+def configure_proxy(url: str = None, exclusions: str = None, password_func: FunctionType = None):
+    """
+    Configure proxy for urllib requests (and winhttp requests created with `zut.network.winhttp.create_winhttp_request`).
+    """
+    # Detect proxy URL
+    if url is None:
+        if "HTTP_PROXY" in os.environ:
+            url = os.environ["HTTP_PROXY"]
+        elif "http_proxy" in os.environ:
+            url = os.environ["http_proxy"]
+        elif "HTTPS_PROXY" in os.environ:
+            url = os.environ["HTTPS_PROXY"]
+        elif "https_proxy" in os.environ:
+            url = os.environ["https_proxy"]
+
+    # Detect proxy exclusions
+    if exclusions is None:
+        if "NO_PROXY" in os.environ:
+            exclusions = os.environ["NO_PROXY"]
+        elif "no_proxy" in os.environ:
+            exclusions = os.environ["no_proxy"]
+
+    # Update proxy configuration
+    _proxyconfig.update(url, exclusions=exclusions)
+    
+    # Detect and register proxy func
+    if _proxyconfig.username and not _proxyconfig._password:
+        if password_func is None:
+            service = os.environ.get("PROXY_PASSWORD_SERVICE", None)
+            if service:
+                if not _with_credentials:
+                    logger.error(f"cannot register PROXY_PASSWORD_SERVICE \"{service}\": zut[credentials] optional dependencies are not installed")
+                else:
+                    password_func = lambda username: get_password(service, username)
+                
+        if password_func:
+            _proxyconfig.set_password_func(password_func)
+
+    def _del_if_exists(data: dict, attr: str):
+        if attr in data:
+            del data[attr]
+
+    # Remove environment variables (would take precedence in some cases, which might cause issues: e.g. should contain password or not?)
+    _del_if_exists(os.environ, "http_proxy")
+    _del_if_exists(os.environ, "https_proxy")
+    _del_if_exists(os.environ, "HTTP_PROXY")
+    _del_if_exists(os.environ, "HTTPS_PROXY")
+
+    # Ensure no_proxy is specified (must be passed as environment variable for urllib)
+    env_exclusions = _proxyconfig.env_exclusions_str
+    if env_exclusions:
+        os.environ["no_proxy"] = env_exclusions
+        os.environ["NO_PROXY"] = env_exclusions
+    else:
+        _del_if_exists(os.environ, "no_proxy")
+        _del_if_exists(os.environ, "NO_PROXY")
+
+    # Stop if no proxy specified/detected
+    if not _proxyconfig.host:
+        return
+    
+    # Register proxy for urllib
+    try:
+        handler = SimpleProxyHandler(_proxyconfig)
+        opener = urllib.request.build_opener(handler)
+        urllib.request.install_opener(opener)
+    except Exception as e:
+        logger.error("cannot register proxy for urllib: %s", e)
+
+
+def get_configured_proxy_url(for_url: str = None, include_password: bool = False) -> str:
+    """
+    Return currently configured proxy URL.
+    If `for_url` is given, return None if the proxy is excluded for this url.
+    """
+    if for_url:
+        o = urlparse(for_url)
+        if urllib.request.proxy_bypass(o.netloc if o.netloc else o.path):
+            return None
+    return _proxyconfig.get_proxy_url(include_password=include_password)
+
+
+def get_configured_proxy_hostport(for_url: str = None, include_password: bool = False) -> tuple[str,int]:
+    """
+    Return currently configured proxy host and port.
+    If `for_url` is given, return None if the proxy is excluded for this url.
+    """
+    if for_url:
+        o = urlparse(for_url)
+        if urllib.request.proxy_bypass(o.netloc if o.netloc else o.path):
+            return None
+    return _proxyconfig.host, _proxyconfig.port
+
+
+def get_configured_proxy_exclusions() -> list[str]:
+    """
+    Return currently configured proxy exclusions.
+    """
+    return _proxyconfig.exclusions
+
+
+def check_urllib_connectivity(url: str, expected_regex: re.Pattern|str, label=None, timeout: float = None, case: TestCase = None) -> bool:
+    """
+    Check network connectivity using urllib library.
+    - `timeout`: in seconds (defaults to 3 seconds).
+
+    Return `True` on success, `False` on failure.
+    """        
+    if not isinstance(expected_regex, re.Pattern):
+        expected_regex = re.compile(expected_regex)
+
+    if label is None:
+        label = url
+
+    if not timeout:
+        timeout = float(os.environ.get("CHECK_CONNECTIVITY_TIMEOUT", 10))
+
+    msg=f"{label} urllib"
+
+    try:
+        res = urllib.request.urlopen(url, timeout=timeout)
+        text = res.read().decode('utf-8')
+        text_startup = text[0:20].replace('\n', '\\n').replace('\r', '\\r') + ('' if len(text) > 20 else '')
+        
+        if not expected_regex.match(text):
+            report_failure(case, f"{msg}: response ({Colors.RED}{text_startup}{Colors.RESET}) does not match expected regex ({Colors.GRAY}{expected_regex.pattern}{Colors.RESET}")
+            return False
+
+        logger.info(f"{msg}: {Colors.GREEN}success{Colors.RESET} (response: {Colors.GRAY}{text_startup}{Colors.RESET})")
+        return True
+    except urllib.error.URLError as e:
+        report_failure(case, f"{msg}: {Colors.RED}{e.reason}{Colors.RESET}")
+        return False
+
+
+def check_connectivity(url: str, expected_regex: re.Pattern|str, label=None, timeout: float = None, case: TestCase = None) -> bool:
+    """
+    Check network connectivity with urllib library, and winhttp library on Windows (if [winhttp] extra dependencies are installed).
+    - `timeout`: in seconds (defaults to 3 seconds).
+
+    Return `True` on success, `False` on failure.
+    """ 
+    ok = check_urllib_connectivity(url, expected_regex, label=label, timeout=timeout, case=case)
+
+    if _with_winhttp:
+        ok = ok and check_winhttp_connectivity(url, expected_regex, label=label, timeout=timeout, case=case)
+
+    return ok
```

## zut/network/commons.py

 * *Ordering differences only*

```diff
@@ -1,121 +1,121 @@
-from __future__ import annotations
-import re, logging
-from types import FunctionType
-from urllib.parse import quote, unquote, urlparse
-from unittest import TestCase
-
-logger = logging.getLogger(__name__)
-
-
-def report_failure(case: TestCase, msg: str):
-    if case:
-        case.fail(msg)
-    else:
-        logger.error(msg)
-
-
-class ProxyConfig:
-    def __init__(self):
-        self.clear()
-
-    def clear(self):
-        self.host: str = None
-        self.port: int = None
-        self.username: str = None
-        self.password_func: FunctionType = None
-        self.scheme: str = "http"
-        self.exclusions: list[str] = None
-
-        # caches
-        self._non_cidr_exclusions_str = '__undefined__'
-        self._password: str = None
-
-    def update(self, url: str, exclusions: str|list[str] = None):
-        self.clear()
-        if url is None:
-            return
-
-        o = urlparse(url)
-        m = re.match(r"^(?:(?P<username>[^\:]+)(?:\:(?P<password>[^\:]+))?@)?(?P<host>[^@\:]+)\:(?P<port>\d+)$", o.netloc)
-        if not m:
-            raise ValueError("invalid url netloc \"%s\"" % o.netloc)
-
-        self.host = unquote(m.group("host")) if m.group("host") else None
-        self.port = int(m.group("port"))
-        self.username = unquote(m.group("username")) if m.group("username") else None
-        self._password = unquote(m.group("password")) if m.group("password") else None
-        self.scheme = o.scheme
-
-        if exclusions is not None:
-            if isinstance(exclusions, str):
-                self.exclusions = exclusions.split(',')
-            else:
-                self.exclusions = exclusions
-
-    def set_password_func(self, func: FunctionType):
-        self.password_func = func
-
-    @property
-    def is_rtm_host(self):
-        return self.host.endswith(('.rtm.fr','.rtm.lan'))
-
-    @property
-    def hostport(self):
-        if not self.host:
-            return None
-        return f"{self.host}:{self.port}"
-
-    @property
-    def env_exclusions_str(self) -> str:
-        """
-        Return a comma-separated string of exclusions, for use as an environment variable.
-        """
-        if not self.exclusions:
-            return None
-        return ",".join(self.exclusions)
-
-    @property
-    def non_cidr_exclusions_str(self) -> str:
-        """
-        Return a comma-separated string of exclusions, excluding CIDR blocks (not supported by WinHTTP).
-        """
-        if self._non_cidr_exclusions_str == '__undefined__':
-            if self.exclusions:
-                self._non_cidr_exclusions_str = ",".join([exclusion for exclusion in self.exclusions if not "/" in exclusion])
-            else:
-                logger.warning("no exclusions for proxy: missing NO_PROXY environment variable?")
-                self._non_cidr_exclusions_str = "localhost"
-
-        return self._non_cidr_exclusions_str
-
-    @property
-    def password(self):
-        if self._password is None:
-            if self.username and self.password_func:
-                self._password = self.password_func(self.username)
-
-        return self._password
-
-    def get_proxy_url(self, include_password=False):
-        if self.host is None:
-            return None
-        
-        proxy_url = self.scheme + "://"
-
-        if self.username:
-            proxy_url += quote(self.username)
-
-            if include_password:
-                if self.password:
-                    if include_password == "*":
-                        proxy_url += ":" + ("*" * len(self.password))
-                    else:
-                        proxy_url += ":" + quote(self.password)
-            
-            proxy_url += "@"
-
-        proxy_url += f"{quote(self.host)}:{self.port}"
-        return proxy_url
-
-
-_proxyconfig = ProxyConfig()
+from __future__ import annotations
+import re, logging
+from types import FunctionType
+from urllib.parse import quote, unquote, urlparse
+from unittest import TestCase
+
+logger = logging.getLogger(__name__)
+
+
+def report_failure(case: TestCase, msg: str):
+    if case:
+        case.fail(msg)
+    else:
+        logger.error(msg)
+
+
+class ProxyConfig:
+    def __init__(self):
+        self.clear()
+
+    def clear(self):
+        self.host: str = None
+        self.port: int = None
+        self.username: str = None
+        self.password_func: FunctionType = None
+        self.scheme: str = "http"
+        self.exclusions: list[str] = None
+
+        # caches
+        self._non_cidr_exclusions_str = '__undefined__'
+        self._password: str = None
+
+    def update(self, url: str, exclusions: str|list[str] = None):
+        self.clear()
+        if url is None:
+            return
+
+        o = urlparse(url)
+        m = re.match(r"^(?:(?P<username>[^\:]+)(?:\:(?P<password>[^\:]+))?@)?(?P<host>[^@\:]+)\:(?P<port>\d+)$", o.netloc)
+        if not m:
+            raise ValueError("invalid url netloc \"%s\"" % o.netloc)
+
+        self.host = unquote(m.group("host")) if m.group("host") else None
+        self.port = int(m.group("port"))
+        self.username = unquote(m.group("username")) if m.group("username") else None
+        self._password = unquote(m.group("password")) if m.group("password") else None
+        self.scheme = o.scheme
+
+        if exclusions is not None:
+            if isinstance(exclusions, str):
+                self.exclusions = exclusions.split(',')
+            else:
+                self.exclusions = exclusions
+
+    def set_password_func(self, func: FunctionType):
+        self.password_func = func
+
+    @property
+    def is_rtm_host(self):
+        return self.host.endswith(('.rtm.fr','.rtm.lan'))
+
+    @property
+    def hostport(self):
+        if not self.host:
+            return None
+        return f"{self.host}:{self.port}"
+
+    @property
+    def env_exclusions_str(self) -> str:
+        """
+        Return a comma-separated string of exclusions, for use as an environment variable.
+        """
+        if not self.exclusions:
+            return None
+        return ",".join(self.exclusions)
+
+    @property
+    def non_cidr_exclusions_str(self) -> str:
+        """
+        Return a comma-separated string of exclusions, excluding CIDR blocks (not supported by WinHTTP).
+        """
+        if self._non_cidr_exclusions_str == '__undefined__':
+            if self.exclusions:
+                self._non_cidr_exclusions_str = ",".join([exclusion for exclusion in self.exclusions if not "/" in exclusion])
+            else:
+                logger.warning("no exclusions for proxy: missing NO_PROXY environment variable?")
+                self._non_cidr_exclusions_str = "localhost"
+
+        return self._non_cidr_exclusions_str
+
+    @property
+    def password(self):
+        if self._password is None:
+            if self.username and self.password_func:
+                self._password = self.password_func(self.username)
+
+        return self._password
+
+    def get_proxy_url(self, include_password=False):
+        if self.host is None:
+            return None
+        
+        proxy_url = self.scheme + "://"
+
+        if self.username:
+            proxy_url += quote(self.username)
+
+            if include_password:
+                if self.password:
+                    if include_password == "*":
+                        proxy_url += ":" + ("*" * len(self.password))
+                    else:
+                        proxy_url += ":" + quote(self.password)
+            
+            proxy_url += "@"
+
+        proxy_url += f"{quote(self.host)}:{self.port}"
+        return proxy_url
+
+
+_proxyconfig = ProxyConfig()
```

## zut/network/winhttp.py

```diff
@@ -1,75 +1,75 @@
-from __future__ import annotations
-from unittest import TestCase
-import re, os, logging, win32com.client, win32inetcon, pywintypes
-from ..format import RED, GREEN, GRAY
-from .commons import _proxyconfig, report_failure
-
-logger = logging.getLogger(__name__)
-
-
-def create_winhttp_request(timeout: float = None):
-    """
-    Create a winhttp request.
-    - `timeout`: in seconds.
-    """
-    winhttp_req = win32com.client.Dispatch('WinHTTP.WinHTTPRequest.5.1')
-
-    if timeout:
-        winhttp_req.SetTimeouts(int(timeout*1000), int(timeout*1000), int(timeout*1000), int(timeout*1000))
-
-    if _proxyconfig.hostport:
-        # See: https://docs.microsoft.com/en-us/windows/win32/winhttp/iwinhttprequest-setproxy
-        # NOTE: no need to pass credentials, this is handled directly by Windows
-        HTTPREQUEST_PROXYSETTING_DEFAULT   = 0
-        HTTPREQUEST_PROXYSETTING_PRECONFIG = 0
-        HTTPREQUEST_PROXYSETTING_DIRECT    = 1
-        HTTPREQUEST_PROXYSETTING_PROXY     = 2
-        winhttp_req.SetProxy(HTTPREQUEST_PROXYSETTING_PROXY, _proxyconfig.hostport, _proxyconfig.non_cidr_exclusions_str)
-        winhttp_req.SetAutoLogonPolicy(HTTPREQUEST_PROXYSETTING_DEFAULT)
-
-    return winhttp_req
-
-
-def check_winhttp_connectivity(url: str, expected_regex: re.Pattern|str, label=None, timeout: float = None, case: TestCase = None) -> bool:
-    """
-    Check network connectivity using winhttp library.
-    - `timeout`: in seconds (defaults to 3 seconds).
-    
-    Return `True` on success, `False` on failure.
-    """        
-    if not isinstance(expected_regex, re.Pattern):
-        expected_regex = re.compile(expected_regex)
-
-    if label is None:
-        label = url
-
-    if not timeout:
-        timeout = float(os.environ.get("CHECK_CONNECTIVITY_TIMEOUT", 3))
-
-    msg=f"{label} winhttp"
-
-    winhttp_req = create_winhttp_request(timeout=timeout)
-    winhttp_req.Open('GET', url, False)
-    try:
-        winhttp_req.Send()
-        winhttp_req.WaitForResponse()
-        if winhttp_req.Status != 200:
-            report_failure(case, f"{msg}: {winhttp_req.Status} {winhttp_req.StatusText}")
-            return False
-
-        text = winhttp_req.ResponseText
-        text_startup = text[0:20].replace('\n', '\\n').replace('\r', '\\r') + ('' if len(text) > 20 else '')
-
-        if not expected_regex.match(text):
-            report_failure(case, f"{msg}: response ({RED % text_startup}) does not match expected regex ({GRAY % expected_regex.pattern})")
-            return False
-        
-        logger.info(f"{msg}: {GREEN % 'success'} (response: {GRAY % text_startup})")
-        return True
-    except pywintypes.com_error as e:
-        if e.excepinfo[5] + 2**32 & 0xffff == win32inetcon.ERROR_INTERNET_TIMEOUT:
-            details = "timed out"
-        else:
-            details = e.excepinfo[2].strip()
-        report_failure(case, f"{msg}: {RED % details}")
-        return False
+from __future__ import annotations
+from unittest import TestCase
+import re, os, logging, win32com.client, win32inetcon, pywintypes
+from ..format import RED, GREEN, GRAY
+from .commons import _proxyconfig, report_failure
+
+logger = logging.getLogger(__name__)
+
+
+def create_winhttp_request(timeout: float = None):
+    """
+    Create a winhttp request.
+    - `timeout`: in seconds.
+    """
+    winhttp_req = win32com.client.Dispatch('WinHTTP.WinHTTPRequest.5.1')
+
+    if timeout:
+        winhttp_req.SetTimeouts(int(timeout*1000), int(timeout*1000), int(timeout*1000), int(timeout*1000))
+
+    if _proxyconfig.hostport:
+        # See: https://docs.microsoft.com/en-us/windows/win32/winhttp/iwinhttprequest-setproxy
+        # NOTE: no need to pass credentials, this is handled directly by Windows
+        HTTPREQUEST_PROXYSETTING_DEFAULT   = 0
+        HTTPREQUEST_PROXYSETTING_PRECONFIG = 0
+        HTTPREQUEST_PROXYSETTING_DIRECT    = 1
+        HTTPREQUEST_PROXYSETTING_PROXY     = 2
+        winhttp_req.SetProxy(HTTPREQUEST_PROXYSETTING_PROXY, _proxyconfig.hostport, _proxyconfig.non_cidr_exclusions_str)
+        winhttp_req.SetAutoLogonPolicy(HTTPREQUEST_PROXYSETTING_DEFAULT)
+
+    return winhttp_req
+
+
+def check_winhttp_connectivity(url: str, expected_regex: re.Pattern|str, label=None, timeout: float = None, case: TestCase = None) -> bool:
+    """
+    Check network connectivity using winhttp library.
+    - `timeout`: in seconds (defaults to 3 seconds).
+    
+    Return `True` on success, `False` on failure.
+    """        
+    if not isinstance(expected_regex, re.Pattern):
+        expected_regex = re.compile(expected_regex)
+
+    if label is None:
+        label = url
+
+    if not timeout:
+        timeout = float(os.environ.get("CHECK_CONNECTIVITY_TIMEOUT", 10))
+
+    msg=f"{label} winhttp"
+
+    winhttp_req = create_winhttp_request(timeout=timeout)
+    winhttp_req.Open('GET', url, False)
+    try:
+        winhttp_req.Send()
+        winhttp_req.WaitForResponse()
+        if winhttp_req.Status != 200:
+            report_failure(case, f"{msg}: {winhttp_req.Status} {winhttp_req.StatusText}")
+            return False
+
+        text = winhttp_req.ResponseText
+        text_startup = text[0:20].replace('\n', '\\n').replace('\r', '\\r') + ('' if len(text) > 20 else '')
+
+        if not expected_regex.match(text):
+            report_failure(case, f"{msg}: response ({RED % text_startup}) does not match expected regex ({GRAY % expected_regex.pattern})")
+            return False
+        
+        logger.info(f"{msg}: {GREEN % 'success'} (response: {GRAY % text_startup})")
+        return True
+    except pywintypes.com_error as e:
+        if e.excepinfo[5] + 2**32 & 0xffff == win32inetcon.ERROR_INTERNET_TIMEOUT:
+            details = "timed out"
+        else:
+            details = e.excepinfo[2].strip()
+        report_failure(case, f"{msg}: {RED % details}")
+        return False
```

## Comparing `zut-0.5.3.dist-info/LICENSE.txt` & `zut-0.6.0.dist-info/LICENSE.txt`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-Copyright (C) 2022 Ipamo
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+Copyright (C) 2022 Ipamo
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 SOFTWARE.
```

