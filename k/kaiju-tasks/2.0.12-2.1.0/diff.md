# Comparing `tmp/kaiju_tasks-2.0.12-py3-none-any.whl.zip` & `tmp/kaiju_tasks-2.1.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 21486 bytes, number of entries: 20
--rw-r--r--  2.0 unx      152 b- defN 23-Apr-27 11:56 kaiju_tasks/__init__.py
--rw-r--r--  2.0 unx     5135 b- defN 23-Apr-27 11:56 kaiju_tasks/etc.py
--rw-r--r--  2.0 unx     8492 b- defN 23-Apr-27 11:56 kaiju_tasks/executor.py
--rw-r--r--  2.0 unx     1290 b- defN 23-Apr-27 11:56 kaiju_tasks/fixtures.py
--rw-r--r--  2.0 unx     6117 b- defN 23-Apr-27 11:56 kaiju_tasks/interface.py
--rw-r--r--  2.0 unx    18363 b- defN 23-Apr-27 11:56 kaiju_tasks/manager.py
--rw-r--r--  2.0 unx     1687 b- defN 23-Apr-27 11:56 kaiju_tasks/notifications.py
--rw-r--r--  2.0 unx      191 b- defN 23-Apr-27 11:56 kaiju_tasks/services.py
--rw-r--r--  2.0 unx     4164 b- defN 23-Apr-27 11:56 kaiju_tasks/tables.py
--rw-r--r--  2.0 unx       38 b- defN 23-Apr-27 11:56 kaiju_tasks/tasks_gui/__init__.py
--rw-r--r--  2.0 unx     2011 b- defN 23-Apr-27 11:56 kaiju_tasks/tasks_gui/models.py
--rw-r--r--  2.0 unx     4272 b- defN 23-Apr-27 11:56 kaiju_tasks/tasks_gui/service.py
--rw-r--r--  2.0 unx      350 b- defN 23-Apr-27 11:56 kaiju_tasks/tasks_gui/validators.py
--rw-r--r--  2.0 unx       42 b- defN 23-Apr-27 11:56 kaiju_tasks/tests/__init__.py
--rw-r--r--  2.0 unx    11345 b- defN 23-Apr-27 11:56 kaiju_tasks/tests/test_task_management.py
--rw-rw-rw-  2.0 unx      610 b- defN 23-Apr-27 11:56 kaiju_tasks-2.0.12.dist-info/LICENSE
--rw-r--r--  2.0 unx     2970 b- defN 23-Apr-27 11:56 kaiju_tasks-2.0.12.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-27 11:56 kaiju_tasks-2.0.12.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 23-Apr-27 11:56 kaiju_tasks-2.0.12.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1666 b- defN 23-Apr-27 11:56 kaiju_tasks-2.0.12.dist-info/RECORD
-20 files, 68999 bytes uncompressed, 18764 bytes compressed:  72.8%
+Zip file size: 21707 bytes, number of entries: 20
+-rw-r--r--  2.0 unx      151 b- defN 23-Jun-10 11:59 kaiju_tasks/__init__.py
+-rw-r--r--  2.0 unx     5212 b- defN 23-Jun-10 11:59 kaiju_tasks/etc.py
+-rw-r--r--  2.0 unx     8196 b- defN 23-Jun-10 11:59 kaiju_tasks/executor.py
+-rw-r--r--  2.0 unx     1290 b- defN 23-Jun-10 11:59 kaiju_tasks/fixtures.py
+-rw-r--r--  2.0 unx     5919 b- defN 23-Jun-10 11:59 kaiju_tasks/interface.py
+-rw-r--r--  2.0 unx    18900 b- defN 23-Jun-10 11:59 kaiju_tasks/manager.py
+-rw-r--r--  2.0 unx     1517 b- defN 23-Jun-10 11:59 kaiju_tasks/notifications.py
+-rw-r--r--  2.0 unx      191 b- defN 23-Jun-10 11:59 kaiju_tasks/services.py
+-rw-r--r--  2.0 unx     4267 b- defN 23-Jun-10 11:59 kaiju_tasks/tables.py
+-rw-r--r--  2.0 unx       38 b- defN 23-Jun-10 11:59 kaiju_tasks/tasks_gui/__init__.py
+-rw-r--r--  2.0 unx     2011 b- defN 23-Jun-10 11:59 kaiju_tasks/tasks_gui/models.py
+-rw-r--r--  2.0 unx     4272 b- defN 23-Jun-10 11:59 kaiju_tasks/tasks_gui/service.py
+-rw-r--r--  2.0 unx      350 b- defN 23-Jun-10 11:59 kaiju_tasks/tasks_gui/validators.py
+-rw-r--r--  2.0 unx       42 b- defN 23-Jun-10 11:59 kaiju_tasks/tests/__init__.py
+-rw-r--r--  2.0 unx    12986 b- defN 23-Jun-10 11:59 kaiju_tasks/tests/test_task_management.py
+-rw-rw-rw-  2.0 unx      610 b- defN 23-Jun-10 12:00 kaiju_tasks-2.1.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3056 b- defN 23-Jun-10 12:00 kaiju_tasks-2.1.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-10 12:00 kaiju_tasks-2.1.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       12 b- defN 23-Jun-10 12:00 kaiju_tasks-2.1.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1661 b- defN 23-Jun-10 12:00 kaiju_tasks-2.1.0.dist-info/RECORD
+20 files, 70773 bytes uncompressed, 18995 bytes compressed:  73.2%
```

## zipnote {}

```diff
@@ -39,23 +39,23 @@
 
 Filename: kaiju_tasks/tests/__init__.py
 Comment: 
 
 Filename: kaiju_tasks/tests/test_task_management.py
 Comment: 
 
-Filename: kaiju_tasks-2.0.12.dist-info/LICENSE
+Filename: kaiju_tasks-2.1.0.dist-info/LICENSE
 Comment: 
 
-Filename: kaiju_tasks-2.0.12.dist-info/METADATA
+Filename: kaiju_tasks-2.1.0.dist-info/METADATA
 Comment: 
 
-Filename: kaiju_tasks-2.0.12.dist-info/WHEEL
+Filename: kaiju_tasks-2.1.0.dist-info/WHEEL
 Comment: 
 
-Filename: kaiju_tasks-2.0.12.dist-info/top_level.txt
+Filename: kaiju_tasks-2.1.0.dist-info/top_level.txt
 Comment: 
 
-Filename: kaiju_tasks-2.0.12.dist-info/RECORD
+Filename: kaiju_tasks-2.1.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## kaiju_tasks/__init__.py

```diff
@@ -1,7 +1,7 @@
 from .etc import *
 from .tables import *
 from .services import *
 
-__version__ = '2.0.12'
+__version__ = '2.1.0'
 __python_version__ = '3.8'
 __author__ = 'antonnidhoggr@me.com'
```

## kaiju_tasks/etc.py

```diff
@@ -36,15 +36,15 @@
 
 
 class Limit(Enum):
     """Time limit constants."""
 
     MAX_STAGES = 100  #: max number of stages per task
     MAX_RETRIES = 10  #: max retries per job
-    MIN_DT = 10  #: (s) minimum acknowledged time interval in all calculations
+    MIN_T = 10  #: (s) minimum acknowledged time interval in all calculations
     DEFAULT_T = 300  #: (s) default timeout
     MAX_T = 3600 * 4  #: (s) maximum allowed timeout for a single task
     PING_INTERVAL = 20  #: (s) executor ping interval
 
 
 class Permission(Enum):
     """Task service user permission keys."""
@@ -122,14 +122,15 @@
 
     active: bool  #: inactive tasks are not queued
     cron: str  #: cron instructions for periodic tasks
     max_exec_timeout: int  #: (s) max allowed execution time in total
     max_retries: int  #: max retries for a failed task (0 for no retries)
     restart_policy: str  #: how the task will be restarted
     notify: bool  #: notify user about status changes
+    next_task: Optional[str]  #: next task to run after finishing of this one
 
     # meta
 
     name: Optional[str]  #: task short name
     description: Optional[str]  #: task long description
     meta: dict  #: task metadata
```

## kaiju_tasks/executor.py

```diff
@@ -77,15 +77,15 @@
     @property
     def closed(self) -> bool:
         return self._closing
 
     async def run_task(self, data: ExecutorTask) -> None:
         """Run a task and callback its results to a manager."""
         stage, deadline = data['stage'], data['exec_deadline']
-        self.logger.info('Acquired task %s', data['id'], task_id=data['id'], stage=stage, deadline=deadline)
+        self.logger.info('Acquired task', task_id=data['id'], stage=stage, deadline=deadline)
         template_data = self._get_template_data(data)
         headers = {
             JSONRPCHeaders.REQUEST_DEADLINE_HEADER: deadline,
             JSONRPCHeaders.CORRELATION_ID_HEADER: data['job_id'],
         }
         await self._alert_on_stage_execution(data, data['stage'])
         async with self._counter:
@@ -95,17 +95,15 @@
                 if self._closing:
                     break
                 stage = stage + n
                 try:
                     cmd = Template(cmd).fill(template_data)
                     _, result = await self._rpc.call(cmd, headers, session=None)
                 except Exception as exc:
-                    self.logger.error(
-                        'Error while preparing for a stage execution', exc=exc, cmd=cmd, task_id=data['id'], stage=stage
-                    )
+                    self.logger.error('Task execution error', exc_info=exc, task_id=data['id'], stage=stage)
                     result = RPCError(id=None, error=InternalError(base_exc=exc, message='Template evaluation error'))
                     await self._write_stage_result(data, stage, error=True, result=result)
                     break
                 else:
                     error, result = self._parse_result(result)
                     await self._write_stage_result(data, stage, error, result)
                     if error:
@@ -141,18 +139,15 @@
     async def _loop(self):
         while not self._closing:
             await self._send_ping()
             await asyncio.sleep(Limit.PING_INTERVAL.value)
 
     async def _alert_on_stage_execution(self, data: ExecutorTask, stage: int):
         self.logger.info(
-            'Executing stage %d/%d of %s',
-            stage,
-            data['stages'],
-            data['id'],
+            'Executing stage',
             task_id=data['id'],
             stage=stage,
             deadline=data['exec_deadline'],
         )
         await retry(
             self._stream.call,
             kws=dict(
@@ -165,21 +160,15 @@
             retries=3,
             retry_timeout=1,
             logger=self.logger,
         )
 
     async def _write_stage_result(self, data: ExecutorTask, stage: int, error: bool, result):
         self.logger.info(
-            'Writing stage %d/%d of %s',
-            stage,
-            data['stages'],
-            data['id'],
-            task_id=data['id'],
-            stage=stage,
-            deadline=data['exec_deadline'],
+            'Writing stage result', task_id=data['id'], stage=stage, deadline=data['exec_deadline'], error=error
         )
         await retry(
             self._stream.call,
             kws=dict(
                 namespace=self.manager_namespace,
                 topic=self.manager_topic,
                 headers={JSONRPCHeaders.CORRELATION_ID_HEADER: data['job_id']},
@@ -195,30 +184,29 @@
             ),
             retries=3,
             retry_timeout=1,
             logger=self.logger,
         )
 
     async def _send_ping(self):
-        self.logger.debug('Ping')
         await retry(
             self._stream.call,
             kws=dict(
                 namespace=self.manager_namespace,
                 topic=self.manager_topic,
                 method=f'{TaskManager.service_name}.ping',
                 params={'executor_id': self.app.id},
             ),
             retries=3,
             retry_timeout=1,
             logger=self.logger,
         )
 
     async def _suspend_self(self):
-        self.logger.info('Suspending')
+        self.logger.info('Suspending executor')
         await retry(
             self._stream.call,
             kws=dict(
                 namespace=self.manager_namespace,
                 topic=self.manager_topic,
                 method=f'{TaskManager.service_name}.suspend_executor',
                 params={'executor_id': self.app.id},
```

## kaiju_tasks/interface.py

```diff
@@ -1,20 +1,18 @@
 import time
 import uuid
 from datetime import datetime, timedelta
-from typing import Optional
 
 import sqlalchemy as sa  # noqa pycharm
 from croniter import croniter  # noqa pycharm
 
 import kaiju_tools.jsonschema as j
 from kaiju_db.services import SQLService
 from kaiju_tools.exceptions import ValidationError
 from kaiju_tools.rpc import AbstractRPCCompatible
-from kaiju_tools.services import Session
 
 from .etc import Permission, TaskStatus, Task, RestartPolicy, Limit
 from .tables import tasks
 
 __all__ = ['TaskService', 'task_schema']
 
 
@@ -26,19 +24,19 @@
 task_schema = j.Object(
     {
         'id': j.String(minLength=1),
         'app': j.String(),
         'commands': j.Array(task_command, minItems=1, maxItems=Limit.MAX_STAGES.value),
         'kws': j.Object(),
         'cron': j.String(),
-        'max_exec_timeout': j.Integer(minimum=Limit.MIN_DT.value, maximum=Limit.MAX_T.value),
+        'max_exec_timeout': j.Integer(minimum=Limit.MIN_T.value, maximum=Limit.MAX_T.value),
         'max_retries': j.Integer(minimum=0, maximum=Limit.MAX_RETRIES.value),
         'restart_policy': j.Enumerated(enum=[RestartPolicy.CURRENT.value, RestartPolicy.FIRST.value]),
+        'next_task': j.String(minLength=1),
         'notify': j.Boolean(),
-        'system': j.Boolean(),
         'name': j.String(),
         'description': j.String(),
         'meta': j.Object(),
     },
     additionalProperties=False,
     required=[],
 )
@@ -98,15 +96,14 @@
             await self._wrap_update(None, sql)
         else:
             raise ValueError('Task is in %s and cannot be restarted.', status)
 
     def prepare_insert_data(self, data: dict):
         """Prepare task."""
         data = self._validate_data(data)
-        session = self.get_session()
         task = Task(
             id=data.get('id', str(uuid.uuid4()).replace('-', '')),
             app=data.get('app', self.app.name),
             commands=data['commands'],
             kws=data.get('kws', {}),
             cron=data.get('cron'),
             max_exec_timeout=data.get('max_exec_timeout', Limit.DEFAULT_T.value),
@@ -121,20 +118,21 @@
             stage=0,
             stages=len(data['commands']),
             result=[],
             created=sa.func.now(),
             queued_at=None,
             exec_deadline=None,
             next_run=int(time.time()),
-            user_id=self.get_user_id(session),
+            user_id=self.get_user_id(),
             executor_id=None,
             job_id=uuid.uuid4().hex[:8],
             retries=0,
             exit_code=None,
             error=None,
+            next_task=data.get('next_task'),
         )
         return task
 
     def prepare_update_data(self, data: dict):
         return self._validate_data(data)
 
     def _validate_data(self, data: dict) -> dict:
@@ -143,24 +141,22 @@
         if cron:
             croniter(data.get('cron'), start_time=datetime.now()).next()  # testing for validity
         commands = data.get('commands')
         if commands and len(commands) == 0:
             raise ValidationError('Commands must not be empty.')
         return data
 
-    def _place_user_condition(self, sql, session: Optional[Session], permission):
+    def _set_user_condition(self, sql, permission):
         """Places user condition if a user has no admin/system privileges."""
-        if self.has_permission(session, permission):
-            user_id = self.get_user_id(session)
+        if self.has_permission(permission):
+            user_id = self.get_user_id()
             sql = sql.where(self.table.c.user_id == user_id)
         return sql
 
     def _get_condition_hook(self, sql):
-        session = self.get_session()
-        return self._place_user_condition(sql, session, Permission.VIEW_OTHERS_TASKS.value)
+        return self._set_user_condition(sql, Permission.VIEW_OTHERS_TASKS.value)
 
     def _update_condition_hook(self, sql):
-        session = self.get_session()
-        return self._place_user_condition(sql, session, Permission.MODIFY_OTHERS_TASKS.value)
+        return self._set_user_condition(sql, Permission.MODIFY_OTHERS_TASKS.value)
 
     def _delete_condition_hook(self, sql):
         return self._update_condition_hook(sql)
```

## kaiju_tasks/manager.py

```diff
@@ -1,22 +1,22 @@
-import asyncio
 import uuid
 from datetime import datetime, timezone, timedelta
 from time import time
 from typing import Any, List
 
 import sqlalchemy as sa  # noqa pycharm
 from croniter import croniter  # noqa pycharm
 
 from kaiju_db.services import DatabaseService
 from kaiju_redis import RedisTransportService
 from kaiju_tools.streams import Listener, Topics
 from kaiju_tools.rpc import AbstractRPCCompatible
 from kaiju_tools.rpc.etc import JSONRPCHeaders
 from kaiju_tools.services import ContextableService
+from kaiju_tools.scheduler import Scheduler
 
 from .etc import Task, TaskStatus, RestartPolicy, Notification, Limit, ExecutorTask, ExitCode
 from .notifications import NotificationService
 from .tables import tasks
 
 __all__ = ['TaskManager']
 
@@ -30,42 +30,45 @@
     def __init__(
         self,
         app,
         database_service: DatabaseService = None,
         stream_service: Listener = None,
         redis_transport: RedisTransportService = None,
         notification_service: NotificationService = None,
+        scheduler_service: Scheduler = None,
         executor_topic: str = Topics.rpc,
         refresh_rate: int = 1,
         suspended_task_lifetime_hours: int = 24,
         logger=None,
     ):
         """Initialize.
 
         :param app: web app
         :param database_service: database connector instance or service name
         :param stream_service: stream service (Listener) for sending rpc queries
         :param redis_transport: a cache for executor states\
         :param notification_service: notification service instance or service name
+        :param scheduler_service: internal loop scheduler
         :param refresh_rate: watcher loop refresh rate in seconds
         :param executor_topic: optional topic name for executor
         :param suspended_task_lifetime_hours: if task was last queued before this interval, it won't be executed again
         :param logger: optional logger
         """
         super().__init__(app=app, logger=logger)
         self._db = self.discover_service(database_service, cls=DatabaseService)
+        self._scheduler = scheduler_service
         self._stream = stream_service
         self._notifications = notification_service
         self._redis = redis_transport
         self._refresh_interval = max(1, int(refresh_rate))
         self._suspended_lifetime = max(1, int(suspended_task_lifetime_hours))
         self._executor_topic = executor_topic
         self.executor_map_key = f'{self.service_name}.executors'
-        self._closing = None
         self._task = None
+        self._closing = None
 
     @property
     def routes(self) -> dict:
         return {
             'list_active_executors': self.list_active_executors,
             'ping': self.ping,
             'suspend_executor': self.suspend_executor,
@@ -76,25 +79,24 @@
 
     @property
     def permissions(self) -> dict:
         return {'*': self.PermissionKeys.GLOBAL_SYSTEM_PERMISSION}
 
     async def init(self):
         self._closing = False
+        self._scheduler: Scheduler = self.discover_service(self._scheduler, cls=Scheduler)
         self._notifications = self.discover_service(self._notifications, cls=NotificationService)
         self._redis = self.discover_service(self._redis, cls=RedisTransportService)
         self._stream = self.discover_service(self._stream, cls=Listener)
-        self._task = asyncio.ensure_future(self.loop())
+        self._task = self._scheduler.schedule_task(
+            self._queue_tasks, interval=self._refresh_interval, policy=Scheduler.ExecPolicy.WAIT, name='taskman.loop'
+        )
 
     async def close(self):
-        self._closing = True
-        if self._task and not self._task.done():
-            await self._task
-        self._task = None
-        self._closing = None
+        self._task.enabled = False
 
     @property
     def closed(self) -> bool:
         return self._closing is None
 
     async def list_active_executors(self) -> dict:
         """Return executor ids and their last ping time."""
@@ -116,28 +118,26 @@
 
     async def ping(self, executor_id: uuid.UUID) -> None:
         """Ping the manager to tell that you're ok."""
         await self._redis.hset(self.executor_map_key, {str(executor_id): int(time())})
 
     async def suspend_executor(self, executor_id: uuid.UUID) -> None:
         """Suspend an executor and its tasks."""
-        self.logger.debug('Suspending executor.', executor_id=executor_id)
+        self.logger.debug('Suspending executor (requested)', executor_id=executor_id)
         sql = (
             self.table.update()
             .where(sa.and_(self.table.c.status == TaskStatus.EXECUTED.value, self.table.c.executor_id == executor_id))
             .values({'status': TaskStatus.SUSPENDED.value, 'executor_id': None})
         )
         await self._db.execute(sql)
         await self._redis.hdel(self.executor_map_key, [str(executor_id)])
 
     async def execute_stage(self, id: str, executor_id: uuid.UUID, stage: int):  # noqa id
         """Tell the manager which stage is being executed."""
-        self.logger.info(
-            'Stage %d of %s is being executed.', stage, id, task_id=id, stage=stage, executor_id=executor_id
-        )
+        self.logger.info('Stage is executed', task_id=id, stage=stage, executor_id=executor_id)
         sql = (
             self.table.update()
             .where(sa.and_(self.table.c.id == id, self.table.c.status == TaskStatus.QUEUED.value))
             .values(
                 {
                     'status': TaskStatus.EXECUTED.value,
                     # 'stage': stage,
@@ -162,17 +162,15 @@
                 self.table.c.executor_id == executor_id,
                 self.table.c.stage == stage,
                 self.table.c.status.in_([TaskStatus.EXECUTED.value, TaskStatus.QUEUED.value]),
             )
         )
         columns = [self.table.c.job_id, self.table.c.result, self.table.c.notify, self.table.c.user_id]
         if error:
-            self.logger.info(
-                'Stage %d of %s: task failed', stage, id, stage=stage, task_id=id, executor_id=executor_id, error=error
-            )
+            self.logger.info('Stage failed', stage=stage, task_id=id, executor_id=executor_id, error=error)
             sql = sql.values(
                 {
                     'status': TaskStatus.FAILED.value,
                     'error': result,
                     'exit_code': ExitCode.EXECUTION_ERROR.value,
                     'executor_id': None,
                     'next_run': None,
@@ -190,58 +188,62 @@
                     status=TaskStatus.FAILED.value,
                     result=task['result'],
                     exit_code=ExitCode.EXECUTION_ERROR.value,
                     error=result,
                 )
                 await self._notifications.create(notification, columns=[])
         elif stage == stages - 1:
-            self.logger.info(
-                'Stage %d of %s: task finished', stage, id, stage=stage, task_id=id, executor_id=executor_id
-            )
+            self.logger.info('Task finished', stage=stage, task_id=id, executor_id=executor_id)
+            columns.append(self.table.c.next_task)
             sql = sql.values(
                 {
                     'status': TaskStatus.FINISHED.value,
                     'result': self.table.c.result + [result],
                     'exit_code': ExitCode.SUCCESS.value,
                     'executor_id': None,
                     'next_run': None,
                 }
             ).returning(*columns)
             task = await self._db.execute(sql)
             task = task.first()
+            if task and task.next_task:
+                self.logger.info('Starting next task', task_id=id, next_task=task.next_task)
+                sql = (
+                    self.table.update()
+                    .where(
+                        sa.and_(
+                            self.table.c.id == task.next_task,
+                            self.table.c.status.in_(
+                                [TaskStatus.IDLE.value, TaskStatus.FAILED.value, TaskStatus.FINISHED.value]
+                            ),
+                            self.table.c.active.is_(True),
+                        )
+                    )
+                    .values({'status': TaskStatus.IDLE.value, 'next_run': int(time())})
+                )
+                await self._db.execute(sql)
             if task and task.notify:
                 task = task._asdict()  # noqa
                 notification = Notification(
                     message='task.result',
                     user_id=task['user_id'],
                     task_id=id,
                     job_id=task['job_id'],
                     status=TaskStatus.FINISHED.value,
                     result=task['result'],
                     exit_code=ExitCode.SUCCESS.value,
                 )
                 await self._notifications.create(notification, columns=[])
         else:
-            self.logger.info(
-                'Stage %d of %s: stage finished', stage, id, stage=stage, task_id=id, executor_id=executor_id
-            )
+            self.logger.info('Stage finished', stage=stage, task_id=id, executor_id=executor_id)
             sql = sql.values(
                 {'status': TaskStatus.EXECUTED.value, 'result': self.table.c.result + [result], 'stage': stage + 1}
             )
             await self._db.execute(sql)
 
-    async def loop(self):
-        """Task manager routines."""
-        while not self._closing:
-            try:
-                await self._queue_tasks()
-            except Exception as exc:
-                self.logger.error('Error in a manager loop: %s.', exc, exc_info=exc)
-            await asyncio.sleep(self._refresh_interval)
-
     async def _queue_tasks(self):
         await self._expell_dead_executors()
         await self._abort_timed_out_tasks()
         await self._restart_cron_tasks()
         await self._queue_suspended_and_idle()
         await self._queue_failed()
 
@@ -254,15 +256,15 @@
                 .where(
                     sa.and_(
                         self.table.c.executor_id.in_(dead_executors), self.table.c.status == TaskStatus.EXECUTED.value
                     )
                 )
                 .values({'status': TaskStatus.SUSPENDED.value, 'executor_id': None})
             )
-            self.logger.info('Suspending tasks for dead executors: "%s".', dead_executors)
+            self.logger.info('Suspending dead executors', executor_id=dead_executors)
             await self._db.execute(sql)
             await self._redis.hdel(self.executor_map_key, dead_executors)
 
     async def _find_dead_executors(self) -> List[str]:
         executors = await self._redis.hgetall(self.executor_map_key)
         t = time()
         dt = Limit.PING_INTERVAL.value * 4
@@ -313,15 +315,15 @@
 
     async def _abort_timed_out_tasks(self):
         """Abort all queued tasks reached their timeout."""
         sql = (
             self.table.update()
             .where(
                 sa.and_(
-                    self.table.c.queued_at < int(time()) - Limit.MIN_DT.value - self.table.c.max_exec_timeout,
+                    self.table.c.queued_at < int(time()) - Limit.MIN_T.value - self.table.c.max_exec_timeout,
                     self.table.c.status.in_([TaskStatus.QUEUED.value, TaskStatus.EXECUTED.value]),
                     self.table.c.active.is_(True),
                 )
             )
             .values(
                 {
                     'status': TaskStatus.FAILED.value,
```

## kaiju_tasks/notifications.py

```diff
@@ -14,33 +14,30 @@
 
     service_name = 'notifications'
     table = notifications
     update_columns = {'marked'}
 
     def prepare_insert_data(self, data: dict):
         """Injecting an author id from user session."""
-        session = self.get_session()
-        user_id = self.get_user_id(session)
+        user_id = self.get_user_id()
         data = {**data, 'author_id': user_id}
         return data
 
-    def _set_user_condition(self, sql, session):
-        user_id = self.get_user_id(session)
+    def _set_user_condition(self, sql):
+        user_id = self.get_user_id()
         sql = sql.where(sa.or_(self.table.c.author_id == user_id, self.table.c.user_id == user_id))
         return sql
 
     def _update_condition_hook(self, sql):
         """Places user condition if a user has no admin/system privileges for editing all the data."""
-        session = self.get_session()
-        if not self.has_permission(session, Permission.MODIFY_OTHERS_NOTIFICATIONS.value):
-            sql = self._set_user_condition(sql, session)
+        if not self.has_permission(Permission.MODIFY_OTHERS_NOTIFICATIONS.value):
+            sql = self._set_user_condition(sql)
         return sql
 
     def _delete_condition_hook(self, sql):
         return self._update_condition_hook(sql)
 
     def _get_condition_hook(self, sql):
         """Places user condition if a user has no admin/system privileges for viewing all the data."""
-        session = self.get_session()
-        if not self.has_permission(session, Permission.VIEW_OTHERS_NOTIFICATIONS.value):
-            sql = self._set_user_condition(sql, session)
+        if not self.has_permission(Permission.VIEW_OTHERS_NOTIFICATIONS.value):
+            sql = self._set_user_condition(sql)
         return sql
```

## kaiju_tasks/tables.py

```diff
@@ -43,14 +43,15 @@
         # manager instructions
         sa.Column('active', sa_pg.BOOLEAN, nullable=False),
         sa.Column('cron', sa_pg.TEXT, nullable=True),
         sa.Column('max_exec_timeout', sa_pg.INTEGER, nullable=False),
         sa.Column('max_retries', sa_pg.INTEGER, nullable=False),
         sa.Column('restart_policy', sa_pg.TEXT, nullable=False),
         sa.Column('notify', sa_pg.BOOLEAN, nullable=False),
+        sa.Column('next_task', sa.ForeignKey(f'{table_name}.id', ondelete='SET NULL'), nullable=True),
         # meta
         sa.Column('name', sa_pg.TEXT, nullable=True),
         sa.Column('description', sa_pg.TEXT, nullable=True),
         sa.Column('meta', sa_pg.JSONB, nullable=False),
         # managed
         sa.Column('status', sa_pg.TEXT, nullable=False),
         sa.Column('result', sa_pg.JSONB, nullable=False),
```

## kaiju_tasks/tests/test_task_management.py

```diff
@@ -2,14 +2,15 @@
 from time import time
 
 import pytest
 
 from kaiju_tasks.etc import TaskStatus, RestartPolicy
 from kaiju_tools.jsonschema import Object, compile_schema
 from kaiju_tools.tests.fixtures import *
+from kaiju_tools.scheduler import Scheduler
 from kaiju_db.tests.fixtures import *
 from kaiju_redis.tests.fixtures import *
 
 from ..services import *
 
 
 class TestService(Service, AbstractRPCCompatible):
@@ -31,25 +32,27 @@
 @pytest.fixture
 def task_manager(application, redis_listener, database_service, logger) -> TaskManager:
     app = application()
     app.services = SimpleNamespace(initialized=asyncio.Event())
     app.services.initialized.set()
     app.logger = logger
     redis_listener.topics = ['rpc']
+    redis_listener._locks_service_name._scheduler = scheduler = Scheduler(app=app, logger=logger)
     database_service.app = redis_listener.app = app
     app.get_session = redis_listener._rpc_service_name.get_session
     notification_service = NotificationService(app=redis_listener.app, database_service=database_service)
     task_service = TaskService(app=app, database_service=database_service)
     task_service._validator = compile_schema(Object({}, additionalProperties=True))
     manager = TaskManager(
         app=redis_listener.app,
         database_service=database_service,
         stream_service=redis_listener,
         redis_transport=redis_listener._transport_name,  # noqa
         notification_service=notification_service,
+        scheduler_service=scheduler,
     )
     manager._tasks = task_service
     rpc = redis_listener._rpc_service_name  # noqa
     rpc.register_service(manager.service_name, manager)
     return manager
 
 
@@ -60,18 +63,14 @@
     task_service = task_manager._tasks
     new_task = str(uuid.uuid4())
     executor_id = uuid.uuid4()
     async with task_manager._db:
         async with task_manager._stream:
             async with task_manager._stream._locks:
                 async with task_manager:
-                    task_manager._task.cancel()
-
-                    # testing execution and notifications
-
                     await task_service.create({'id': new_task, 'commands': [{'method': 'do'}], 'notify': True})
                     await task_manager._queue_tasks()
                     await task_manager.execute_stage(new_task, executor_id, 0)
                     await task_manager.write_stage(new_task, executor_id, 0, 1, 42, False)
                     # notifications = await task_manager._notifications.list(conditions={'task_id': new_task})
                     # logger.info(notifications)
                     # assert notifications['data'][0]['result'] == [42]
@@ -90,15 +89,14 @@
 async def test_manager_executor_management(per_session_database, per_session_redis, task_manager, logger):
     task_manager.app.name = 'pytest'
     task_service = task_manager._tasks
     new_task = str(uuid.uuid4())
     new_executor = uuid.uuid4()
     async with task_manager._db:
         async with task_manager:
-            task_manager._task.cancel()
 
             # registering executors
 
             await task_manager.ping(new_executor)
             active = await task_manager.list_active_executors()
             assert str(new_executor).encode('utf-8') in active
             await task_service.create({'id': new_task, 'commands': [{'method': 'do'}]})
@@ -197,15 +195,14 @@
 async def test_manager_tasks(per_session_database, per_session_redis, task_manager, logger, data, after_queue):
     task_manager.app.name = 'pytest'
     task_service = task_manager._tasks
     async with task_manager._db:
         async with task_manager._stream:
             async with task_manager._stream._locks:
                 async with task_manager:
-                    task_manager._task.cancel()
                     task = await task_service.create(
                         {'commands': [{'method': 'do'}, {'method': 'do.2'}]}, columns=['id']
                     )
                     task = await task_service.update(task['id'], data, columns='*')
                     await asyncio.sleep(1)
                     logger.info('Task before: %s', task)
                     queue = await task_manager._queue_tasks()
@@ -215,51 +212,81 @@
                     logger.info('Expected: %s', after_queue)
                     for key, value in after_queue.items():
                         assert _task[key] == value
 
 
 @pytest.mark.asyncio
 @pytest.mark.docker
-async def test_manager_executor_interaction(per_session_database, per_session_redis, task_manager, logger):
+async def test_task_chaining(per_session_database, per_session_redis, task_manager, logger):
     task_manager.app.name = 'pytest'
     task_service = task_manager._tasks
-    simple_service = TestService(app=task_manager.app)
-    task_manager._stream._rpc_service_name.register_service(simple_service.service_name, simple_service)
-    executor = TaskExecutor(
-        app=task_manager.app,
-        rpc_service=task_manager._stream._rpc_service_name,  # noqa
-        stream_service=task_manager._stream,
-        max_parallel_tasks=1,
-    )
-    executor._rpc.register_service(executor.service_name, executor)
     async with task_manager._db:
-        task = await task_service.create(
-            {
-                'commands': [
-                    {'method': 'test.do', 'params': {'a': 0, 'b': 1}},
-                    {'method': 'test.do', 'params': {'a': '[KWS.const]', 'b': '[RESULT.0]'}},
-                    {'method': 'test.do', 'params': {'a': '[RESULT.1]', 'b': 1}},
-                ],
-                'kws': {'const': 42},
-            },
-            columns=['id'],
-        )
-        task = await task_service.update(
-            task['id'],
-            {'status': TaskStatus.SUSPENDED.value, 'stage': 1, 'result': [1], 'queued_at': int(time())},
-            columns='*',
-        )
-        logger.info('Task before: %s', task)
-        async with task_manager._stream._rpc_service_name:
-            async with task_manager._stream:
-                async with task_manager._stream._locks:
-                    async with task_manager:
-                        for consumer in task_manager._stream._consumers.values():
-                            consumer._rpc = task_manager._stream._rpc
-                        async with executor:
-                            await asyncio.sleep(2)
-                        task = await task_service.get(task['id'])
-                        logger.info(task)
-                        assert task['status'] == TaskStatus.FINISHED.value
-                        assert task['stage'] == 2
-                        assert task['exit_code'] == 0
-                        assert task['result'] == [1, 43, 44]  # should be resumed from the last stage
+        async with task_manager._stream:
+            async with task_manager._stream._locks:
+                async with task_manager:
+                    executor_id = uuid.uuid4()
+                    next_task = await task_service.create({'commands': [{'method': 'do'}]})
+                    logger.debug(next_task)
+                    task = await task_service.create(
+                        {'commands': [{'method': 'do'}], 'next_task': next_task['id']}, columns='*'
+                    )
+                    logger.debug(task)
+                    await task_service.update(
+                        next_task['id'], {'status': TaskStatus.FINISHED.value, 'next_run': time() + 10000}
+                    )
+                    await task_service.update(
+                        task['id'], {'status': TaskStatus.EXECUTED.value, 'executor_id': executor_id, 'stage': 0}
+                    )
+                    await task_manager.write_stage(task['id'], executor_id, 0, 1, 'result', False)
+                    next_task = await task_service.get(next_task['id'])
+                    logger.debug(next_task)
+                    assert next_task['status'] == TaskStatus.IDLE.value
+                    assert next_task['next_run'] <= time()
+
+
+# @pytest.mark.asyncio
+# @pytest.mark.docker
+# async def test_manager_executor_interaction(per_session_database, per_session_redis, task_manager, logger):
+#     task_manager.app.name = 'pytest'
+#     task_service = task_manager._tasks
+#     simple_service = TestService(app=task_manager.app)
+#     task_manager._stream._rpc_service_name.register_service(simple_service.service_name, simple_service)
+#     executor = TaskExecutor(
+#         app=task_manager.app,
+#         rpc_service=task_manager._stream._rpc_service_name,  # noqa
+#         stream_service=task_manager._stream,
+#         max_parallel_tasks=2,
+#     )
+#     executor._rpc.register_service(executor.service_name, executor)
+#     async with task_manager._db:
+#         task = await task_service.create(
+#             {
+#                 'commands': [
+#                     {'method': 'test.do', 'params': {'a': 0, 'b': 1}},
+#                     {'method': 'test.do', 'params': {'a': '[KWS.const]', 'b': '[RESULT.0]'}},
+#                     {'method': 'test.do', 'params': {'a': '[RESULT.1]', 'b': 1}},
+#                 ],
+#                 'kws': {'const': 42},
+#             },
+#             columns=['id'],
+#         )
+#         task = await task_service.update(
+#             task['id'],
+#             {'status': TaskStatus.SUSPENDED.value, 'stage': 1, 'result': [1], 'queued_at': int(time())},
+#             columns='*',
+#         )
+#         logger.info('Task before: %s', task)
+#         async with task_manager._stream._rpc_service_name:
+#             async with task_manager._stream:
+#                 async with task_manager._stream._locks:
+#                     async with task_manager:
+#                         for consumer in task_manager._stream._consumers.values():
+#                             consumer._rpc = task_manager._stream._rpc
+#                         await task_manager._queue_tasks()
+#                         async with executor:
+#                             await asyncio.sleep(3)
+#                             task = await task_service.get(task['id'])
+#                             logger.info(task)
+#                             assert task['status'] == TaskStatus.FINISHED.value
+#                             assert task['stage'] == 2
+#                             assert task['exit_code'] == 0
+#                             assert task['result'] == [1, 43, 44]  # should be resumed from the last stage
```

## Comparing `kaiju_tasks-2.0.12.dist-info/LICENSE` & `kaiju_tasks-2.1.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `kaiju_tasks-2.0.12.dist-info/METADATA` & `kaiju_tasks-2.1.0.dist-info/METADATA`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: kaiju-tasks
-Version: 2.0.12
+Version: 2.1.0
 Summary: Service and user task management
 Home-page: https://gitlab.com/kaiju-python/kaiju-tasks
 Author: antonnidhoggr@me.com
 Author-email: antonnidhoggr@me.com
 License: Apache Software License 2.0
 Classifier: Development Status :: 3 - Alpha
 Classifier: License :: OSI Approved :: Apache Software License
@@ -15,31 +15,33 @@
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Requires-Python: >=3.8
 Description-Content-Type: text/x-rst
 License-File: LICENSE
 Requires-Dist: croniter (>=1.3)
-Requires-Dist: kaiju-tools (<3,>=2.0.53)
-Requires-Dist: kaiju-db (<3,>=2.0.11)
-Requires-Dist: kaiju-redis (<3.0,>=2.0.5)
+Requires-Dist: kaiju-tools (<3,>=2)
+Requires-Dist: kaiju-db (<3,>=2)
+Requires-Dist: kaiju-redis (<3.0,>=2)
 Provides-Extra: dev
 Requires-Dist: bump2version (>=1.0) ; extra == 'dev'
 Requires-Dist: pyroma (>=4.1) ; extra == 'dev'
 Requires-Dist: bandit (==1.7) ; extra == 'dev'
 Requires-Dist: black (>=22.12) ; extra == 'dev'
 Requires-Dist: flake8 (>=6.0) ; extra == 'dev'
 Requires-Dist: pyproject-flake8 ; extra == 'dev'
 Requires-Dist: pre-commit (>=3.1) ; extra == 'dev'
 Requires-Dist: pydocstyle (>=6.2) ; extra == 'dev'
 Requires-Dist: setup-cfg-fmt (>=2.2) ; extra == 'dev'
 Requires-Dist: restructuredtext-lint (>=1.4) ; extra == 'dev'
 Requires-Dist: tox (>=3.28) ; extra == 'dev'
 Requires-Dist: tox-pyenv (>=1.1) ; extra == 'dev'
 Requires-Dist: pip-tools (>=6.13) ; extra == 'dev'
+Requires-Dist: towncrier (>=23.6) ; extra == 'dev'
+Requires-Dist: pyupgrade (>=3.4) ; extra == 'dev'
 Provides-Extra: docs
 Requires-Dist: sphinx ; extra == 'docs'
 Requires-Dist: python-docs-theme ; extra == 'docs'
 Provides-Extra: test
 Requires-Dist: pytest (>=7.2) ; extra == 'test'
 Requires-Dist: pytest-asyncio (>=0.20) ; extra == 'test'
 Requires-Dist: docker (>=6.0) ; extra == 'test'
```

## Comparing `kaiju_tasks-2.0.12.dist-info/RECORD` & `kaiju_tasks-2.1.0.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-kaiju_tasks/__init__.py,sha256=0XkuR4-u6ctmoBTpwwbBxXCkIH0hoswMGDAjecq-9aU,152
-kaiju_tasks/etc.py,sha256=fPwM7jthxYb8Wd0GjmgVo9vKEyrnDW5VPeApT06xk-0,5135
-kaiju_tasks/executor.py,sha256=9_OKnNLyaFzRpuOSPTHIWm62Wp1m4ULk9LfcqUnLqwM,8492
+kaiju_tasks/__init__.py,sha256=4ytn3hyINRMu118OgkZN1LPinG8sYcZYdgu7zRnilwQ,151
+kaiju_tasks/etc.py,sha256=QYq3fRu9zmYdJv2OdB4n9gsxWMp4rJNZvReDcLpTd0U,5212
+kaiju_tasks/executor.py,sha256=ohV19bROFRtE9BWf_5QJ_mqtgqo2SuMohlQoCsSR0y0,8196
 kaiju_tasks/fixtures.py,sha256=EBpjAZ9_nfbMV0DpkcpQoFbw3RsELFuSXBVm-zMPCOk,1290
-kaiju_tasks/interface.py,sha256=5toifG-uP-OzQ6w7UbK8WywpyquX_lePi6zYdSZFvYA,6117
-kaiju_tasks/manager.py,sha256=w5D5xt_ZTk5s0shwnsGWdSM8F6fVM8DgXaSy-hVuON8,18363
-kaiju_tasks/notifications.py,sha256=z7mluYiJFCpFjyddxZ82HkhgRyxgePT6PSdQ0p1D0v8,1687
+kaiju_tasks/interface.py,sha256=vuXUmYjfujmJo433uNvVu-ZdUy5YNGuqn0FSmh9y1TU,5919
+kaiju_tasks/manager.py,sha256=ewA1L2fTH-fqR6SJGLPiYXlv40OQFw3JA7kA_ZtiElQ,18900
+kaiju_tasks/notifications.py,sha256=wMNYMxlsTvFDVYNf8tf79zAzgeBLI2WpmXDPQ7Z56zI,1517
 kaiju_tasks/services.py,sha256=mudNyQmrgekIw-Ig7lqMktb2UlbCGjBIX2I0nkz9O8I,191
-kaiju_tasks/tables.py,sha256=mWR4NHSALlHX1s96079MwenNrEkXcCVdLSFK8L_3sA8,4164
+kaiju_tasks/tables.py,sha256=sU5F_PMR6T4ZAHlF1EPvnJenwBRvfMGxbFjr4J4JVMk,4267
 kaiju_tasks/tasks_gui/__init__.py,sha256=_gDfM5r8uxCvydv3NOUN21imwJW_NW9R16UXWExQAE8,38
 kaiju_tasks/tasks_gui/models.py,sha256=iXqYnYYh8TJ7jkVxyEmMeykfpmoNfEfEERW-1jwzjsk,2011
 kaiju_tasks/tasks_gui/service.py,sha256=_qCURg-h6I9OI5uZdTGYCzJglXPXomcqAt6D7ODLRmU,4272
 kaiju_tasks/tasks_gui/validators.py,sha256=QybfHwKMWJq9AcGlXO7F5fuEGLssjHN2jcAV0UI6FPc,350
 kaiju_tasks/tests/__init__.py,sha256=WlPruePOcaMi5ikqn6GheE1Z-zYcysb9M1dj6SteWGY,42
-kaiju_tasks/tests/test_task_management.py,sha256=WkN0lAyStIogQxJPyvlYDEY7XcYi5XK-RmQbf6oHCi8,11345
-kaiju_tasks-2.0.12.dist-info/LICENSE,sha256=XIlN2qA8UqpBDA-PteoYP4hTU0qBW0G9PRB__khO2zc,610
-kaiju_tasks-2.0.12.dist-info/METADATA,sha256=_ZZDa7W91FcgaVztsvZOFDv1Vv5_CmsNmjaSNd2ss-I,2970
-kaiju_tasks-2.0.12.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-kaiju_tasks-2.0.12.dist-info/top_level.txt,sha256=QyLogqOVVajJlalq6RfikGx5VGn_lLeTANJEsfZZlM0,12
-kaiju_tasks-2.0.12.dist-info/RECORD,,
+kaiju_tasks/tests/test_task_management.py,sha256=A50zkkQdy3BE8Nu_xcM36vqb_ccXEcgFtGo_E_SQZUM,12986
+kaiju_tasks-2.1.0.dist-info/LICENSE,sha256=XIlN2qA8UqpBDA-PteoYP4hTU0qBW0G9PRB__khO2zc,610
+kaiju_tasks-2.1.0.dist-info/METADATA,sha256=UnU_KEwFfK-yjrFh-NLfRy3MwH0YGR7yBQOwSy7uD6w,3056
+kaiju_tasks-2.1.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+kaiju_tasks-2.1.0.dist-info/top_level.txt,sha256=QyLogqOVVajJlalq6RfikGx5VGn_lLeTANJEsfZZlM0,12
+kaiju_tasks-2.1.0.dist-info/RECORD,,
```

